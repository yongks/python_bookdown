[{"path":"index.html","id":"about-this-book","chapter":"About This Book","heading":"About This Book","text":"","code":""},{"path":"index.html","id":"motivation","chapter":"About This Book","heading":"Motivation","text":"python cookbook, serving quick reference python popular library. content covers python fundamentals, data manipulation, plotting, machine learning sentiment analysis.main motivation book personal reference. Therefore, written manner according thinking process. like work python part-time basis, book may help refresh memories quickly.","code":""},{"path":"index.html","id":"building-the-book","chapter":"About This Book","heading":"Building The Book","text":"Although book written python code, contructed sing Bookdown (R Language). made possible reticulate R library integrating Python R.content pages book written RMarkdown files, rendered Bookdown BS4 (bootstrap 4, 3 columns layout) output format. Renders output goes “/doc” folder, uploaded github. **/doc** folder Github served Github Pages, reading right now.","code":""},{"path":"index.html","id":"ingridients","chapter":"About This Book","heading":"Ingridients","text":"key ingredients used build book.R LanguageRMarkownBookdownRStudio IDEGithub Pages","code":""},{"path":"index.html","id":"environment","chapter":"About This Book","heading":"Environment","text":"book build Python environment:Anaconda “base” environmentPython 3.9.13pandas (1.4.4)numpy (1.23.4)scipy (1.9.3)scikit-learn (1.1.3)seaborn (0.12.1)matplotlib (3.6.2)plotnine (0.10.1)nltk (3.7)statsmodel (0.13.2)bs4 (4.11.1)","code":""},{"path":"fundamentals.html","id":"fundamentals","chapter":"1 Fundamentals","heading":"1 Fundamentals","text":"","code":""},{"path":"fundamentals.html","id":"library-management","chapter":"1 Fundamentals","heading":"1.1 Library Management","text":"","code":""},{"path":"fundamentals.html","id":"built-in-libraries","chapter":"1 Fundamentals","heading":"1.1.1 Built-In Libraries","text":"","code":"import string\nimport datetime as dt\nimport os\n#os.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = \"C:\\ProgramData\\Anaconda3\\Library\\plugins\\platforms\""},{"path":"fundamentals.html","id":"external-libraries","chapter":"1 Fundamentals","heading":"1.1.2 External Libraries","text":"popular external libraries.numpy\n- large multi-dimensional array matrices\n- High level mathematical funcitons operate \n- Efficient array computation, modeled matlab\n- Support vectorized array math functions (built C, hence faster python loop list)scipy\n- Collection mathematical algorithms convenience functions built numpy extension\n- Built upon numpyPandas\n- Data manipulation analysis\n- Offer data structures operations manipulating numerical tables time series\n- Good analyzing tabular data\n- Use exploratory data analysis, data pre-processing, statistics visualization\n- Built upon numpyscikit-learn\n- Machine learning functions\n- Built top scipymatplotlib\n- Data Visualization","code":""},{"path":"fundamentals.html","id":"package-management","chapter":"1 Fundamentals","heading":"1.1.3 Package Management","text":"","code":""},{"path":"fundamentals.html","id":"anaconda","chapter":"1 Fundamentals","heading":"1.1.4 Anaconda","text":"","code":""},{"path":"fundamentals.html","id":"conda-environment","chapter":"1 Fundamentals","heading":"Conda Environment","text":"Anaconda popular package management system python. Interaction anaconda command prompt “conda”.","code":"conda info ## check the installed conda version and directories\nconda list ## list all installed python modules, and its version"},{"path":"fundamentals.html","id":"package-installation","chapter":"1 Fundamentals","heading":"Package Installation","text":"Conda recommended distribution. install official conda channel:install conda-forge community channel:","code":"## Syntax\nconda install <package_name>                 # always install latest\nconda install <package_name=version_number>  ## install specific version\n\n## Example\nconda install scipy        ## official channel\nconda install scipy=1.2.3  ## official channelconda install -c conda-forge <package_name>\nconda install -c conda-forge <package_name=version_number>\n\n## Example: Install From conda community:\nconda install -c conda-forge plotnine\nconda install -c conda-forge plotnine=1.2.3\n"},{"path":"fundamentals.html","id":"pip","chapter":"1 Fundamentals","heading":"1.1.5 PIP","text":"PIP python open repository (part conda). Use pip package available conda.","code":""},{"path":"fundamentals.html","id":"package-version","chapter":"1 Fundamentals","heading":"Package Version","text":"","code":"pip list ## list all installed module"},{"path":"fundamentals.html","id":"package-installation-1","chapter":"1 Fundamentals","heading":"1.1.5.1 Package Installation","text":"","code":"pip install <package_name>\npip install <package_name=version_numner>\n\n## Example: \npip install plydata\npip install plydata=1.2.3"},{"path":"fundamentals.html","id":"variables-are-objects","chapter":"1 Fundamentals","heading":"1.2 Variables Are Objects","text":"variables python objectsEvery variable assginment reference based, , object value reference memory block dataIn example, , b c  refer memory location:Notice object assigned another object, refer memory locationWhen two variable refers value, refer memory locationChanging data value (using assignment) changes reference","code":"a = 123\nb = 123  \nc = a\nprint ('Data of a =',  a,\n       '\\nData of b =',b,\n       '\\nData of c =',c,\n       '\\nID of a = ', id(a),\n       '\\nID of b = ', id(b),\n       '\\nID of c = ', id(c)\n)## Data of a = 123 \n## Data of b = 123 \n## Data of c = 123 \n## ID of a =  2732738238640 \n## ID of b =  2732738238640 \n## ID of c =  2732738238640a = 123\nb = a\na = 456  # reassignemnt changed a memory reference\n         # b memory reference not changed\nprint ('Data of a =',a,\n     '\\nData of b =',b,\n     '\\nID of a = ', id(a),\n     '\\nID of b = ', id(b)\n)## Data of a = 456 \n## Data of b = 123 \n## ID of a =  2732866733808 \n## ID of b =  2732738238640"},{"path":"fundamentals.html","id":"assignment","chapter":"1 Fundamentals","heading":"1.3 Assignment","text":"","code":""},{"path":"fundamentals.html","id":"multiple-assignment","chapter":"1 Fundamentals","heading":"1.3.1 Multiple Assignment","text":"Assign multiple variable time value. Note object created using method refer memory location.","code":"x = y = 'same mem loc'\nprint ('x = ', x,\n     '\\ny = ', y,\n     '\\nid(x) = ', id(x), \n     '\\nid(y) = ', id(y)\n)## x =  same mem loc \n## y =  same mem loc \n## id(x) =  2732866861936 \n## id(y) =  2732866861936"},{"path":"fundamentals.html","id":"augmented-assignment","chapter":"1 Fundamentals","heading":"1.3.2 Augmented Assignment","text":"","code":"x = 1\ny = x + 1\ny += 1\nprint ('y = ', y)## y =  3"},{"path":"fundamentals.html","id":"unpacking-assingment","chapter":"1 Fundamentals","heading":"1.3.3 Unpacking Assingment","text":"Assign multiple value multiple variabels time.","code":"x,y = 1,3\nprint (x,y)## 1 3"},{"path":"built-in-data-types.html","id":"built-in-data-types","chapter":"2 Built-in Data Types","heading":"2 Built-in Data Types","text":"","code":""},{"path":"built-in-data-types.html","id":"numbers","chapter":"2 Built-in Data Types","heading":"2.1 Numbers","text":"Two types built-number type, integer float.","code":""},{"path":"built-in-data-types.html","id":"integer","chapter":"2 Built-in Data Types","heading":"2.1.1 Integer","text":"","code":"n = 123\ntype (n)## <class 'int'>"},{"path":"built-in-data-types.html","id":"float","chapter":"2 Built-in Data Types","heading":"2.1.2 Float","text":"","code":"f = 123.4\ntype (f)## <class 'float'>"},{"path":"built-in-data-types.html","id":"number-operators","chapter":"2 Built-in Data Types","heading":"2.1.3 Number Operators","text":"general, operation potentially return float, result float type. Otherwise return integer.Division always return floatInteger Division integer return inter. Integer division float return float.Remainder integer return integer.\nRemainder float return floatPower return int float","code":"print(4/2)  # return float## 2.0type(4/2)## <class 'float'>print (8//3,'\\n',    # return int\n       8//3.2)       # return float## 2 \n##  2.0print (8%3, '\\n',    # return int\n       8%3.2)        # return float## 2 \n##  1.5999999999999996print (2**3)    # return int## 8print (2.1**3)  # return float## 9.261000000000001print (2**3.1)  # return float## 8.574187700290345"},{"path":"built-in-data-types.html","id":"string","chapter":"2 Built-in Data Types","heading":"2.2 String","text":"String object class ‘str’. ordered collection letters, array object type str","code":"import string\ns = 'abcde'\nprint( '\\nvar type  = ', type(s),\n       '\\nelems     = ',s[0], s[1], s[2],\n       '\\nlen       = ', len(s),\n       '\\nelem type = ',type(s[1]))## \n## var type  =  <class 'str'> \n## elems     =  a b c \n## len       =  5 \n## elem type =  <class 'str'>"},{"path":"built-in-data-types.html","id":"constructor","chapter":"2 Built-in Data Types","heading":"2.2.1 Constructor","text":"","code":""},{"path":"built-in-data-types.html","id":"classical-method","chapter":"2 Built-in Data Types","heading":"2.2.1.1 Classical Method","text":"class str(object='')class str(object=b'', encoding='utf-8', errors='strict')","code":"my_string = str()        ## empty stringmy_string = str('abc')"},{"path":"built-in-data-types.html","id":"shortcut-method","chapter":"2 Built-in Data Types","heading":"2.2.1.2 Shortcut Method","text":"","code":"my_string = 'abc'"},{"path":"built-in-data-types.html","id":"multiline-method","chapter":"2 Built-in Data Types","heading":"2.2.1.3 Multiline Method","text":"Note variable contain \\n front end string.","code":"my_string = '''\nThis is me.\nYong Keh Soon\n'''\nprint(my_string)## \n## This is me.\n## Yong Keh Soonmy_string## '\\nThis is me.\\nYong Keh Soon\\n'"},{"path":"built-in-data-types.html","id":"immutability","chapter":"2 Built-in Data Types","heading":"2.2.1.4 Immutability","text":"String immuatable. Changing content result errorChanging variable completley change reference (new object)","code":"s = 'abcde'\nprint ('s : ', id(s))\n#s[1] = 'z'               # immutable, result in error## s :  2654769956208s = 'efgh'\nprint ('s : ', id(s))## s :  2654769960496"},{"path":"built-in-data-types.html","id":"class-constants","chapter":"2 Built-in Data Types","heading":"2.2.2 Class Constants","text":"","code":""},{"path":"built-in-data-types.html","id":"letters","chapter":"2 Built-in Data Types","heading":"2.2.2.1 Letters","text":"","code":"print( 'letters = ', string.ascii_letters,\n        '\\nlowercase = ',string.ascii_lowercase,\n        '\\nuppercase = ',string.ascii_uppercase )## letters =  abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ \n## lowercase =  abcdefghijklmnopqrstuvwxyz \n## uppercase =  ABCDEFGHIJKLMNOPQRSTUVWXYZ"},{"path":"built-in-data-types.html","id":"digits","chapter":"2 Built-in Data Types","heading":"2.2.2.2 Digits","text":"","code":"string.digits## '0123456789'"},{"path":"built-in-data-types.html","id":"white-spaces","chapter":"2 Built-in Data Types","heading":"2.2.2.3 White Spaces","text":"","code":"string.whitespace## ' \\t\\n\\r\\x0b\\x0c'"},{"path":"built-in-data-types.html","id":"instance-methods","chapter":"2 Built-in Data Types","heading":"2.2.3 Instance Methods","text":"","code":""},{"path":"built-in-data-types.html","id":"substitution-format","chapter":"2 Built-in Data Types","heading":"2.2.3.1 Substitution : format()","text":"PositionalBy NameBy Dictionary NameFormatting NumberFloatInteger, PercentageAlignment","code":"print( '{} + {} = {}'.format('a', 'b', 'c'),         # auto sequence\n       '\\n{0} + {1} = {2}'.format('aa', 'bb', 'cc')) # manual sequence## a + b = c \n## aa + bb = cc'Coordinates: {latitude}, {longitude}'.format(latitude='37.24N', longitude='-115.81W') ## constant## 'Coordinates: 37.24N, -115.81W'coord = {'latitude': '37.24N', 'longitude': '-115.81W'} ## dictionary key/value\n'Coordinates: {latitude}, {longitude}'.format(**coord)## 'Coordinates: 37.24N, -115.81W''{:+f}; {:+f}'.format(3.14, -3.14)  # show it always## '+3.140000; -3.140000''{: f}; {: f}'.format(3.14, -3.14)  # show a space for positive numbers## ' 3.140000; -3.140000''Correct answers: {:.2f}'.format(55676.345345)## 'Correct answers: 55676.35''{0:,}   {0:.2%}   {0:,.2%}'.format(1234567890.4455)## '1,234,567,890.4455   123456789044.55%   123,456,789,044.55%''{0:<20}   {0:<<20}'.format('left aligned')## 'left aligned           left aligned<<<<<<<<''{0:>20}  {0:$>20}'.format('right aligned')## '       right aligned  $$$$$$$right aligned''{:^30}'.format('centered')  # use '*' as a fill char## '           centered           '"},{"path":"built-in-data-types.html","id":"substitution-f-string","chapter":"2 Built-in Data Types","heading":"2.2.3.2 Substitution : f-string","text":"","code":"my_name = 'Yong Keh Soon'\nsalary  = 11123.346\nf'Hello, {my_name}, your salary is {salary:,.2f} !'## 'Hello, Yong Keh Soon, your salary is 11,123.35 !'"},{"path":"built-in-data-types.html","id":"conversion-upper-lower","chapter":"2 Built-in Data Types","heading":"2.2.3.3 Conversion: upper() lower()","text":"","code":"'myEXEel.xls'.upper()## 'MYEXEEL.XLS''myEXEel.xls'.lower()## 'myexeel.xls'"},{"path":"built-in-data-types.html","id":"find-pattern-position","chapter":"2 Built-in Data Types","heading":"2.2.3.4 find() pattern position","text":"","code":"string.find() return position of first occurance. -1 if not founds='I love karaoke, I know you love it oo'\nprint (s.find('lov'))## 2print (s.find('kemuning'))## -1"},{"path":"built-in-data-types.html","id":"strip-off-blank-spaces","chapter":"2 Built-in Data Types","heading":"2.2.3.5 strip() off blank spaces","text":"","code":"filename = '  myexce l.   xls   '\nfilename.strip()## 'myexce l.   xls'"},{"path":"built-in-data-types.html","id":"list-related-split","chapter":"2 Built-in Data Types","heading":"2.2.3.6 List Related: split()","text":"Splitting delimeter specified. Observe empty spaces conserved result array","code":"animals = 'a1,a2 ,a3, a4'\nanimals.split(',')## ['a1', 'a2 ', 'a3', ' a4']"},{"path":"built-in-data-types.html","id":"list-related-join","chapter":"2 Built-in Data Types","heading":"2.2.3.7 List Related: join()","text":"","code":"'-'.join(['1', '2', '3', '4'])## '1-2-3-4'"},{"path":"built-in-data-types.html","id":"replacement-.replace","chapter":"2 Built-in Data Types","heading":"2.2.3.8 Replacement: .replace()","text":"","code":"string = \"geeks for geeks geeks geeks geeks\" \n   \n# Prints the string by replacing geeks by Geeks  \nprint(string.replace(\"geeks\", \"Geeks\"))  \n  \n# Prints the string by replacing only 3 occurrence of Geeks   ## Geeks for Geeks Geeks Geeks Geeksprint(string.replace(\"geeks\", \"GeeksforGeeks\", 3)) ## GeeksforGeeks for GeeksforGeeks GeeksforGeeks geeks geeks"},{"path":"built-in-data-types.html","id":"operator","chapter":"2 Built-in Data Types","heading":"2.2.4 Operator","text":"","code":""},{"path":"built-in-data-types.html","id":"old-style-substitution","chapter":"2 Built-in Data Types","heading":"2.2.4.1 % Old Style Substitution","text":"https://docs.python.org/3/library/stdtypes.html#old-string-formatting","code":"my_name = 'Yong Keh Soon'\nsalary  = 11123.346\n'Hello, %s, your salary is %.2f !' %(my_name, salary)## 'Hello, Yong Keh Soon, your salary is 11123.35 !'"},{"path":"built-in-data-types.html","id":"concatenation","chapter":"2 Built-in Data Types","heading":"2.2.4.2 + Concatenation","text":"","code":"'this is ' + 'awesome'## 'this is awesome'"},{"path":"built-in-data-types.html","id":"in-matching","chapter":"2 Built-in Data Types","heading":"2.2.4.3 in matching","text":"single string, partial matchFor list strings, exact match (even though one element list).\npartial match, workaround convert list single string","code":"print( 'abc' in '123abcdefg' )## Trueprint( 'abc' in ['abcdefg'],             # false\n       'abc' in ['abcdefg','123'],       # fakse\n       'abc' in ['123','abc','def'],     # true\n       'abc' in str(['123','abcdefg']))  # true## False False True True"},{"path":"built-in-data-types.html","id":"comparitor","chapter":"2 Built-in Data Types","heading":"2.2.4.4 Comparitor","text":"Comparitor compares memory address.","code":"a='abc'\nb='abc'\nprint('id(a) = ', id(a), \n      '\\nid(b) = ', id(b),\n      '\\na == b  ', a==b)## id(a) =  2654693094320 \n## id(b) =  2654693094320 \n## a == b   True"},{"path":"built-in-data-types.html","id":"iterations","chapter":"2 Built-in Data Types","heading":"2.2.5 Iterations","text":"step negative (reverse), end value must lower start value","code":"string[start:end:step]  # default start:0, end:last, step:1s = 'abcdefghijk'\nprint (s[0])       # first later## aprint (s[:3])      # first 3 letters## abcprint (s[2:8 :2])  # stepping## cegprint (s[-1])      # last letter## kprint (s[-3:])     # last three letters## ijkprint (s[:   :-1]) # reverse everything## kjihgfedcbaprint (s[8:2 :-1])## ihgfedprint (s[8:2])     # return NOTHING"},{"path":"built-in-data-types.html","id":"boolean","chapter":"2 Built-in Data Types","heading":"2.3 Boolean","text":"","code":"b = False\n\nif (b):\n    print ('It is true')\nelse:\n    print ('It is fake')## It is fake"},{"path":"built-in-data-types.html","id":"what-is-considered-false","chapter":"2 Built-in Data Types","heading":"2.3.1 What is Considered False ?","text":"Everything false, anything else true","code":"print ( bool(0),      # zero\n        bool(None),  # none\n        bool(''),    # empty string\n        bool([]),    # empty list\n        bool(()),    # empty tupple\n        bool(False), # False\n        bool(2-2))    # expression that return any value above## False False False False False False False"},{"path":"built-in-data-types.html","id":"and-operator","chapter":"2 Built-in Data Types","heading":"2.3.2 and operator","text":"BEWARE !can return different data typesIf evaluated result True, last True Value returned (python need evaluate last value)evaluated result False, first False Value returned (python return immediately detecting False value)","code":"print (123 and 2 and 1,\n       123 and [] and 2)## 1 []"},{"path":"built-in-data-types.html","id":"not-operator","chapter":"2 Built-in Data Types","heading":"2.3.3 not operator","text":"","code":"not (True)## Falsenot (True or False)## Falsenot (False)## Truenot (True and False)## True~(False)## -1"},{"path":"built-in-data-types.html","id":"or-operator","chapter":"2 Built-in Data Types","heading":"2.3.4 or operator","text":"can return different data typeIf evaluated result True, first True Value returned (right hand side value need evaluated)evaluated result False, last Fasle Value returned (need evalute items concluding False)","code":"print (1 or 2)## 1print (0 or 1 or 1)## 1print (0 or () or [])## []"},{"path":"built-in-data-types.html","id":"none","chapter":"2 Built-in Data Types","heading":"2.4 None","text":"","code":""},{"path":"built-in-data-types.html","id":"none-is-an-object","chapter":"2 Built-in Data Types","heading":"2.4.1 None is an Object","text":"None Python object NonTypeAny operation None object result errorFor array data None elements, verification required check iteration determine item None. computaionaly heavy","code":"type(None)## <class 'NoneType'>import numpy as np\n\nt1 = np.array([1, 2, 3, 4, 5])\nt2= np.array([1, 2, 3, None, 4, 5])\nprint( t1.dtype  , '\\n\\n',    # it's an object\n       t2.dtype)## int32 \n## \n##  object"},{"path":"built-in-data-types.html","id":"comparing-none","chapter":"2 Built-in Data Types","heading":"2.4.2 Comparing None","text":"Prefered MethodPrefered","code":"null_variable = None\nprint( null_variable == None )## Trueprint( null_variable is None )## Trueprint( null_variable is not None )## False"},{"path":"built-in-data-types.html","id":"operation-on-none","chapter":"2 Built-in Data Types","heading":"2.4.3 Operation on None","text":"operator (except ) None results error.","code":"None & None## Error in py_call_impl(callable, dots$args, dots$keywords): TypeError: unsupported operand type(s) for &: 'NoneType' and 'NoneType'"},{"path":"datetime-standard-library.html","id":"datetime-standard-library","chapter":"3 datetime Standard Library","heading":"3 datetime Standard Library","text":"built-library Python. need install library.","code":""},{"path":"datetime-standard-library.html","id":"iso8601","chapter":"3 datetime Standard Library","heading":"3.1 ISO8601","text":"https://en.wikipedia.org/wiki/ISO_8601#Time_zone_designators","code":""},{"path":"datetime-standard-library.html","id":"date-time","chapter":"3 datetime Standard Library","heading":"3.1.1 Date Time","text":"UTC:   \"2007-04-05T14:30Z\"      #notice Z GMT+8:  \"2007-04-05T12:30+08:00  #notice +08:00 GMT+8:  \"2007-04-05T12:30+0800   #notice +0800 GMT+8:  \"2007-04-05T12:30+08     #notice +08","code":""},{"path":"datetime-standard-library.html","id":"date","chapter":"3 datetime Standard Library","heading":"3.1.2 Date","text":"2019-02-04 #notice timezone available","code":""},{"path":"datetime-standard-library.html","id":"module-import","chapter":"3 datetime Standard Library","heading":"3.2 Module Import","text":"","code":"from datetime import date     # module for date object\nfrom datetime import time     # module for time object\nfrom datetime import datetime # module for datetime object\nfrom datetime import timedelta"},{"path":"datetime-standard-library.html","id":"class","chapter":"3 datetime Standard Library","heading":"3.3 Class","text":"datetime library contain three class objects:\n- date (year,month,day)\n- time (hour,minute,second)\n- datetime (year,month,day,hour,minute,second)\n- timedelta: duration two datetime date object","code":""},{"path":"datetime-standard-library.html","id":"date-1","chapter":"3 datetime Standard Library","heading":"3.4 date","text":"","code":""},{"path":"datetime-standard-library.html","id":"constructor-1","chapter":"3 datetime Standard Library","heading":"3.4.1 Constructor","text":"","code":"print( date(2000,1,1) )## 2000-01-01print( date(year=2000,month=1,day=1) )## 2000-01-01print( type(date(year=2000,month=1,day=1)))## <class 'datetime.date'>"},{"path":"datetime-standard-library.html","id":"class-method","chapter":"3 datetime Standard Library","heading":"3.4.2 Class Method","text":"","code":""},{"path":"datetime-standard-library.html","id":"today","chapter":"3 datetime Standard Library","heading":"3.4.2.1 today","text":"local date (UTC)","code":"date.today()## datetime.date(2022, 12, 29)print( date.today() )## 2022-12-29"},{"path":"datetime-standard-library.html","id":"convert-from-iso-fromisoformat","chapter":"3 datetime Standard Library","heading":"3.4.2.2 Convert From ISO fromisoformat","text":"strptime available date conversion. datetime conversionTo convert non-iso format date string date object, convert datetime first, date","code":"date.fromisoformat('2011-11-11')## datetime.date(2011, 11, 11)"},{"path":"datetime-standard-library.html","id":"instance-method","chapter":"3 datetime Standard Library","heading":"3.4.3 Instance Method","text":"","code":""},{"path":"datetime-standard-library.html","id":"replace","chapter":"3 datetime Standard Library","heading":"3.4.3.1 replace()","text":"Replace year/month/day specified parameter, non specified params remain unchange.Example change month. can change year day combination","code":"print( date.today() )## 2022-12-29print( date.today().replace(month=8) )## 2022-08-29"},{"path":"datetime-standard-library.html","id":"weekday-isoweekday","chapter":"3 datetime Standard Library","heading":"3.4.3.2 weekday(), isoweekday()","text":"weekday(), Zero Monday\nisoweekday(), Zero Sunday","code":"print( date.today().weekday() )## 3print( date.today().isoweekday() )## 4weekdays = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']\nwd = date.today().weekday()\nprint( date.today(), \"is day\", wd ,\"which is\", weekdays[wd] )## 2022-12-29 is day 3 which is Thu"},{"path":"datetime-standard-library.html","id":"formating-with-isoformat","chapter":"3 datetime Standard Library","heading":"3.4.3.3 Formating with isoformat()","text":"isoformat() return ISO 8601 String (YYYY-MM-DD)","code":"date.today().isoformat() # return string## '2022-12-29'"},{"path":"datetime-standard-library.html","id":"formating-with-strftime","chapter":"3 datetime Standard Library","heading":"3.4.3.4 Formating with strftime","text":"complete directive, see :https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior","code":"date.today().strftime(\"%m/%d\")## '12/29'"},{"path":"datetime-standard-library.html","id":"isocalendar","chapter":"3 datetime Standard Library","heading":"3.4.3.5 isocalendar()","text":"isocalendar return 3-tuple, (ISO year, ISO week number, ISO weekday).","code":"date.today().isocalendar() ## return tuple ## datetime.IsoCalendarDate(year=2022, week=52, weekday=4)"},{"path":"datetime-standard-library.html","id":"attributes","chapter":"3 datetime Standard Library","heading":"3.4.4 Attributes","text":"","code":"print( date.today().year )## 2022print( date.today().month )## 12print( date.today().day )## 29"},{"path":"datetime-standard-library.html","id":"date-and-datetime","chapter":"3 datetime Standard Library","heading":"3.5 date and datetime","text":"","code":""},{"path":"datetime-standard-library.html","id":"constructor-2","chapter":"3 datetime Standard Library","heading":"3.5.1 Constructor","text":"","code":"import datetime as dt\n\nprint( \n    dt.date(2000,1,1,), '\\n',\n    dt.datetime(2000,1,1,0,0,0), '\\n',\n    dt.datetime(year=2000,month=1,day=1,hour=23,minute=15,second=55),'\\n',\n    type(dt.date(2000,1,1)),'\\n',\n    type(dt.datetime(2000,1,1,0,0,0)))## 2000-01-01 \n##  2000-01-01 00:00:00 \n##  2000-01-01 23:15:55 \n##  <class 'datetime.date'> \n##  <class 'datetime.datetime'>"},{"path":"datetime-standard-library.html","id":"class-method-1","chapter":"3 datetime Standard Library","heading":"3.5.2 Class Method","text":"","code":""},{"path":"datetime-standard-library.html","id":"now-and-today","chapter":"3 datetime Standard Library","heading":"3.5.2.1 now and today","text":"now() today() return current system local datetime, timezone","code":"print(  dt.datetime.now(), '\\n',\n        dt.datetime.now().date())## 2022-12-29 14:51:46.832852 \n##  2022-12-29dt.datetime.today()## datetime.datetime(2022, 12, 29, 14, 51, 47, 365292)"},{"path":"datetime-standard-library.html","id":"utcnow","chapter":"3 datetime Standard Library","heading":"3.5.2.2 utcnow","text":"","code":"dt.datetime.utcnow()## datetime.datetime(2022, 12, 29, 6, 51, 47, 903590)"},{"path":"datetime-standard-library.html","id":"combine-date-and-time","chapter":"3 datetime Standard Library","heading":"3.5.2.3 combine() date and time","text":"Apply datetime.combine() module method date time object get datetime","code":"now = dt.datetime.now()\ndt.datetime.combine(now.date(), now.time())## datetime.datetime(2022, 12, 29, 14, 51, 48, 417834)"},{"path":"datetime-standard-library.html","id":"convert-from-string-strptime","chapter":"3 datetime Standard Library","heading":"3.5.2.4 Convert from String strptime()","text":"Use strptime convert string datetime object","code":"%I : 12-hour\n%H : 24-hour\n%M : Minute\n%p : AM/PM\n%y : 18\n%Y : 2018\n%b : Mar\n%m : month (1 to 12)\n%d : daydatetime.strptime('2011-02-25','%Y-%m-%d')## datetime.datetime(2011, 2, 25, 0, 0)datetime.strptime('9-01-18','%d-%m-%y')## datetime.datetime(2018, 1, 9, 0, 0)datetime.strptime('09-Mar-2018','%d-%b-%Y')## datetime.datetime(2018, 3, 9, 0, 0)datetime.strptime('2/5/2018 4:49 PM', '%m/%d/%Y %I:%M %p')## datetime.datetime(2018, 2, 5, 16, 49)"},{"path":"datetime-standard-library.html","id":"convert-from-iso-fromisoformat-1","chapter":"3 datetime Standard Library","heading":"3.5.2.5 Convert from ISO fromisoformat","text":"fromisoformat() intend reverse isoformat()actually ISO compliance: Z +8 included end string, error occur","code":"#s = dt.datetime.now().isoformat()\ndt.datetime.fromisoformat(\"2019-02-05T10:22:33\")## datetime.datetime(2019, 2, 5, 10, 22, 33)"},{"path":"datetime-standard-library.html","id":"instance-method-1","chapter":"3 datetime Standard Library","heading":"3.5.3 Instance Method","text":"","code":""},{"path":"datetime-standard-library.html","id":"weekday","chapter":"3 datetime Standard Library","heading":"3.5.3.1 weekday","text":"","code":"datetime.now().weekday()## 3"},{"path":"datetime-standard-library.html","id":"replace-1","chapter":"3 datetime Standard Library","heading":"3.5.3.2 replace","text":"","code":"datetime.now().replace(year=1999)## datetime.datetime(1999, 12, 29, 14, 51, 52, 355392)"},{"path":"datetime-standard-library.html","id":"convert-to-.time","chapter":"3 datetime Standard Library","heading":"3.5.3.3 convert to .time()","text":"","code":"datetime.now().time()## datetime.time(14, 51, 52, 911623)"},{"path":"datetime-standard-library.html","id":"convert-to-.date","chapter":"3 datetime Standard Library","heading":"3.5.3.4 Convert to .date()","text":"","code":"datetime.now().date()## datetime.date(2022, 12, 29)"},{"path":"datetime-standard-library.html","id":"convert-to-string","chapter":"3 datetime Standard Library","heading":"3.5.3.5 Convert to String","text":"strUse strftime()Use isoformat()","code":"str( datetime.now() )## '2022-12-29 14:51:54.031238'dt.datetime.now().strftime('%d-%b-%Y')## '29-Dec-2022'dt.datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%S.%fZ')  ## ISO 8601 UTC## '2022-12-29T06:51:55.187293Z'dt.datetime.utcnow().isoformat()## '2022-12-29T06:51:55.720954'"},{"path":"datetime-standard-library.html","id":"attributes-1","chapter":"3 datetime Standard Library","heading":"3.5.4 Attributes","text":"","code":"print( datetime.now().year )## 2022print( datetime.now().month )## 12print( datetime.now().day )## 29print( datetime.now().hour )## 14print( datetime.now().minute )## 51"},{"path":"datetime-standard-library.html","id":"time","chapter":"3 datetime Standard Library","heading":"3.6 time","text":"","code":""},{"path":"datetime-standard-library.html","id":"constructor-3","chapter":"3 datetime Standard Library","heading":"3.6.1 Constructor","text":"","code":"print( time(2) )    #default single arugement, hour## 02:00:00print( time(2,15) ) #default two arguments, hour, minute## 02:15:00print( time(hour=2,minute=15,second=30) )## 02:15:30"},{"path":"datetime-standard-library.html","id":"class-method-2","chapter":"3 datetime Standard Library","heading":"3.6.2 Class Method","text":"","code":""},{"path":"datetime-standard-library.html","id":"now","chapter":"3 datetime Standard Library","heading":"3.6.2.1 now()","text":"unfortunately single function extract current time. Use time() function datetime object","code":"datetime.now().time()## datetime.time(14, 51, 57, 279151)"},{"path":"datetime-standard-library.html","id":"attributes-2","chapter":"3 datetime Standard Library","heading":"3.6.3 Attributes","text":"","code":"print( datetime.now().time().hour )## 14print( datetime.now().time().minute )## 51print( datetime.now().time().second )## 57"},{"path":"datetime-standard-library.html","id":"timedelta","chapter":"3 datetime Standard Library","heading":"3.7 timedelta","text":"years argument supportedApply timedelta datetime objecttimedelta applied time object , timedelta potentially go beyond single day (24H)","code":"delt = timedelta(days=365,minutes=33,seconds=15)now = datetime.now()\nprint ('delt+now : ', now+delt)## delt+now :  2023-12-29 15:25:13.746457"},{"path":"built-in-data-structure.html","id":"built-in-data-structure","chapter":"4 Built-In Data Structure","heading":"4 Built-In Data Structure","text":"","code":""},{"path":"built-in-data-structure.html","id":"tuple","chapter":"4 Built-In Data Structure","heading":"4.1 Tuple","text":"Tuple immutable list. attempt change/update tuple return error. can contain different types object just like list.Benefits tuple List :Tuple Faster listTuple Protects data accidental changeCan used key dictionaries, list can’t","code":""},{"path":"built-in-data-structure.html","id":"creation","chapter":"4 Built-In Data Structure","heading":"4.1.1 Creation","text":"Tuple created assignment without brackets. create tuple list, use tuple() constructor.","code":"t1 = (1,2,3,'o',(4,5,6))                   ## with brackets\nt2 = 1,2,3,'o','apple', (4,5,6)            ## without brackets\nt3 = tuple([1,2,3,'o','apple', (4,5,6)])   ## create from list using constructor\n\nprint(type(t1), type(t2), type(t3))## <class 'tuple'> <class 'tuple'> <class 'tuple'>"},{"path":"built-in-data-structure.html","id":"accessor","chapter":"4 Built-In Data Structure","heading":"4.1.2 Accessor","text":"Assessing single element returns element. Assessing range elements returns tuple.","code":"print( t1[0], t1[1:3] )## 1 (2, 3)"},{"path":"built-in-data-structure.html","id":"copy-and-clone","chapter":"4 Built-In Data Structure","heading":"4.1.3 Copy and Clone","text":"Use normal assignment = duplicate. Reference memory address copied. Data actually duplicated memory. clone tuple (different ID), convert list back tuple .","code":"## Copy actually points to the same memory location\noriginal   = (1,2,3,4,5)\ncopy_test  = original\nclone_test = tuple(list(original)) ## convert to list then back to tuple\n\n## The copy refers to the same content\nprint(original)## (1, 2, 3, 4, 5)print(copy_test)## (1, 2, 3, 4, 5)print(clone_test)\n\n## Copy and original has the same memory location.## (1, 2, 3, 4, 5)print('Original ID: ', id(original))## Original ID:  2462233379680print('Copy ID:     ', id(copy_test))## Copy ID:      2462233379680print('Clone ID:    ', id(clone_test))  ## clone has different ID## Clone ID:     2462233636512"},{"path":"built-in-data-structure.html","id":"list","chapter":"4 Built-In Data Structure","heading":"4.2 List","text":"List collection ordered items, items can different data typesYou can pack list items placing []List mutable","code":""},{"path":"built-in-data-structure.html","id":"creation-1","chapter":"4 Built-In Data Structure","heading":"4.2.1 Creation","text":"","code":"## Create Empty List\nempty = []      # literal assignment method\nempty = list()  # constructor method\n\nmultiple = [123,'abc',456, None] ## multiple datatypes allowed\nstr_list = list('hello')         ## [split into h,e,l,l,o]\n\nmultiple\nstr_list## [123, 'abc', 456, None]\n## ['h', 'e', 'l', 'l', 'o']"},{"path":"built-in-data-structure.html","id":"accessor-1","chapter":"4 Built-In Data Structure","heading":"4.2.2 Accessor","text":"Use [] specify single range objects return. Index numner starts 0.","code":"food = ['bread', 'noodle', 'rice', 'biscuit','jelly','cake']\n\n## Accessing Single Index, Returns Object\nfood[2]  # 3rd item\nfood[-1] # last item\n\n## Accessing Range Of Indexes, Return List\nfood[:4]     # first 3 items\nfood[-3:]    # last 3 items\nfood[1:5]    # item 1 to 4\nfood[5:2:-1] # item 3 to 5, reverse order\nfood[::-1]   # reverse order## 'rice'\n## 'cake'\n## ['bread', 'noodle', 'rice', 'biscuit']\n## ['biscuit', 'jelly', 'cake']\n## ['noodle', 'rice', 'biscuit', 'jelly']\n## ['cake', 'jelly', 'biscuit']\n## ['cake', 'jelly', 'biscuit', 'rice', 'noodle', 'bread']"},{"path":"built-in-data-structure.html","id":"methods","chapter":"4 Built-In Data Structure","heading":"4.2.3 Methods","text":"methods shown “inplace”, meaning original data changed.Remove Item(s)Removal non-existence item result errorAppendingThere two methods add elements tail. append() adds single element. extend() addes multiple elements.Methods","code":"food = list(['bread', 'noodle', 'rice', 'biscuit','jelly','biscuit','noodle'])\nfood.remove('biscuit')     ## remove first found element\nfood.pop()         ## remove last element, and return it\nfood.pop(1)        ## remove second element, and return it\nfood## 'noodle'\n## 'noodle'\n## ['bread', 'rice', 'jelly', 'biscuit']food.append('durian')        ## add single element to the tail \nfood.extend(['nand','puff']) ## add elements to the tail\nfood## ['bread', 'rice', 'jelly', 'biscuit', 'durian', 'nand', 'puff']## ordering of elements\nfood.reverse()          ## reverse current order\nfood.sort()             ## sort ascending\nfood.sort(reverse=True) ## sort descending\nfood\n\n## methods returning number\nfood.index('biscuit')   ## return the index of first found element\nfood.count('biscuit')   ## return occurance of element## ['rice', 'puff', 'nand', 'jelly', 'durian', 'bread', 'biscuit']\n## 6\n## 1"},{"path":"built-in-data-structure.html","id":"operators","chapter":"4 Built-In Data Structure","heading":"4.2.4 Operators","text":"ConcatenationTwo lists can concatenated using ‘+’ operator.List MutableThe reference list variable won’t change adding/removing itemCopy CloneAssignment another variable always refers data.Use copy() method wish clone data, different ID.Passing Function ReferenceWhen passing list functions, reference passed. Meaning changes list within function reflected outside function.","code":"animals = ['dog','cat','horse'] + ['elephant','tiger'] + ['sheep']id(animals)\nanimals += ['chicken']\nanimals.pop()\nid(animals)  ## ID had not changed## 2462227601728\n## 'chicken'\n## 2462227601728original   = [1,2,3,4,5]      ## original data\ncopy_test  = original         ## same ID as Original\nclone_test = original.copy()  ## different ID\nprint( id(original), id(copy_test), id(clone_test))## 2462233682176 2462233682176 2462233688384my_list = [1,2,3,4,5]\n\ndef func(x):\n    print (x)\n    print('ID in Function:      ', id(x))\n    x.append(6)    ## modify the refrence\n\nmy_list\nid(my_list)\n\nfunc(my_list)  ## passing reference to function\n\nmy_list        ## content was altered\nid(my_list)## [1, 2, 3, 4, 5]\n## 2462233688448\n## [1, 2, 3, 4, 5]\n## ID in Function:       2462233688448\n## [1, 2, 3, 4, 5, 6]\n## 2462233688448"},{"path":"built-in-data-structure.html","id":"iteration","chapter":"4 Built-In Data Structure","heading":"4.2.5 Iteration","text":"LoopList ComprehensionThis code short-form method loop . output list comprehension new list.Code long-version compared list comprehension aboce.","code":"mylist = ['abc','abcd','bcde','bcdee','cdefg']\nfor x in mylist:\n    if 'abc' in x:\n        print (x)## abc\n## abcdold_list = ['abc','abcd','bcde','bcdee','cdefg']\n[x for x in old_list if 'abc' in x]## ['abc', 'abcd']new_list = []\nold_list = ['abc','abcd','bcde','bcdee','cdefg']\nfor x in old_list:\n    if 'abc' in x:\n        new_list.append(x)\n        \nnew_list## ['abc', 'abcd']"},{"path":"built-in-data-structure.html","id":"tuple-conversion","chapter":"4 Built-In Data Structure","heading":"4.2.6 Tuple Conversion","text":"","code":"my_list  = [1,2,3]\nmy_tuple = tuple(my_list)   ## concert to tuple using constructor\n\nmy_list\nmy_tuple## [1, 2, 3]\n## (1, 2, 3)"},{"path":"built-in-data-structure.html","id":"built-in-functions","chapter":"4 Built-In Data Structure","heading":"4.2.7 Built-In Functions","text":"","code":"my_numbers = [1,2,3,5,5,3,2,1]\n\nlen(my_numbers)    ## numner of elements\nmax(my_numbers)    ## maximum value of elements\nsorted(my_numbers) ## sort ascending\nsorted(my_numbers, reverse=True) ## sort descending## 8\n## 5\n## [1, 1, 2, 2, 3, 3, 5, 5]\n## [5, 5, 3, 3, 2, 2, 1, 1]"},{"path":"built-in-data-structure.html","id":"dictionaries","chapter":"4 Built-In Data Structure","heading":"4.3 Dictionaries","text":"Dictionary list index-value items.","code":""},{"path":"built-in-data-structure.html","id":"creation-2","chapter":"4 Built-In Data Structure","heading":"4.3.1 Creation","text":"Simple DictionaryDictionary list","code":"empty_dict    = {}   ## create empty\nanimal_counts = { 'cats' : 2, 'dogs' : 5, 'horses':4}\ntype(animal_counts)\ntype(empty_dict)## <class 'dict'>\n## <class 'dict'>horse_names  = ['Sax','Jack','Ann','Jeep']\nanimal_names = {'cats':   ['Walter','Ra'],\n                'dogs':   ['Jim','Roy','John','Lucky','Row'],\n                'horses': horse_names\n               }\nanimal_names## {'cats': ['Walter', 'Ra'], 'dogs': ['Jim', 'Roy', 'John', 'Lucky', 'Row'], 'horses': ['Sax', 'Jack', 'Ann', 'Jeep']}"},{"path":"built-in-data-structure.html","id":"accessor-2","chapter":"4 Built-In Data Structure","heading":"4.3.2 Accessor","text":"Get KeysGet ValuesAcceess KeyUse [ key ] notation get value. However, return Error key existFor safer approach (return error key doesn’t exist), use get( key ) notation. return None key exist","code":"animal_name_keys = animal_names.keys()\nanimal_name_keys               ## it is a list\n[x for x in animal_name_keys]  ## it is iterable## dict_keys(['cats', 'dogs', 'horses'])\n## ['cats', 'dogs', 'horses']animal_name_values = animal_names.values()\nanimal_name_values               ## it is a list\n[x for x in animal_name_values]  ## values are iterable## dict_values([['Walter', 'Ra'], ['Jim', 'Roy', 'John', 'Lucky', 'Row'], ['Sax', 'Jack', 'Ann', 'Jeep']])\n## [['Walter', 'Ra'], ['Jim', 'Roy', 'John', 'Lucky', 'Row'], ['Sax', 'Jack', 'Ann', 'Jeep']]animal_names['dogs']## ['Jim', 'Roy', 'John', 'Lucky', 'Row']animal_names.get('cow')   ## does not exist, return None\nanimal_names.get('dogs')## ['Jim', 'Roy', 'John', 'Lucky', 'Row']"},{"path":"built-in-data-structure.html","id":"macd","chapter":"4 Built-In Data Structure","heading":"4.3.3 MACD","text":"Update/AppendUse [key] notation update append content element. Use del remove key/value pair.Use clear() erase elements","code":"new_world = {}                                 ## create empty\nnew_world['bacteria'] = ['Ameoba','Fractona']  ## add new key/value\nnew_world['alien']    = ['Ali','Abu']          ## add new key/value\nnew_world\nnew_world['bacteria'] = ['Mutu', 'Aru']        ## Update value\ndel new_world['alien']                         ## delete key/value\nnew_world## {'bacteria': ['Ameoba', 'Fractona'], 'alien': ['Ali', 'Abu']}\n## {'bacteria': ['Mutu', 'Aru']}animal_names.clear()\nanimal_names  ## now an empty dict## {}"},{"path":"built-in-data-structure.html","id":"iteration-1","chapter":"4 Built-In Data Structure","heading":"4.3.4 Iteration","text":"Example shows iterate keys (.keys()), values (.values()) key/values (.items()).","code":"animal_dict = { 'cats' : 2, 'dogs' : 5, 'horses':4}\n\n[ (key,val) for key,val in animal_dict.items()] \n[x for x in animal_dict.values()]  ## values are iterable\n[x for x in animal_dict.keys()]    ## keys are iterable## [('cats', 2), ('dogs', 5), ('horses', 4)]\n## [2, 5, 4]\n## ['cats', 'dogs', 'horses']"},{"path":"built-in-data-structure.html","id":"sets","chapter":"4 Built-In Data Structure","heading":"4.4 Sets","text":"Set unordered collection unique items. Set mutable","code":""},{"path":"built-in-data-structure.html","id":"creation-3","chapter":"4 Built-In Data Structure","heading":"4.4.1 Creation","text":"Set can declared {}, just like list creation uses ‘[]’.Set can created list, converted back list. perfect way make list unique.","code":"myset = {'a','b','c','d','a','b','e','f','g'}\nmyset # notice no repetition values## {'f', 'g', 'd', 'b', 'e', 'a', 'c'}mylist = ['a','b','c','d','a','b','e','f','g']\nmyset = set(mylist)\nmy_unique_list = list(myset)\nprint (\n  'Original List       : ', mylist,\n  '\\nConvert to set      : ', myset,\n  '\\nConvert back to list: ', my_unique_list) # notice no repetition values## Original List       :  ['a', 'b', 'c', 'd', 'a', 'b', 'e', 'f', 'g'] \n## Convert to set      :  {'f', 'd', 'e', 'c', 'b', 'a', 'g'} \n## Convert back to list:  ['f', 'd', 'e', 'c', 'b', 'a', 'g']"},{"path":"built-in-data-structure.html","id":"operators-1","chapter":"4 Built-In Data Structure","heading":"4.4.2 Operators","text":"Membership TestSubset TestSubset Test : <=\nProper Subset Test : <Proper Subset test master set contain least one element subsetUnion using |Intersection using &elments exist left right setDifference using -Remove right left","code":"'a' in myset      # is member ?\n'f' not in myset  # is not member ?## True\n## Falsemysubset = {'d','g'}\nmysubset <= myset## Truemysubset = {'b','a','d','c','e','f','g'}\nprint ('Is Subset : ', mysubset <= myset)\nprint ('Is Proper Subet : ', mysubset < myset)## Is Subset :  True\n## Is Proper Subet :  False{'a','b','c'} | {'a','e','f'}## {'f', 'b', 'e', 'a', 'c'}{'a','b','c','d'} & {'c','d','e','f'}## {'d', 'c'}{'a','b','c','d'} - {'c','d','e','f'}## {'a', 'b'}"},{"path":"control-and-loops.html","id":"control-and-loops","chapter":"5 Control and Loops","heading":"5 Control and Loops","text":"","code":""},{"path":"control-and-loops.html","id":"if-statement","chapter":"5 Control and Loops","heading":"5.1 If Statement","text":"","code":""},{"path":"control-and-loops.html","id":"multiline-if..-statements","chapter":"5 Control and Loops","heading":"5.1.1 Multiline If.. Statements","text":"","code":"price = 102\nif price <100:\n    print ('buy')\nelif price < 110:\n    print ('hold')\nelif price < 120:\n    print ('think about it')\nelse:\n    print ('sell')## holdprint('end of programming')## end of programming"},{"path":"control-and-loops.html","id":"single-line-if-..-statement","chapter":"5 Control and Loops","heading":"5.1.2 Single Line If .. Statement","text":"","code":""},{"path":"control-and-loops.html","id":"if-in-one-statement","chapter":"5 Control and Loops","heading":"5.1.2.1 if … In One Statement","text":"","code":"price = 70\nif price<80: print('buy')## buy"},{"path":"control-and-loops.html","id":"ternary-statemnt","chapter":"5 Control and Loops","heading":"5.1.2.2 Ternary Statemnt","text":"statement return value simple condition","code":"price = 85\n'buy' if (price<80) else 'dont buy'## 'dont buy'"},{"path":"control-and-loops.html","id":"for-loops","chapter":"5 Control and Loops","heading":"5.2 For Loops","text":"","code":""},{"path":"control-and-loops.html","id":"for-..-else-construct","chapter":"5 Control and Loops","heading":"5.2.1 For .. Else Construct","text":"else executed loop completed cyclesIn exmaple, loop encountered break, hence else section executed.","code":"\nmylist = [1,2,3,4,5]\n\nfor i in mylist:\n  print (i)\nelse:\n  print('Hooray, the loop is completed successfully')## 1\n## 2\n## 3\n## 4\n## 5\n## Hooray, the loop is completed successfullyfor i in mylist:\n  if i < 4:\n    print (i)\n  else:\n    print('Oops, I am breaking out half way in the loop')\n    break\nelse:\n  print('Hooray, the loop is completed successfully')## 1\n## 2\n## 3\n## Oops, I am breaking out half way in the loop"},{"path":"control-and-loops.html","id":"loop-thorugh-range","chapter":"5 Control and Loops","heading":"5.2.2 Loop thorugh ‘range’","text":"","code":"for i in range (1,10,2):\n    print ('Odds Number : ',i) ## Odds Number :  1\n## Odds Number :  3\n## Odds Number :  5\n## Odds Number :  7\n## Odds Number :  9"},{"path":"control-and-loops.html","id":"loop-through-list","chapter":"5 Control and Loops","heading":"5.2.3 Loop through ‘list’","text":"","code":""},{"path":"control-and-loops.html","id":"standard-for-loop","chapter":"5 Control and Loops","heading":"5.2.3.1 Standard For Loop","text":"","code":"letters = ['a','b','c','d']\nfor e in letters:\n    print ('Letter : ',e)## Letter :  a\n## Letter :  b\n## Letter :  c\n## Letter :  d"},{"path":"control-and-loops.html","id":"list-comprehension","chapter":"5 Control and Loops","heading":"5.2.3.2 List Comprehension","text":"Iterate existing list, build new list based conditionnew_list = [expression() old_list]Extend list comprehension can extended condition**new_list = [expression() old_list filter()]","code":"s = ['abc','abcd','bcde','bcdee','cdefg']\n[x.upper() for x in s]## ['ABC', 'ABCD', 'BCDE', 'BCDEE', 'CDEFG']old_list    = ['abc','abcd','bcde','bcdee','cdefg']\nmatching = [ x.upper() for x in old_list if 'bcd' in x ]\nprint( matching )## ['ABCD', 'BCDE', 'BCDEE']"},{"path":"control-and-loops.html","id":"loop-through-dictionary","chapter":"5 Control and Loops","heading":"5.2.4 Loop Through ‘Dictionary’","text":"Looping dict picup key","code":"d = {\"x\": 1, \"y\": 2}\nfor key in d:\n    print (key, d[key])## x 1\n## y 2"},{"path":"control-and-loops.html","id":"generators","chapter":"5 Control and Loops","heading":"5.3 Generators","text":"Generator lazy, produce items asked , hence memory efficientGenerator function ‘yield’ instead ‘return’Generator contains one yields statementWhen called, returns object (iterator) start execution immediatelyMethods like iter() next() implemented automatically. can iterate items using next()function yields, function paused control transferred callerLocal variables states remembered successive callsFinally, function terminates, StopIteration raised automatically calls","code":""},{"path":"control-and-loops.html","id":"basic-generator-function","chapter":"5 Control and Loops","heading":"5.3.1 Basic Generator Function","text":"example give clear understanding generator works","code":"def my_gen():\n    n = 1\n    print('This is printed first')\n    # Generator function contains yield statements\n    yield n\n\n    n += 1\n    print('This is printed second')\n    yield n\n\n    n += 1\n    print('This is printed at last')\n    yield na = my_gen()\ntype(a)## <class 'generator'>next(a)## This is printed first\n## 1next(a)## This is printed second\n## 2"},{"path":"control-and-loops.html","id":"useful-generator-fuction","chapter":"5 Control and Loops","heading":"5.3.2 Useful Generator Fuction","text":"Generator useful uses -loop\n- -loop within generator\n- -loop iterate generator","code":"def rev_str(my_str):\n    length = len(my_str)\n    for i in range(length - 1,-1,-1):\n        yield my_str[i]for c in rev_str(\"hello\"):\n     print(c)## o\n## l\n## l\n## e\n## h"},{"path":"control-and-loops.html","id":"generator-expression","chapter":"5 Control and Loops","heading":"5.3.3 Generator Expression","text":"Use () create annonymous generator function","code":"my_list = [1, 3, 6, 10]\na = (x**2 for x in my_list)next(a)## 1next(a)## 9sum(a) # sum the power of 6,10## 136"},{"path":"control-and-loops.html","id":"compare-to-iterator-class","chapter":"5 Control and Loops","heading":"5.3.4 Compare to Iterator Class","text":"Obviously, Generator concise cleaner","code":"class PowTwo:\n    def __init__(self, max = 0):\n        self.max = max\n\n    def __iter__(self):\n        self.n = 0\n        return self\n\n    def __next__(self):\n        if self.n > self.max:\n            raise StopIteration\n\n        result = 2 ** self.n\n        self.n += 1\n        return resultdef PowTwoGen(max = 0):\n    n = 0\n    while n < max:\n        yield 2 ** n\n        n += 1"},{"path":"library-and-functions.html","id":"library-and-functions","chapter":"6 Library and Functions","heading":"6 Library and Functions","text":"Library group functions","code":""},{"path":"library-and-functions.html","id":"package-source","chapter":"6 Library and Functions","heading":"6.1 Package Source","text":"","code":""},{"path":"library-and-functions.html","id":"conda","chapter":"6 Library and Functions","heading":"6.1.1 Conda","text":"Package manager languageInstall binaries","code":""},{"path":"library-and-functions.html","id":"pip-1","chapter":"6 Library and Functions","heading":"6.1.2 PIP","text":"Package manager python onlyCompile sourceStands Pip Installs PackagesPython’s officially-sanctioned package manager, commonly used install packages published Python Package Index (PyPI)pip PyPI governed supported Python Packaging Authority (PyPA).","code":""},{"path":"library-and-functions.html","id":"importing-library","chapter":"6 Library and Functions","heading":"6.2 Importing Library","text":"two methods import library functions:","code":""},{"path":"library-and-functions.html","id":"standalone-namespace","chapter":"6 Library and Functions","heading":"6.2.1 Standalone Namespace","text":"Use aliasing library name. useful conflicting library name","code":"# access function through: libName.functionName\n- import <libName>                        \n\n# access function through: shortName.functionName\n- import <libName> as <shortName>         import math\nmath.sqrt(9)\n\nimport math as m   ## use library shortname\nm.sqrt(9)## 3.0\n## 3.0"},{"path":"library-and-functions.html","id":"global-namespace","chapter":"6 Library and Functions","heading":"6.2.2 Global Namespace","text":"","code":"# all functions available at global namespace\n- from   <libName> import *\n\n# access function through original names\n- from   <libName> import <functionName>      \n\n# access function through custom names\n- from   <libName> import <functionName> as <shortFunctionName>  from math import sqrt\nsqrt(9)\n\nfrom math import sqrt as sq\nsq(9)## 3.0\n## 3.0"},{"path":"library-and-functions.html","id":"functions","chapter":"6 Library and Functions","heading":"6.3 Functions","text":"","code":""},{"path":"library-and-functions.html","id":"define","chapter":"6 Library and Functions","heading":"6.3.1 Define","text":"default, arguments assigned function left right. However, can also specify argument assignment function call. Function can default args value.","code":"def myfun(x,y=3):\n    print ('x:',x)\n    print ('y:',y)\n\nmyfun(5,8)      ## default function read args from left to right\nmyfun (y=8,x=5) ## but we can specific as well\nmyfun (x=5)     ## args x not specified, function assume default=## x: 5\n## y: 8\n## x: 5\n## y: 8\n## x: 5\n## y: 3"},{"path":"library-and-functions.html","id":"list-within-function","chapter":"6 Library and Functions","heading":"6.3.2 List Within Function","text":"Consider function object, variable (some_list) reference. Hence value remembered parameter passed . counter intuitive, always ensure pass arguments function, even though empty list.","code":"def spam (elem, some_list=[]):\n    some_list.append(elem)\n    return some_list\n\nprint (spam(1))\nprint (spam(2,[6]))\nprint (spam(3))\nprint (spam(2,[7]))\nprint (spam(4, []))## [1]\n## [6, 2]\n## [1, 3]\n## [7, 2]\n## [4]"},{"path":"library-and-functions.html","id":"return-statement","chapter":"6 Library and Functions","heading":"6.3.3 Return Statement","text":"Multiple value returned tuple. Use multiple assignment assign multiple variableif return statement, python return None","code":"def bigger(x,y):\n    if (x>y):\n        return x\n    else:\n        return y\n\ndef minmax(x,y,z):\n    return min(x,y,z), max(x,y,z)\n\nbig   = bigger(5,8)\na,b   = minmax(7,8,9)     # multiple assignment\nc     = minmax(7,8,9)     # tuple\n\nprint (big)  ## noolean\nprint (a,b)  ## integer\nprint (c)    ## tuple## 8\n## 7 9\n## (7, 9)def dummy():\n    print ('This is a dummy function, return no value')\n\ndummy() == None## This is a dummy function, return no value\n## True"},{"path":"library-and-functions.html","id":"argument","chapter":"6 Library and Functions","heading":"6.3.4 Argument","text":"Passing many arguments result error.\nPassing little arguments without default value defined also result error.\ndynamic number arguments, see args next section.Function ArgumentBreaking Dict ArgumentBelow example break dict function. However, careful pass extra key function, result error.","code":"def myfun(x,y):\n    print (x)\n    print (y)\n\nmyfun(1,2,3,4,5)\nmyfun(1)## Error in py_call_impl(callable, dots$args, dots$keywords): TypeError: myfun() takes 2 positional arguments but 5 were given## Error in py_call_impl(callable, dots$args, dots$keywords): TypeError: myfun() missing 1 required positional argument: 'y'def myfun(x,y,f):\n    f(x,y)\n\nmyfun('hello',54,print)## hello 54def foo(a,b,c,d=1):\n    print(a, b, c, d)\n\nfoo(**{\"a\":2,\"b\":3,\"c\":4})          ## ok\nfoo(**{\"a\":2,\"b\":3,\"c\":4, \"z\":100}) ## Error, 'z' not recognized## 2 3 4 1## Error in py_call_impl(callable, dots$args, dots$keywords): TypeError: foo() got an unexpected keyword argument 'z'"},{"path":"library-and-functions.html","id":"argument-args","chapter":"6 Library and Functions","heading":"6.3.5 Argument: args","text":"dynamic length argumens captured defined argument overflow args, tuple.Example 1 - tails overflow argsFirst argument goes x, second argument goes y, remaining overflow args.Example 2 - Middle overflow argsExample 3 - goes argsExample 4 - Empty args","code":"def myfun(x,y,*args):\n    print (x)\n    print (y)\n    print (args)     #tuple\n    \nmyfun(1,2,3,4,5,'any')## 1\n## 2\n## (3, 4, 5, 'any')def myfun(x,*args, y=9):\n    print (x)\n    print (y)\n    print (args)     #tuple\n    \nmyfun(1,2,3,4,5)## 1\n## 9\n## (2, 3, 4, 5)def myfun(*args):\n    print (args)     #tuple\n    \nmyfun(1,2,3,4,5)## (1, 2, 3, 4, 5)def myfun(x,y,*args):\n    print (x)\n    print (y)\n    print (args)\n    \nmyfun(1,2)## 1\n## 2\n## ()"},{"path":"library-and-functions.html","id":"argument-kwargs","chapter":"6 Library and Functions","heading":"6.3.6 Argument: kwargs","text":"kwargs dictionaryExample 1 - goes kwargsExample 2 - Tails overflow kwargsFirst param goes x, rest goes kwargs.Mixing args, kwargsAlways put args kwargs, otherwise Error.","code":"def foo(**kwargs):\n    print(kwargs)\n    \nfoo(a=1,b=2,c=3)## {'a': 1, 'b': 2, 'c': 3}def foo(x,**kwargs):\n    print(x)\n    print(kwargs)\n    \nfoo(9,a=1,b=2,c=3)\nfoo(9)              ## empty kwargs dictionary## 9\n## {'a': 1, 'b': 2, 'c': 3}\n## 9\n## {}def foo(x,y=2,*args,**kwargs):\n    print (x,y, args, kwargs)\n    \nfoo(1,2,3,4,5,c=6,d=7)  ## ok\nfoo(1,2,3,c=6,4,5,d=7)  ## ERROR, always puts args before kwargs## positional argument follows keyword argument (<string>, line 5)"},{"path":"built-in-functions-1.html","id":"built-in-functions-1","chapter":"7 Built-in Functions","heading":"7 Built-in Functions","text":"","code":""},{"path":"built-in-functions-1.html","id":"range","chapter":"7 Built-in Functions","heading":"7.1 range","text":"range(X) generates sequence integer objectUse list() convert order view actual sequence dataMore Examples","code":"range (lower_bound, upper_bound, step_size)  \n# lower bound is optional, default = 0\n# upper bound is not included in result\n# step is optional, default = 1r = range(10)     # default lower bound =0, step =1\nprint (type (r))## <class 'range'>print (r)## range(0, 10)print (list(r))## [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]print (list(range(2,8)))    # step not specified, default 1## [2, 3, 4, 5, 6, 7]print ('Odds Number : ' , list(range(1,10,2))) # generate odds number## Odds Number :  [1, 3, 5, 7, 9]"},{"path":"exception-handling.html","id":"exception-handling","chapter":"8 Exception Handling","heading":"8 Exception Handling","text":"try statement works follows:First, try clause (statement(s) try except keywords) executedIf exception occurs, except clause skipped execution try statement finishedIf exception occurs execution try clause, rest clause skipped. type matches exception named except keyword, except clause executed, execution continues try statementIf exception occurs match exception named except clause, passed outer try statements; handler found, unhandled exception execution stops message shown aboveA try statement may one except clause, specify handlers different exceptions.Try-Except-Finally","code":"try:\n    # code that may cause exceptions\n    \nexcept:\n    # code that handle exceptions\n    \nfinally:\n    # code that clean up\n    # this block optional\n    "},{"path":"exception-handling.html","id":"catching-error","chapter":"8 Exception Handling","heading":"8.1 Catching Error","text":"Different exception object different attributes.","code":"try:\n  a = 1 + 'a'\n  \n## catch specific  error  \nexcept TypeError as err:\n  print('I know this error !!!!',\n        '\\n Error: ', err,\n        '\\n Args:  ', err.args,\n        '\\n Type:  ', type(err))\n\n## Catch all other error\nexcept Exception as err:\n  print( 'Error: ', err,\n         '\\nArgs:  ', err.args,\n         '\\nType:  ', type(err))## I know this error !!!! \n##  Error:  unsupported operand type(s) for +: 'int' and 'str' \n##  Args:   (\"unsupported operand type(s) for +: 'int' and 'str'\",) \n##  Type:   <class 'TypeError'>"},{"path":"exception-handling.html","id":"custom-exception","chapter":"8 Exception Handling","heading":"8.2 Custom Exception","text":"","code":"try:\n  raise Exception('bloody', 'hell')  #simulate exception\n\nexcept Exception as err:\n  print( 'Error: ', err,\n         '\\nArgs:  ', err.args,\n         '\\nType:  ', type(err))## Error:  ('bloody', 'hell') \n## Args:   ('bloody', 'hell') \n## Type:   <class 'Exception'>"},{"path":"object-oriented-programming.html","id":"object-oriented-programming","chapter":"9 Object Oriented Programming","heading":"9 Object Oriented Programming","text":"","code":""},{"path":"object-oriented-programming.html","id":"defining-class","chapter":"9 Object Oriented Programming","heading":"9.1 Defining Class","text":"Every function within class must least one parameter - selfUse init constructor function. init optional","code":"class Person:\n  wallet = 0  # \n  def __init__(self, myname,money=0):   # constructor\n      self.name = myname\n      self.wallet=money\n      print('I\\'m in Person Constructor: {}'.format(myname))\n  def say_hi(self):\n      print('Hello, my name is : ', self.name)\n  def say_bye(self):\n      print('Goodbye', Person.ID)\n  def take(self,amount):\n      self.wallet+=amount\n  def balance(self):\n      print('Wallet Balance:',self.wallet)\n  def MakeCry(self):\n      self.Cry()\n      \nclass Kid(Person):\n  def __init__(self, myname, money=0):\n      print('I\\'m in Kid Constructor: {}'.format(myname))\n      super().__init__(myname=myname, money=money)\n  def Cry(self):\n      print('Kid is crying')"},{"path":"object-oriented-programming.html","id":"constructor-4","chapter":"9 Object Oriented Programming","heading":"9.2 Constructor","text":"","code":"p1 = Person('Yong')  ## I'm in Person Constructor: Yongp2 = Person('Gan',200)## I'm in Person Constructor: Ganp3 = Kid('Jolin',50)## I'm in Kid Constructor: Jolin\n## I'm in Person Constructor: Jolin"},{"path":"object-oriented-programming.html","id":"calling-method","chapter":"9 Object Oriented Programming","heading":"9.3 Calling Method","text":"","code":"p1.say_hi()## Hello, my name is :  Yongp1.balance()## Wallet Balance: 0p3.Cry()## Kid is cryingp3.MakeCry()## Kid is cryingp2.say_hi()## Hello, my name is :  Ganp2.balance()## Wallet Balance: 200"},{"path":"object-oriented-programming.html","id":"getting-property","chapter":"9 Object Oriented Programming","heading":"9.4 Getting Property","text":"","code":"p1.wallet## 0p2.wallet## 200"},{"path":"object-oriented-programming.html","id":"setting-property","chapter":"9 Object Oriented Programming","heading":"9.5 Setting Property","text":"","code":"p1.wallet = 900\np1.wallet## 900"},{"path":"decorator.html","id":"decorator","chapter":"10 Decorator","heading":"10 Decorator","text":"","code":""},{"path":"decorator.html","id":"definition","chapter":"10 Decorator","heading":"10.1 Definition","text":"Decorator function accept callable argumentThe main purpose decarator enhance program decorated functionIt returns callable","code":""},{"path":"decorator.html","id":"examples","chapter":"10 Decorator","heading":"10.2 Examples","text":"","code":""},{"path":"decorator.html","id":"example-1---plain-decorator-function","chapter":"10 Decorator","heading":"10.2.1 Example 1 - Plain decorator function","text":"Many times, useful register function elsewhere - example, registering task task runner, functin signal handlerregister decarator, accept decorated argumentfoo() bar() decorated function register","code":"registry = []\n\ndef register(decorated):\n    registry.append(decorated)\n    return decorated\n\n@register\ndef foo():\n    return 3\n\n@register\ndef bar():\n    return 5registry## [<function foo at 0x000002CA5C5F8700>, <function bar at 0x000002CA5C6475E0>]registry[0]()## 3registry[1]()## 5"},{"path":"decorator.html","id":"example-2---decorator-with-class","chapter":"10 Decorator","heading":"10.2.2 Example 2 - Decorator with Class","text":"Extending use case aboveregister decarator, one argumentThe decorator decorate two functions, object bObserve result","code":"class Registry(object):\n    def __init__(self):\n        self._functions = []\n    def register(self,decorated):\n        self._functions.append(decorated)\n        return decorated\n    def run_all(self,*args,**kwargs):\n        return_values = []\n        for func in self._functions:\n            return_values.append(func(*args,**kwargs))\n        return return_valuesa = Registry()\nb = Registry()\n\n@a.register\ndef foo(x=3):\n    return x\n\n@b.register\ndef bar(x=5):\n    return x\n\n@a.register\n@b.register\ndef bax(x=7):\n    return xprint (a._functions)## [<function foo at 0x000002CA5C647670>, <function bax at 0x000002CA5C647940>]print (b._functions)## [<function bar at 0x000002CA5C6478B0>, <function bax at 0x000002CA5C647940>]print (a.run_all())## [3, 7]print (b.run_all())## [5, 7]print ( a.run_all(x=9) )## [9, 9]print ( b.run_all(x=9) )## [9, 9]"},{"path":"matplotlib.html","id":"matplotlib","chapter":"11 matplotlib","heading":"11 matplotlib","text":"","code":""},{"path":"matplotlib.html","id":"library","chapter":"11 matplotlib","heading":"11.1 Library","text":"","code":"import matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n\nfrom plydata import define, query, select, group_by, summarize, arrange, head, rename\nimport plotnine\nfrom plotnine import *\n\nimport os\nos.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = \"C:\\ProgramData\\Anaconda3\\Library\\plugins\\platforms\""},{"path":"matplotlib.html","id":"sample-data","chapter":"11 matplotlib","heading":"11.2 Sample Data","text":"chapter uses sample data generate code. idea simulate two categorical-alike feature, two numeric value feature:com random character ?C1?, ?C2? ?C3?dept random character ?D1?, ?D2?, ?D3?, ?D4? ?D5?grp random character randomly generated ?G1?, ?G2?value1 represents numeric value, normally distributed mean 50value2 numeric value, normally distributed mean 25","code":"n = 200\ncomp = ['C' + i for i in np.random.randint( 1,4, size  = n).astype(str)] # 3x Company\ndept = ['D' + i for i in np.random.randint( 1,6, size  = n).astype(str)] # 5x Department\ngrp =  ['G' + i for i in np.random.randint( 1,3, size  = n).astype(str)] # 2x Groups\nvalue1 = np.random.normal( loc=50 , scale=5 , size = n)\nvalue2 = np.random.normal( loc=20 , scale=3 , size = n)\nvalue3 = np.random.normal( loc=5 , scale=30 , size = n)\n\nmydf = pd.DataFrame({\n    'comp':comp, \n    'dept':dept, \n    'grp': grp,\n    'value1':value1, \n    'value2':value2,\n    'value3':value3 })\nmydf.head()##   comp dept grp     value1     value2     value3\n## 0   C3   D4  G1  51.658816  20.475950   7.924439\n## 1   C1   D5  G2  55.275038  25.379146  -4.089964\n## 2   C3   D3  G1  48.096090  18.799671  18.013139\n## 3   C1   D5  G2  56.402108  21.478002   2.004319\n## 4   C2   D5  G1  55.537266  17.310106 -27.548142mydf.info()## <class 'pandas.core.frame.DataFrame'>\n## RangeIndex: 200 entries, 0 to 199\n## Data columns (total 6 columns):\n##  #   Column  Non-Null Count  Dtype  \n## ---  ------  --------------  -----  \n##  0   comp    200 non-null    object \n##  1   dept    200 non-null    object \n##  2   grp     200 non-null    object \n##  3   value1  200 non-null    float64\n##  4   value2  200 non-null    float64\n##  5   value3  200 non-null    float64\n## dtypes: float64(3), object(3)\n## memory usage: 9.5+ KB"},{"path":"matplotlib.html","id":"matlab-like-api","chapter":"11 matplotlib","heading":"11.3 MATLAB-like API","text":"good thing pylab MATLAB-style API easy get started familiar MATLAB, minumum coding overhead simple plots.However, ’d encourrage using MATLAB compatible API anything simplest figures.Instead, recommend learning using matplotlib’s object-oriented plotting API. remarkably powerful. advanced figures subplots, insets components nice work .","code":""},{"path":"matplotlib.html","id":"sample-data-1","chapter":"11 matplotlib","heading":"11.3.1 Sample Data","text":"","code":"# Sample Data\nx = np.linspace(0,5,10)\ny = x ** 2"},{"path":"matplotlib.html","id":"single-plot","chapter":"11 matplotlib","heading":"11.3.2 Single Plot","text":"","code":"plt.figure()\nplt.xlabel('x')\nplt.ylabel('y')\nplt.plot(x,y,'red')\nplt.title('My Good Data')\nplt.show()"},{"path":"matplotlib.html","id":"multiple-subplots","chapter":"11 matplotlib","heading":"11.3.3 Multiple Subplots","text":"call lto subplot() create new container subsequent plot command","code":"plt.figure()\nplt.subplot(1,2,1) # 1 row, 2 cols, at first box\nplt.plot(x,y,'r--')\nplt.subplot(1,2,2) # 1 row, 2 cols, at second box\nplt.plot(y,x,'g*-')\nplt.show()"},{"path":"matplotlib.html","id":"object-oriented-api","chapter":"11 matplotlib","heading":"11.4 Object-Oriented API","text":"","code":""},{"path":"matplotlib.html","id":"sample-data-2","chapter":"11 matplotlib","heading":"11.4.1 Sample Data","text":"","code":"# Sample Data\nx = np.linspace(0,5,10)\ny = x ** 2"},{"path":"matplotlib.html","id":"single-plot-1","chapter":"11 matplotlib","heading":"11.4.2 Single Plot","text":"One figure, one axes","code":"fig = plt.figure()\naxes = fig.add_axes([0,0,1,1]) # left, bottom, width, height (range 0 to 1)\naxes.plot(x, y, 'r')\naxes.set_xlabel('x')\naxes.set_ylabel('y')\naxes.set_title('title')\nplt.show()"},{"path":"matplotlib.html","id":"multiple-axes-in-one-plot","chapter":"11 matplotlib","heading":"11.4.3 Multiple Axes In One Plot","text":"still considered single plot, multiple axes","code":"fig = plt.figure()\nax1 = fig.add_axes([0, 0, 1, 1])         # main axes\nax2 = fig.add_axes([0.2, 0.5, 0.4, 0.3]) # inset axes\n\nax1.plot(x,y,'r')\nax1.set_xlabel('x')\nax1.set_ylabel('y')\n\nax2.plot(y, x, 'g')\nax2.set_xlabel('y')\nax2.set_ylabel('x')\nax2.set_title('insert title')\nplt.show()"},{"path":"matplotlib.html","id":"multiple-subplots-1","chapter":"11 matplotlib","heading":"11.4.4 Multiple Subplots","text":"One figure can contain multiple subplotsEach subplot one axes","code":""},{"path":"matplotlib.html","id":"simple-subplots---all-same-size","chapter":"11 matplotlib","heading":"11.4.4.1 Simple Subplots - all same size","text":"subplots() function return axes object iterable.Single Row Grid\nSingle row grid means axes 1-D array. Hence can use iterate axesMultiple Row Grid\nMultile row grid means axes 2-D array. Hence can use two levels loop iterate row column","code":"fig, axes = plt.subplots( nrows=1,ncols=3 )\nprint (axes.shape)## (3,)for ax in axes:\n    ax.plot(x, y, 'r')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_title('title')\n    ax.text(0.2,0.5,'One')\nplt.show()fig, axes = plt.subplots(2, 3, sharex='col', sharey='row')\nprint (axes.shape)## (2, 3)for i in range(axes.shape[0]):\n    for j in range(axes.shape[1]):\n        axes[i, j].text(0.5, 0.5, str((i, j)),\n                      fontsize=18, ha='center')\nplt.show()"},{"path":"matplotlib.html","id":"complicated-subplots---different-size","chapter":"11 matplotlib","heading":"11.4.4.2 Complicated Subplots - different size","text":"GridSpec specify grid size figureManually specify subplot relevant grid position size-1 means last row column","code":"plt.figure(figsize=(5,5))\ngrid = plt.GridSpec(2, 3, hspace=0.4, wspace=0.4)\nplt.subplot(grid[0, 0])  #row 0, col 0\nplt.subplot(grid[0, 1:]) #row 0, col 1 to :\nplt.subplot(grid[1, :2]) #row 1, col 0:2 \nplt.subplot(grid[1, 2]); #row 1, col 2\nplt.show()plt.figure(figsize=(5,5))\ngrid = plt.GridSpec(4, 4, hspace=0.8, wspace=0.4)\nplt.subplot(grid[:3, 0])    # row 0:3, col 0\nplt.subplot(grid[:3, 1: ])  # row 0:3, col 1:\nplt.subplot(grid[3, 1: ]);  # row 3,   col 1:\nplt.show()plt.figure(figsize=(6,6))\ngrid = plt.GridSpec(4, 4, hspace=0.4, wspace=1.2)\nplt.subplot(grid[:-1, 0 ])  # row 0 till last row (not including last row), col 0\nplt.subplot(grid[:-1, 1:])  # row 0 till last row (not including last row), col 1 till end\nplt.subplot(grid[-1, 1: ]); # row last row, col 1 till end\nplt.show()"},{"path":"matplotlib.html","id":"figure-customization","chapter":"11 matplotlib","heading":"11.4.5 Figure Customization","text":"","code":""},{"path":"matplotlib.html","id":"avoid-overlap---use-tight_layout","chapter":"11 matplotlib","heading":"11.4.5.1 Avoid Overlap - Use tight_layout()","text":"Sometimes figure size small, plots overlap .\n- tight_layout() introduce extra white space subplots avoid overlap.\n- figure became wider.","code":"fig, axes = plt.subplots( nrows=1,ncols=2)\nfor ax in axes:\n    ax.plot(x, y, 'r')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_title('title')\nfig.tight_layout() # adjust the positions of axes so that there is no overlap\nplt.show()"},{"path":"matplotlib.html","id":"avoid-overlap---change-figure-size","chapter":"11 matplotlib","heading":"11.4.5.2 Avoid Overlap - Change Figure Size","text":"","code":"fig, axes = plt.subplots( nrows=1,ncols=2,figsize=(12,3))\nfor ax in axes:\n    ax.plot(x, y, 'r')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_title('title')\nplt.show()"},{"path":"matplotlib.html","id":"text-within-figure","chapter":"11 matplotlib","heading":"11.4.5.3 Text Within Figure","text":"","code":"fig = plt.figure()\nfig.text(0.5, 0.5, 'This Is A Sample',fontsize=18, ha='center');\naxes = fig.add_axes([0,0,1,1]) # left, bottom, width, height (range 0 to 1)\nplt.show()"},{"path":"matplotlib.html","id":"axes-customization","chapter":"11 matplotlib","heading":"11.4.6 Axes Customization","text":"","code":""},{"path":"matplotlib.html","id":"y-axis-limit","chapter":"11 matplotlib","heading":"11.4.6.1 Y-Axis Limit","text":"","code":"fig = plt.figure()\nfig.add_axes([0,0,1,1], ylim=(-2,5));\nplt.show()"},{"path":"matplotlib.html","id":"text-within-axes","chapter":"11 matplotlib","heading":"11.4.6.2 Text Within Axes","text":"","code":"fig, ax = plt.subplots(2, 3, sharex='col', sharey='row')\nfor i in range(2):\n    for j in range(3):\n        ax[i, j].text(0.5, 0.5, str((i, j)),\n                      fontsize=18, ha='center')\nplt.show()plt.text(0.5, 0.5, 'one',fontsize=18, ha='center')\nplt.show()"},{"path":"matplotlib.html","id":"share-y-axis-label","chapter":"11 matplotlib","heading":"11.4.6.3 Share Y Axis Label","text":"","code":"fig, ax = plt.subplots(2, 3, sharex='col', sharey='row') # removed inner label\nplt.show()"},{"path":"matplotlib.html","id":"create-subplot-individually","chapter":"11 matplotlib","heading":"11.4.6.4 Create Subplot Individually","text":"call lto subplot() create new container subsequent plot commandIterate subplots (ax) populate ","code":"plt.subplot(2,4,1)\nplt.text(0.5, 0.5, 'one',fontsize=18, ha='center')\n\nplt.subplot(2,4,8)\nplt.text(0.5, 0.5, 'eight',fontsize=18, ha='center')\nplt.show()fig, ax = plt.subplots(2, 3, sharex='col', sharey='row')\nfor i in range(2):\n    for j in range(3):\n        ax[i, j].text(0.5, 0.5, str((i, j)),\n                      fontsize=18, ha='center')\nplt.show()"},{"path":"matplotlib.html","id":"histogram","chapter":"11 matplotlib","heading":"11.5 Histogram","text":"","code":"plt.hist(mydf.value1, bins=12);\nplt.show()"},{"path":"matplotlib.html","id":"scatter-plot","chapter":"11 matplotlib","heading":"11.6 Scatter Plot","text":"","code":"plt.scatter(mydf.value1, mydf.value2)\nplt.show()"},{"path":"matplotlib.html","id":"bar-chart","chapter":"11 matplotlib","heading":"11.7 Bar Chart","text":"","code":"com_grp = mydf.groupby('comp')\ngrpdf = com_grp['value1'].sum().reset_index()\ngrpdf##   comp       value1\n## 0   C1  2880.956907\n## 1   C2  3868.237073\n## 2   C3  3182.548585plt.bar(grpdf.comp, grpdf.value1);\nplt.xlabel('Company')\nplt.ylabel('Sum of Value 1')\nplt.show()"},{"path":"seaborn.html","id":"seaborn","chapter":"12 seaborn","heading":"12 seaborn","text":"","code":""},{"path":"seaborn.html","id":"seaborn-and-matplotlib","chapter":"12 seaborn","heading":"12.1 Seaborn and Matplotlib","text":"seaborn returns matplotlib object can modified options pyplot moduleOften, options wrapped seaborn .plot() pandas available arguments","code":""},{"path":"seaborn.html","id":"sample-data-3","chapter":"12 seaborn","heading":"12.2 Sample Data","text":"","code":"n = 100\ncomp = ['C' + i for i in np.random.randint( 1,4, size  = n).astype(str)] # 3x Company\ndept = ['D' + i for i in np.random.randint( 1,4, size  = n).astype(str)] # 5x Department\ngrp =  ['G' + i for i in np.random.randint( 1,4, size  = n).astype(str)] # 2x Groups\nvalue1 = np.random.normal( loc=50 , scale=5 , size = n)\nvalue2 = np.random.normal( loc=20 , scale=3 , size = n)\nvalue3 = np.random.normal( loc=5 , scale=30 , size = n)\n\nmydf = pd.DataFrame({\n    'comp':comp, \n    'dept':dept, \n    'grp': grp,\n    'value1':value1, \n    'value2':value2,\n    'value3':value3 \n})\nmydf.head()##   comp dept grp     value1     value2     value3\n## 0   C3   D1  G1  53.363478  17.909895  -9.245050\n## 1   C2   D3  G3  45.758243  26.982441  -5.504683\n## 2   C3   D2  G1  44.389197  17.156083   7.146977\n## 3   C3   D2  G3  49.534615  23.393759 -48.380884\n## 4   C3   D1  G2  59.860002  18.334803  35.396153"},{"path":"seaborn.html","id":"scatter-plot-1","chapter":"12 seaborn","heading":"12.3 Scatter Plot","text":"","code":""},{"path":"seaborn.html","id":"x-numeric","chapter":"12 seaborn","heading":"12.3.1 2x Numeric","text":"","code":"sns.lmplot(x='value1', y='value2', data=mydf)plt.show()sns.lmplot(x='value1', y='value2', fit_reg=False, data=mydf);  #hide regresion lineplt.show()"},{"path":"seaborn.html","id":"xnumeric-1x-categorical","chapter":"12 seaborn","heading":"12.3.2 2xNumeric + 1x Categorical","text":"Use hue represent additional categorical feature","code":"sns.lmplot(x='value1', y='value2', data=mydf, hue='comp', fit_reg=False);\nplt.show()"},{"path":"seaborn.html","id":"xnumeric-2x-categorical","chapter":"12 seaborn","heading":"12.3.3 2xNumeric + 2x Categorical","text":"Use col hue represent two categorical features","code":"sns.lmplot(x='value1', y='value2', col='comp',hue='grp', fit_reg=False, data=mydf);\nplt.show()"},{"path":"seaborn.html","id":"xnumeric-3x-categorical","chapter":"12 seaborn","heading":"12.3.4 2xNumeric + 3x Categorical","text":"Use row, col hue represent three categorical features","code":"sns.lmplot(x='value1', y='value2', row='dept',col='comp', hue='grp', fit_reg=False, data=mydf);## C:\\PROGRA~3\\Anaconda3\\lib\\site-packages\\seaborn\\axisgrid.py:447: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.plt.show()"},{"path":"seaborn.html","id":"customization","chapter":"12 seaborn","heading":"12.3.5 Customization","text":"","code":""},{"path":"seaborn.html","id":"size","chapter":"12 seaborn","heading":"12.3.5.1 size","text":"size: height inch facetObserve even size large, lmplot fit (shrink) everything one row deafult. See example .","code":"sns.lmplot(x='value1', y='value2', col='comp',hue='grp', fit_reg=False, data=mydf)plt.show()## Traceback (most recent call last):\n##   File \"C:\\PROGRA~3\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_qt.py\", line 454, in _draw_idle\n##     self.draw()\n##   File \"C:\\PROGRA~3\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\", line 405, in draw\n##     self.figure.draw(self.renderer)\n##   File \"C:\\PROGRA~3\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 74, in draw_wrapper\n##     result = draw(artist, renderer, *args, **kwargs)\n##   File \"C:\\PROGRA~3\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 51, in draw_wrapper\n##     return draw(artist, renderer)\n##   File \"C:\\PROGRA~3\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\", line 3071, in draw\n##     mimage._draw_list_compositing_images(\n##   File \"C:\\PROGRA~3\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\", line 131, in _draw_list_compositing_images\n##     a.draw(renderer)\n##   File \"C:\\PROGRA~3\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 51, in draw_wrapper\n##     return draw(artist, renderer)\n##   File \"C:\\PROGRA~3\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\", line 3071, in draw\n##     self._update_title_position(renderer)\n##   File \"C:\\PROGRA~3\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\", line 3004, in _update_title_position\n##     if (ax.xaxis.get_ticks_position() in ['top', 'unknown']\n##   File \"C:\\PROGRA~3\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 2399, in get_ticks_position\n##     self._get_ticks_position()]\n##   File \"C:\\PROGRA~3\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 2112, in _get_ticks_position\n##     minor = self.minorTicks[0]\n## IndexError: list index out of rangesns.lmplot(x='value1', y='value2', col='comp',hue='grp',fit_reg=False, data=mydf)plt.show()"},{"path":"seaborn.html","id":"col_wrap","chapter":"12 seaborn","heading":"12.3.5.2 col_wrap","text":"avoid lmplot shrinking chart, use col_wrap=<col_number wrap output.\nCompare size (height facet) without col_wrap. chart larger.","code":"sns.lmplot(x='value1', y='value2', col='comp',hue='grp', col_wrap=2, fit_reg=False, data=mydf)plt.show()"},{"path":"seaborn.html","id":"histogram-1","chapter":"12 seaborn","heading":"12.4 Histogram","text":"","code":"seaborn.distplot(\n  a,               # Series, 1D Array or List\n  bins=None,\n  hist=True,\n  rug = False,\n  vertical=False\n)"},{"path":"seaborn.html","id":"x-numeric-1","chapter":"12 seaborn","heading":"12.4.1 1x Numeric","text":"","code":"sns.distplot(mydf.value1)\nplt.show()sns.distplot(mydf.value1,hist=True,rug=True,vertical=True, bins=30,color='g')\nplt.show()"},{"path":"seaborn.html","id":"bar-chart-1","chapter":"12 seaborn","heading":"12.5 Bar Chart","text":"","code":"com_grp = mydf.groupby('comp')\ngrpdf = com_grp['value1'].sum().reset_index()\ngrpdf##   comp       value1\n## 0   C1  1748.544868\n## 1   C2  1535.003192\n## 2   C3  1711.932667"},{"path":"seaborn.html","id":"x-categorical-1x-numeric","chapter":"12 seaborn","heading":"12.5.1 1x Categorical, 1x Numeric","text":"","code":"sns.barplot(x='comp',y='value1',data=grpdf)\nplt.show()"},{"path":"seaborn.html","id":"customization-1","chapter":"12 seaborn","heading":"12.5.2 Customization","text":"","code":""},{"path":"seaborn.html","id":"ordering","chapter":"12 seaborn","heading":"12.5.2.1 Ordering","text":"","code":"sns.barplot(x='comp',y='value2', hue='grp',\n            order=['C3','C2','C1'],\n            hue_order=['G1','G2','G3'],\n            data=mydf\n)\nplt.show()"},{"path":"seaborn.html","id":"flipping-xy-axis","chapter":"12 seaborn","heading":"12.5.2.2 Flipping X/Y Axis","text":"","code":"sns.barplot(x='value2',y='comp', hue='grp',data=mydf)\nplt.show()"},{"path":"seaborn.html","id":"faceting","chapter":"12 seaborn","heading":"12.6 Faceting","text":"Faceting Seaborn generic function works matplotlib various plot utility.\nsupport matplotlib well seaborn plotting utility.","code":""},{"path":"seaborn.html","id":"faceting-histogram","chapter":"12 seaborn","heading":"12.6.1 Faceting Histogram","text":"","code":"g = sns.FacetGrid(mydf, col=\"comp\", row='dept')\ng.map(plt.hist, \"value1\")plt.show()g = sns.FacetGrid(mydf, col=\"comp\", row='dept')\ng.map(plt.hist, \"value1\")plt.show()"},{"path":"seaborn.html","id":"faceting-scatter-plot","chapter":"12 seaborn","heading":"12.6.2 Faceting Scatter Plot","text":"","code":"g = sns.FacetGrid(mydf, col=\"comp\", row='dept',hue='grp')\ng.map(plt.scatter, \"value1\",\"value2\",alpha=0.7);\ng.add_legend()plt.show()"},{"path":"seaborn.html","id":"pair-grid","chapter":"12 seaborn","heading":"12.7 Pair Grid","text":"","code":""},{"path":"seaborn.html","id":"simple-pair-grid","chapter":"12 seaborn","heading":"12.7.1 Simple Pair Grid","text":"","code":"g = sns.PairGrid(mydf, hue='comp')\ng.map(plt.scatter);\ng.add_legend()plt.show()"},{"path":"seaborn.html","id":"different-diag-and-offdiag","chapter":"12 seaborn","heading":"12.7.2 Different Diag and OffDiag","text":"","code":"g = sns.PairGrid(mydf, hue='comp')\ng.map_diag(plt.hist, bins=15)g.map_offdiag(plt.scatter)g.add_legend()plt.show()"},{"path":"plotnine.html","id":"plotnine","chapter":"13 plotnine","heading":"13 plotnine","text":"","code":""},{"path":"plotnine.html","id":"histogram-2","chapter":"13 plotnine","heading":"13.1 Histogram","text":"","code":""},{"path":"plotnine.html","id":"xnumeric","chapter":"13 plotnine","heading":"13.1.1 1xNumeric","text":"","code":"plotnine.ggplot( dataframe, aex(x='colName')) + geom_histogram( bins=10 )\nplotnine.ggplot( dataframe, aex(x='colName')) + geom_histogram( binwidth=? )plotnine.options.figure_size = (3, 3)\nggplot(mydf, aes(x='value1')) + geom_histogram()  # default bins = 10## <ggplot: (176789164036)>\n## \n## C:\\PROGRA~3\\Anaconda3\\lib\\site-packages\\plotnine\\stats\\stat_bin.py:95: PlotnineWarning: 'stat_bin()' using 'bins = 8'. Pick better value with 'binwidth'.ggplot(mydf, aes(x='value1')) + geom_histogram(bins = 15)## <ggplot: (176789048058)>ggplot(mydf, aes(x='value1')) + geom_histogram(binwidth = 3)## <ggplot: (176794410355)>"},{"path":"plotnine.html","id":"xnumeric-1xcategorical","chapter":"13 plotnine","heading":"13.1.2 1xNumeric + 1xCategorical","text":"","code":"plotnine.ggplot( dataframe, \n                    aes(x='colName'), \n                    fill='categorical-alike-colName') \n+ geom_histogram()ggplot(mydf, aes(x='value1', fill='grp')) + geom_histogram(bins=15)## <ggplot: (176794889463)>"},{"path":"plotnine.html","id":"scatter-plot-2","chapter":"13 plotnine","heading":"13.2 Scatter Plot","text":"","code":""},{"path":"plotnine.html","id":"x-numeric-2","chapter":"13 plotnine","heading":"13.2.1 2x Numeric","text":"","code":"ggplot(mydf, aes(x='value1',y='value2')) + geom_point()## <ggplot: (176794953704)>"},{"path":"plotnine.html","id":"x-numeric-1x-categorical","chapter":"13 plotnine","heading":"13.2.2 2x Numeric + 1x Categorical","text":"","code":"ggplot( DataFrame, aes(x='colName1',y='colName2')) \n    + geom_point( aes(\n        color='categorical-alike-colName',\n        size='numberColName'\n    ))ggplot(mydf, aes(x='value1',y='value2')) + geom_point(aes(color='grp'))## <ggplot: (176792443724)>ggplot(mydf, aes(x='value1',y='value2',color='grp')) + geom_point()## <ggplot: (176792456427)>ggplot(mydf, aes(x='value1',y='value2')) + \\\n    geom_point(aes(\n        color='grp'\n    ))## <ggplot: (176789342064)>"},{"path":"plotnine.html","id":"x-numeric-1x-numeric-1x-categorical","chapter":"13 plotnine","heading":"13.2.3 2x Numeric + 1x Numeric + 1x Categorical","text":"","code":"ggplot(mydf, aes(x='value1',y='value2')) + \\\n    geom_point(aes( \n        color='grp', size='value3'\n    ))## <ggplot: (176789308880)>"},{"path":"plotnine.html","id":"overlay-smooth-line","chapter":"13 plotnine","heading":"13.2.4 Overlay Smooth Line","text":"","code":"ggplot(mydf, aes(x='value1', y='value2')) + \\\n    geom_point() + \\\n    geom_smooth()          # default method='loess'## <ggplot: (176788959642)>\n## \n## C:\\PROGRA~3\\Anaconda3\\lib\\site-packages\\plotnine\\stats\\smoothers.py:321: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.ggplot(mydf, aes(x='value1', y='value2',fill='grp')) + \\\n    geom_point() + \\\n    geom_smooth(\n        se=True,\n        color='red',\n        method='lm', \n        level=0.75)## <ggplot: (176788608455)>"},{"path":"plotnine.html","id":"line-chart","chapter":"13 plotnine","heading":"13.3 Line Chart","text":"","code":""},{"path":"plotnine.html","id":"x-numeric-data","chapter":"13 plotnine","heading":"13.3.1 2x Numeric Data","text":"","code":"ggplot (mydf.head(15), aes(x='value1', y='value2')) + geom_line()## <ggplot: (176794949084)>"},{"path":"plotnine.html","id":"x-numeric-1x-categorical-1","chapter":"13 plotnine","heading":"13.3.2 1x Numeric, 1x Categorical","text":"","code":"ggplot (mydf.head(15), aes(x='dept', y='value1')) + geom_line()## <ggplot: (176794464386)>ggplot (mydf.head(30), aes(x='dept', y='value1')) + geom_line( aes(group=1))## <ggplot: (176796006054)>"},{"path":"plotnine.html","id":"x-numeric-1x-categorical-2","chapter":"13 plotnine","heading":"13.3.3 2x Numeric, 1x Categorical","text":"","code":"ggplot (mydf.head(15), aes(x='value1', y='value2')) + geom_line( aes(color='grp'),size=2)## <ggplot: (176796028305)>"},{"path":"plotnine.html","id":"bar-chart-2","chapter":"13 plotnine","heading":"13.4 Bar Chart","text":"","code":""},{"path":"plotnine.html","id":"x-categorical","chapter":"13 plotnine","heading":"13.4.0.1 1x Categorical","text":"Single categorical variable produces frequency chart.","code":"tmpdf = mydf.groupby(['comp'],as_index=False).count()\ntmpdf##   comp  dept  grp  value1  value2  value3\n## 0   C1    35   35      35      35      35\n## 1   C2    31   31      31      31      31\n## 2   C3    34   34      34      34      34tmpdf.info()## <class 'pandas.core.frame.DataFrame'>\n## RangeIndex: 3 entries, 0 to 2\n## Data columns (total 6 columns):\n##  #   Column  Non-Null Count  Dtype \n## ---  ------  --------------  ----- \n##  0   comp    3 non-null      object\n##  1   dept    3 non-null      int64 \n##  2   grp     3 non-null      int64 \n##  3   value1  3 non-null      int64 \n##  4   value2  3 non-null      int64 \n##  5   value3  3 non-null      int64 \n## dtypes: int64(5), object(1)\n## memory usage: 272.0+ bytesggplot (tmpdf, aes(x='comp', y='grp')) +geom_col()## <ggplot: (176794410466)>"},{"path":"numpy.html","id":"numpy","chapter":"14 numpy","heading":"14 numpy","text":"Best array data manipulation, fastnumpy array allows single data type, unlike listSupport matrix operation","code":""},{"path":"numpy.html","id":"environment-setup","chapter":"14 numpy","heading":"14.1 Environment Setup","text":"","code":"from IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container { width:75% !important; margin-left:350px; }<\/style>\"))\n#%matplotlib inline## <IPython.core.display.HTML object>import pandas as pd\nimport matplotlib.pyplot as plt\nimport math\npd.set_option( 'display.notebook_repr_html', False)  # render Series and DataFrame as text, not HTML\npd.set_option( 'display.max_column', 10)    # number of columns\npd.set_option( 'display.max_rows', 10)     # number of rows\npd.set_option( 'display.width', 90)        # number of characters per row"},{"path":"numpy.html","id":"module-import-1","chapter":"14 numpy","heading":"14.2 Module Import","text":"","code":"import numpy as np\nnp.__version__\n\n## other modules## '1.23.4'from datetime import datetime\nfrom datetime import date\nfrom datetime import time"},{"path":"numpy.html","id":"data-types","chapter":"14 numpy","heading":"14.3 Data Types","text":"","code":""},{"path":"numpy.html","id":"numpy-data-types","chapter":"14 numpy","heading":"14.3.1 NumPy Data Types","text":"NumPy supports much greater variety numerical types Python . makes numpy much powerful\nhttps://www.numpy.org/devdocs/user/basics.types.htmlInteger: np.int8, np.int16, np.int32, np.uint8, np.uint16, np.uint32\nFloat: np.float32, np.float64","code":""},{"path":"numpy.html","id":"int3264","chapter":"14 numpy","heading":"14.3.2 int32/64","text":"np.int actually python standard intnp.int32/64 NumPy specific","code":"x = np.int(13)## <string>:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n## Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecationsy = int(13)\nprint( type(x) )## <class 'int'>print( type(y) )## <class 'int'>x = np.int32(13)\ny = np.int64(13)\nprint( type(x) )## <class 'numpy.int32'>print( type(y) )## <class 'numpy.int64'>"},{"path":"numpy.html","id":"float3264","chapter":"14 numpy","heading":"14.3.3 float32/64","text":"","code":"x = np.float(13)## <string>:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n## Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecationsy = float(13)\nprint( type(x) )## <class 'float'>print( type(y) )## <class 'float'>x = np.float32(13)\ny = np.float64(13)\nprint( type(x) )## <class 'numpy.float32'>print( type(y) )## <class 'numpy.float64'>"},{"path":"numpy.html","id":"bool","chapter":"14 numpy","heading":"14.3.4 bool","text":"np.bool actually python standard bool","code":"x = np.bool(True)## <string>:1: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n## Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecationsprint( type(x) )## <class 'bool'>print( type(True) )## <class 'bool'>"},{"path":"numpy.html","id":"str","chapter":"14 numpy","heading":"14.3.5 str","text":"np.str actually python standard str","code":"x = np.str(\"ali\")## <string>:1: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n## Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecationsprint( type(x) )## <class 'str'>x = np.str_(\"ali\")\nprint( type(x) )## <class 'numpy.str_'>"},{"path":"numpy.html","id":"datetime64","chapter":"14 numpy","heading":"14.3.6 datetime64","text":"Unlike python standard datetime library, seperation date, datetime time.\ntime equivalent object\nNumPy one object: datetime64 object .","code":""},{"path":"numpy.html","id":"constructor-5","chapter":"14 numpy","heading":"14.3.6.1 Constructor","text":"String\nNote input string ISO8601 compliance, meaning timezone related information end string (Z +8) result error.datetime","code":"np.datetime64('2005-02')## numpy.datetime64('2005-02')np.datetime64('2005-02-25')## numpy.datetime64('2005-02-25')np.datetime64('2005-02-25T03:30')## numpy.datetime64('2005-02-25T03:30')np.datetime64( date.today() )## numpy.datetime64('2022-12-29')np.datetime64( datetime.now() )## numpy.datetime64('2022-12-29T15:01:21.398226')"},{"path":"numpy.html","id":"instance-method-2","chapter":"14 numpy","heading":"14.3.6.2 Instance Method","text":"Convert datetime using astype()","code":"dt64 = np.datetime64(\"2019-01-31\" )\ndt64.astype(datetime)## datetime.date(2019, 1, 31)"},{"path":"numpy.html","id":"nan","chapter":"14 numpy","heading":"14.3.7 nan","text":"","code":""},{"path":"numpy.html","id":"creating-nan","chapter":"14 numpy","heading":"14.3.7.1 Creating NaN","text":"NaN BUILT-datatype. means number, numpy float object type. Can created using two methods .","code":"import numpy as np\nimport pandas as pd\nimport math\n\nkosong1 = float('NaN')\nkosong2 = np.nan\n\nprint('Type: ', type(kosong1), '\\n',\n       'Value: ', kosong1)## Type:  <class 'float'> \n##  Value:  nanprint('Type: ', type(kosong2), '\\n',\n       'Value: ', kosong2)## Type:  <class 'float'> \n##  Value:  nan"},{"path":"numpy.html","id":"detecting-nan","chapter":"14 numpy","heading":"14.3.7.2 Detecting NaN","text":"Detect nan using various function panda, numpy math.","code":"print(pd.isna(kosong1), '\\n',\n      pd.isna(kosong2), '\\n',\n      np.isnan(kosong1),'\\n',\n      math.isnan(kosong2))## True \n##  True \n##  True \n##  True"},{"path":"numpy.html","id":"operation","chapter":"14 numpy","heading":"14.3.7.3 Operation","text":"","code":""},{"path":"numpy.html","id":"logical-operator","chapter":"14 numpy","heading":"14.3.7.3.1 Logical Operator","text":"","code":"print( True and kosong1,\n       kosong1 and True)## nan Trueprint( True or kosong1,\n       False or kosong1)## True nan"},{"path":"numpy.html","id":"comparing","chapter":"14 numpy","heading":"14.3.7.3.2 Comparing","text":"Compare nan anything results False, including .","code":"print(kosong1 > 0, kosong1==0, kosong1<0,\n      kosong1 ==1, kosong1==kosong1, kosong1==False, kosong1==True)## False False False False False False False"},{"path":"numpy.html","id":"casting","chapter":"14 numpy","heading":"14.3.7.3.3 Casting","text":"nan numpy floating value. zero value, therefore casting boolean returns True.","code":"bool(kosong1)## True"},{"path":"numpy.html","id":"numpy-array","chapter":"14 numpy","heading":"14.4 Numpy Array","text":"","code":""},{"path":"numpy.html","id":"concept","chapter":"14 numpy","heading":"14.4.1 Concept","text":"Structure\n- NumPy provides N-dimensional array type, ndarray\n- ndarray homogenous: every item takes size block memory, blocks\n- ndarray, seperate dtype object, describe ndarray data type\n- item extracted array, e.g., indexing, represented Python object whose type one array scalar types built NumPy. array scalars allow easy manipulation also complicated arrangements data.\n","code":""},{"path":"numpy.html","id":"constructor-6","chapter":"14 numpy","heading":"14.4.2 Constructor","text":"default, numpy.array autodetect data types based common denominator","code":""},{"path":"numpy.html","id":"dtype-int-float","chapter":"14 numpy","heading":"14.4.2.1 dType: int, float","text":"Notice example auto detected int32 data typeNotice example auto detected float64 data typeYou can specify dtype specify desired data types.\nNumPy auto convert data specifeid types. Observe convert float integer","code":"x = np.array( (1,2,3,4,5) )\nprint(x)## [1 2 3 4 5]print('Type: ', type(x))## Type:  <class 'numpy.ndarray'>print('dType:', x.dtype)## dType: int32x = np.array( (1,2,3,4.5,5) )\nprint(x)## [1.  2.  3.  4.5 5. ]print('Type: ', type(x))## Type:  <class 'numpy.ndarray'>print('dType:', x.dtype)## dType: float64x = np.array( (1,2,3,4.5,5), dtype='int' )\nprint(x)## [1 2 3 4 5]print('Type: ', type(x))## Type:  <class 'numpy.ndarray'>print('dType:', x.dtype)## dType: int32"},{"path":"numpy.html","id":"dtype-datetime64","chapter":"14 numpy","heading":"14.4.2.2 dType: datetime64","text":"Specify dtype necessary ensure output datetime type. , output generic object type.strFrom datetime","code":"x = np.array(['2007-07-13', '2006-01-13', '2010-08-13'], dtype='datetime64')\nprint(x)## ['2007-07-13' '2006-01-13' '2010-08-13']print('Type: ', type(x))## Type:  <class 'numpy.ndarray'>print('dType:', x.dtype)## dType: datetime64[D]x = np.array([datetime(2019,1,12), datetime(2019,1,14),datetime(2019,3,3)], dtype='datetime64')\nprint(x)## ['2019-01-12T00:00:00.000000' '2019-01-14T00:00:00.000000'\n##  '2019-03-03T00:00:00.000000']print('Type: ', type(x))## Type:  <class 'numpy.ndarray'>print('dType:', x.dtype)## dType: datetime64[us]print('\\nElement Type:',type(x[1]))## \n## Element Type: <class 'numpy.datetime64'>"},{"path":"numpy.html","id":"d-array","chapter":"14 numpy","heading":"14.4.2.3 2D Array","text":"","code":"x = np.array([range(10),np.arange(10)])\nx## array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n##        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])"},{"path":"numpy.html","id":"dimensions","chapter":"14 numpy","heading":"14.4.3 Dimensions","text":"","code":""},{"path":"numpy.html","id":"differentiating-dimensions","chapter":"14 numpy","heading":"14.4.3.1 Differentiating Dimensions","text":"1-D array array single list\n2-D array array made list containing lists (row list)\n2-D single row array array list containing just one list","code":""},{"path":"numpy.html","id":"d-array-1","chapter":"14 numpy","heading":"14.4.3.2 1-D Array","text":"Observe shape array (5,). seems like array 5 rows, empty columns !\nreally means 5 items single dimension.","code":"arr = np.array(range(5))\nprint (arr)## [0 1 2 3 4]print (arr.shape)## (5,)print (arr.ndim)## 1"},{"path":"numpy.html","id":"d-array-2","chapter":"14 numpy","heading":"14.4.3.3 2-D Array","text":"","code":"arr = np.array([range(5),range(5,10),range(10,15)])\nprint (arr)## [[ 0  1  2  3  4]\n##  [ 5  6  7  8  9]\n##  [10 11 12 13 14]]print (arr.shape)## (3, 5)print (arr.ndim)## 2"},{"path":"numpy.html","id":"d-array---single-row","chapter":"14 numpy","heading":"14.4.3.4 2-D Array - Single Row","text":"","code":"arr = np.array([range(5)])\nprint (arr)## [[0 1 2 3 4]]print (arr.shape)## (1, 5)print (arr.ndim)## 2"},{"path":"numpy.html","id":"d-array-single-column","chapter":"14 numpy","heading":"14.4.3.5 2-D Array : Single Column","text":"Using array slicing method newaxis COLUMN, turn 1D array 2D single columnUsing array slicing method newaxis ROW, turn 1D array 2D single row","code":"arr = np.arange(5)[:, np.newaxis]\nprint (arr)## [[0]\n##  [1]\n##  [2]\n##  [3]\n##  [4]]print (arr.shape)## (5, 1)print (arr.ndim)## 2arr = np.arange(5)[np.newaxis,:]\nprint (arr)## [[0 1 2 3 4]]print (arr.shape)## (1, 5)print (arr.ndim)## 2"},{"path":"numpy.html","id":"class-method-3","chapter":"14 numpy","heading":"14.4.4 Class Method","text":"","code":""},{"path":"numpy.html","id":"arange","chapter":"14 numpy","heading":"14.4.4.1 arange()","text":"Generate array sequence numbers","code":"np.arange(10)## array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"},{"path":"numpy.html","id":"ones","chapter":"14 numpy","heading":"14.4.4.2 ones()","text":"","code":"np.ones(10)  # One dimension, default is float## array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])np.ones((2,5),'int')  #Two dimensions## array([[1, 1, 1, 1, 1],\n##        [1, 1, 1, 1, 1]])"},{"path":"numpy.html","id":"zeros","chapter":"14 numpy","heading":"14.4.4.3 zeros()","text":"","code":"np.zeros( 10 )    # One dimension, default is float## array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])np.zeros((2,5),'int')   # 2 rows, 5 columns of ZERO## array([[0, 0, 0, 0, 0],\n##        [0, 0, 0, 0, 0]])"},{"path":"numpy.html","id":"where","chapter":"14 numpy","heading":"14.4.4.4 where()","text":"1D array numpy.() returns items matching criteriaOn 2D array, () return array row index col index matching elements","code":"ar1 = np.array(range(10))\nprint( ar1 )## [0 1 2 3 4 5 6 7 8 9]print( np.where(ar1>5) )## (array([6, 7, 8, 9], dtype=int64),)ar = np.array([(1,2,3,4,5),(11,12,13,14,15),(21,22,23,24,25)])\nprint ('Data : \\n', ar)## Data : \n##  [[ 1  2  3  4  5]\n##  [11 12 13 14 15]\n##  [21 22 23 24 25]]np.where(ar>13)## (array([1, 1, 2, 2, 2, 2, 2], dtype=int64), array([3, 4, 0, 1, 2, 3, 4], dtype=int64))"},{"path":"numpy.html","id":"logical-methods","chapter":"14 numpy","heading":"14.4.4.5 Logical Methods","text":"numpy.logical_or\nPerform operation two boolean array, generate new resulting boolean arraysnumpy.logical_and\nPerform operation two boolean array, generate new resulting boolean arrays","code":"ar = np.arange(10)\nprint( ar==3 )  # boolean array 1## [False False False  True False False False False False False]print( ar==6 )  # boolean array 2## [False False False False False False  True False False False]print( np.logical_or(ar==3,ar==6 ) ) # resulting boolean## [False False False  True False False  True False False False]ar = np.arange(10)\nprint( ar==3 ) # boolean array 1## [False False False  True False False False False False False]print( ar==6 ) # boolean array 2## [False False False False False False  True False False False]print( np.logical_and(ar==3,ar==6 ) )  # resulting boolean## [False False False False False False False False False False]"},{"path":"numpy.html","id":"instance-method-3","chapter":"14 numpy","heading":"14.4.5 Instance Method","text":"","code":""},{"path":"numpy.html","id":"astype-conversion","chapter":"14 numpy","heading":"14.4.5.1 astype() conversion","text":"Convert datetime64 datetimeAfter convert datetime (non-numpy object, dtype becomes generic ‘object’.","code":"ar1 = np.array(['2007-07-13', '2006-01-13', '2010-08-13'], dtype='datetime64')\nprint( type(ar1) )  ## a numpy array## <class 'numpy.ndarray'>print( ar1.dtype )  ## dtype is a numpy data type## datetime64[D]ar2 = ar1.astype(datetime)\nprint( type(ar2) )  ## still a numpy array## <class 'numpy.ndarray'>print( ar2.dtype )  ## dtype becomes generic 'object'## object"},{"path":"numpy.html","id":"reshape","chapter":"14 numpy","heading":"14.4.5.2 reshape()","text":"Sample DataResphepe 1-Dim 2-DimRespahe 2-Dim 2-DimReshape 2-Dimension 2-Dim (single row)\n- Change 2x10 1x10\n- Observe [[ ]], number dimension stll 2, don’t fooledReshape 1-Dim Array 2-Dim Array (single column)better method, use newaxis, easier need input row number parameterReshape 1-Dim Array 2-Dim Array (single row)","code":"reshape ( row numbers, col numbers )a = np.array([range(5), range(10,15), range(20,25), range(30,35)])\na## array([[ 0,  1,  2,  3,  4],\n##        [10, 11, 12, 13, 14],\n##        [20, 21, 22, 23, 24],\n##        [30, 31, 32, 33, 34]])np.arange(12) # 1-D Array## array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])np.arange(12).reshape(3,4)  # 2-D Array## array([[ 0,  1,  2,  3],\n##        [ 4,  5,  6,  7],\n##        [ 8,  9, 10, 11]])np.array([range(5), range(10,15)])  # 2-D Array## array([[ 0,  1,  2,  3,  4],\n##        [10, 11, 12, 13, 14]])np.array([range(5), range(10,15)]).reshape(5,2) # 2-D Array## array([[ 0,  1],\n##        [ 2,  3],\n##        [ 4, 10],\n##        [11, 12],\n##        [13, 14]])np.array( [range(0,5), range(5,10)])  # 2-D Array## array([[0, 1, 2, 3, 4],\n##        [5, 6, 7, 8, 9]])np.array( [range(0,5), range(5,10)]).reshape(1,10) # 2-D Array## array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])np.arange(8)## array([0, 1, 2, 3, 4, 5, 6, 7])np.arange(8).reshape(8,1)## array([[0],\n##        [1],\n##        [2],\n##        [3],\n##        [4],\n##        [5],\n##        [6],\n##        [7]])np.arange(8)[:,np.newaxis]## array([[0],\n##        [1],\n##        [2],\n##        [3],\n##        [4],\n##        [5],\n##        [6],\n##        [7]])np.arange(8)## array([0, 1, 2, 3, 4, 5, 6, 7])np.arange(8)[np.newaxis,:]## array([[0, 1, 2, 3, 4, 5, 6, 7]])"},{"path":"numpy.html","id":"element-selection","chapter":"14 numpy","heading":"14.4.6 Element Selection","text":"","code":""},{"path":"numpy.html","id":"sample-data-4","chapter":"14 numpy","heading":"14.4.6.1 Sample Data","text":"","code":"x1 = np.array( (0,1,2,3,4,5,6,7,8))\nx2 = np.array(( (1,2,3,4,5), \n      (11,12,13,14,15),\n      (21,22,23,24,25)))\nprint(x1)## [0 1 2 3 4 5 6 7 8]print(x2)## [[ 1  2  3  4  5]\n##  [11 12 13 14 15]\n##  [21 22 23 24 25]]"},{"path":"numpy.html","id":"dimension","chapter":"14 numpy","heading":"14.4.6.2 1-Dimension","text":"indexing starts 0 (1)Choosing Single Element return arraySelecting multiple elments return ndarray","code":"print( x1[0]   )  ## first element## 0print( x1[-1]  )  ## last element## 8print( x1[3]   )  ## third element from start 3## 3print( x1[-3]  )  ## third element from end## 6print( x1[:3]  )  ## first 3 elements## [0 1 2]print( x1[-3:])   ## last 3 elements## [6 7 8]print( x1[3:]  )  ## all except first 3 elements## [3 4 5 6 7 8]print( x1[:-3] )  ## all except last 3 elements## [0 1 2 3 4 5]print( x1[1:4] )  ## elemnt 1 to 4 (not including 4)## [1 2 3]"},{"path":"numpy.html","id":"dimension-1","chapter":"14 numpy","heading":"14.4.6.3 2-Dimension","text":"Indexing [ row_positoins, row_positions ], index starts 0","code":"x[1:3, 1:4] # row 1 to 2 column 1 to 3## array([[1, 2, 3]])"},{"path":"numpy.html","id":"attributes-3","chapter":"14 numpy","heading":"14.4.7 Attributes","text":"","code":""},{"path":"numpy.html","id":"dtype","chapter":"14 numpy","heading":"14.4.7.1 dtype","text":"ndarray contain property called dtype, whcih tell us type underlying items","code":"a = np.array( (1,2,3,4,5), dtype='float' )\na.dtype## dtype('float64')print(a.dtype)## float64print( type(a[1]))## <class 'numpy.float64'>"},{"path":"numpy.html","id":"dim","chapter":"14 numpy","heading":"14.4.7.2 dim","text":"dim returns number dimensions NumPy array. Example shows 2-D array","code":"x = np.array(( (1,2,3,4,5), \n      (11,12,13,14,15),\n      (21,22,23,24,25)))\nx.ndim  ## 2"},{"path":"numpy.html","id":"shape","chapter":"14 numpy","heading":"14.4.7.3 shape","text":"shape return type (rows, cols)","code":"x = np.array(( (1,2,3,4,5), \n      (11,12,13,14,15),\n      (21,22,23,24,25)))\nx.shape  ## (3, 5)np.identity(5)## array([[1., 0., 0., 0., 0.],\n##        [0., 1., 0., 0., 0.],\n##        [0., 0., 1., 0., 0.],\n##        [0., 0., 0., 1., 0.],\n##        [0., 0., 0., 0., 1.]])"},{"path":"numpy.html","id":"operations","chapter":"14 numpy","heading":"14.4.8 Operations","text":"","code":""},{"path":"numpy.html","id":"arithmetic","chapter":"14 numpy","heading":"14.4.8.1 Arithmetic","text":"Sample Date***+ -**","code":"ar = np.arange(10)\nprint( ar )## [0 1 2 3 4 5 6 7 8 9]ar = np.arange(10)\nprint (ar)## [0 1 2 3 4 5 6 7 8 9]print (ar*2)## [ 0  2  4  6  8 10 12 14 16 18]ar = np.arange(10)\nprint (ar+2)## [ 2  3  4  5  6  7  8  9 10 11]print (ar-2)## [-2 -1  0  1  2  3  4  5  6  7]"},{"path":"numpy.html","id":"comparison","chapter":"14 numpy","heading":"14.4.8.2 Comparison","text":"Sample Data==>, >=, <, <=","code":"ar = np.arange(10)\nprint( ar )## [0 1 2 3 4 5 6 7 8 9]print( ar==3 )## [False False False  True False False False False False False]print( ar>3 )## [False False False False  True  True  True  True  True  True]print( ar<=3 )## [ True  True  True  True False False False False False False]"},{"path":"numpy.html","id":"random-numbers","chapter":"14 numpy","heading":"14.5 Random Numbers","text":"","code":""},{"path":"numpy.html","id":"uniform-distribution","chapter":"14 numpy","heading":"14.5.1 Uniform Distribution","text":"","code":""},{"path":"numpy.html","id":"random-integer-with-replacement","chapter":"14 numpy","heading":"14.5.1.1 Random Integer (with Replacement)","text":"randint() Return random integers low (inclusive) high (exclusive)","code":"np.random.randint( low )                  # generate an integer, i, which         i < low\nnp.random.randint( low, high )            # generate an integer, i, which  low <= i < high\nnp.random.randint( low, high, size=1)     # generate an ndarray of integer, single dimension\nnp.random.randint( low, high, size=(r,c)) # generate an ndarray of integer, two dimensions np.random.randint( 10 )## 3np.random.randint( 10, 20 )## 10np.random.randint( 10, high=20, size=5)   # single dimension## array([16, 17, 13, 16, 19])np.random.randint( 10, 20, (3,5) )        # two dimensions## array([[11, 18, 17, 19, 16],\n##        [17, 18, 17, 19, 19],\n##        [12, 19, 19, 10, 11]])"},{"path":"numpy.html","id":"random-integer-with-or-without-replacement","chapter":"14 numpy","heading":"14.5.1.2 Random Integer (with or without replacement)","text":"","code":"numpy.random .choice( a, size, replace=True)\n # sampling from a, \n #   if a is integer, then it is assumed sampling from arange(a)\n #   if a is an 1-D array, then sampling from this arraynp.random.choice(10,5, replace=False) # take 5 samples from 0:19, without replacement## array([7, 6, 2, 8, 4])np.random.choice( np.arange(10,20), 5, replace=False)## array([13, 14, 17, 10, 16])"},{"path":"numpy.html","id":"random-float","chapter":"14 numpy","heading":"14.5.1.3 Random Float","text":"randf() Generate float numbers 0.0 1.0uniform() Return random float low (inclusive) high (exclusive)","code":"np.random.ranf(size=None)np.random.ranf(4)## array([0.29133069, 0.68149636, 0.6769486 , 0.78113796])np.random.uniform( low )                  # generate an float, i, which         f < low\nnp.random.uniform( low, high )            # generate an float, i, which  low <= f < high\nnp.random.uniform( low, high, size=1)     # generate an array of float, single dimension\nnp.random.uniform( low, high, size=(r,c)) # generate an array of float, two dimensions np.random.uniform( 2 )## 1.6486212103846476np.random.uniform( 2,5, size=(4,4) )## array([[3.73935599, 3.27852869, 4.16887145, 2.10216656],\n##        [4.00301017, 3.72814232, 4.6897219 , 4.97649882],\n##        [2.54140528, 2.4190437 , 3.48150324, 4.31595142],\n##        [2.00611579, 4.92580851, 2.1107683 , 4.09324433]])"},{"path":"numpy.html","id":"normal-distribution","chapter":"14 numpy","heading":"14.5.2 Normal Distribution","text":"","code":"numpy. random.randn (n_items)       # 1-D standard normal (mean=0, stdev=1)\nnumpy. random.randn (nrows, ncols)  # 2-D standard normal (mean=0, stdev=1)\nnumpy. random.standard_normal( size=None )                # default to mean = 0, stdev = 1, non-configurable\nnumpy. random.normal         ( loc=0, scale=1, size=None) # loc = mean, scale = stdev, size = dimension"},{"path":"numpy.html","id":"standard-normal-distribution","chapter":"14 numpy","heading":"14.5.2.1 Standard Normal Distribution","text":"Generate random normal numbers gaussion distribution (mean=0, stdev=1)One DimensionTwo DimensionsObserve: randn(), standard_normal() normal() able generate standard normal numbers","code":"np.random.standard_normal(3)## array([-0.70375452,  0.53053035, -1.87609398])np.random.randn(3)## array([0.38666756, 0.93977217, 0.67245593])np.random.randn(2,4)## array([[ 0.19419534, -1.58178563,  1.40679994,  1.22288073],\n##        [-1.17974396,  0.59848167,  0.5021601 ,  0.26611803]])np.random.standard_normal((2,4))## array([[ 0.56794766,  0.94118701, -0.74332446, -1.61568935],\n##        [ 0.20941382, -1.71242473,  0.94806938,  0.61454969]])np.random.seed(15)\nprint (np.random.randn(5))## [-0.31232848  0.33928471 -0.15590853 -0.50178967  0.23556889]np.random.seed(15)\nprint (np.random.normal ( size = 5 )) # stdev and mean not specified, default to standard normal## [-0.31232848  0.33928471 -0.15590853 -0.50178967  0.23556889]np.random.seed(15)\nprint (np.random.standard_normal (size=5))## [-0.31232848  0.33928471 -0.15590853 -0.50178967  0.23556889]"},{"path":"numpy.html","id":"normal-distribution-non-standard","chapter":"14 numpy","heading":"14.5.2.2 Normal Distribution (Non-Standard)","text":"","code":"np.random.seed(125)\nnp.random.normal( loc = 12, scale=1.25, size=(3,3))## array([[11.12645382, 12.01327885, 10.81651695],\n##        [12.41091248, 12.39383072, 11.49647195],\n##        [ 8.70837035, 12.25246312, 11.49084235]])"},{"path":"numpy.html","id":"linear-spacing","chapter":"14 numpy","heading":"14.5.2.3 Linear Spacing","text":"Include Endpoint\nStep = Gap divide (number elements minus 1) (2/(10-1))Include Endpoint\nStep = Gap divide (number elements minus 1) (2/(101))","code":"numpy.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None)\n# endpoint: If True, stop is the last sample, otherwise it is not includednp.linspace(1,3,10) #default endpont=True## array([1.        , 1.22222222, 1.44444444, 1.66666667, 1.88888889,\n##        2.11111111, 2.33333333, 2.55555556, 2.77777778, 3.        ])np.linspace(1,3,10,endpoint=False)## array([1. , 1.2, 1.4, 1.6, 1.8, 2. , 2.2, 2.4, 2.6, 2.8])"},{"path":"numpy.html","id":"sampling-integer","chapter":"14 numpy","heading":"14.6 Sampling (Integer)","text":"","code":"random.choice( a, size=None, replace=True, p=None)  # a=integer, return <size> integers < a\nrandom.choice( a, size=None, replace=True, p=None)  # a=array-like, return <size> integers picked from list anp.random.choice (100, size=10)## array([58,  0, 84, 50, 89, 32, 87, 30, 66, 92])np.random.choice( [1,3,5,7,9,11,13,15,17,19,21,23], size=10, replace=False)## array([ 5,  1, 23, 17,  3, 13, 15,  9, 21,  7])"},{"path":"numpy.html","id":"nan-missing-numerical-data","chapter":"14 numpy","heading":"14.7 NaN : Missing Numerical Data","text":"aware NaN bit like data virus?infects object touchesRegardless operation, result arithmetic NaN another NaN","code":"t = np.array([1, np.nan, 3, 4]) \nt.dtype## dtype('float64')1 + np.nan## nant.sum(), t.mean(), t.max()## (nan, nan, nan)np.nansum(t), np.nanmean(t), np.nanmax(t)## (8.0, 2.6666666666666665, 4.0)"},{"path":"pandas.html","id":"pandas","chapter":"15 pandas","heading":"15 pandas","text":"","code":""},{"path":"pandas.html","id":"modules-import","chapter":"15 pandas","heading":"15.1 Modules Import","text":"","code":"import pandas as pd\n\n## Other Libraries\nimport numpy as np\nimport datetime as dt\nfrom datetime import datetime\nfrom datetime import date"},{"path":"pandas.html","id":"pandas-objects","chapter":"15 pandas","heading":"15.2 Pandas Objects","text":"","code":""},{"path":"pandas.html","id":"types-of-objects","chapter":"15 pandas","heading":"15.2.1 Types of Objects","text":"pandas.Timestamppandas.Timedeltapandas.Periodpandas.Intervalpandas.DateTimeIndexpandas.DataFramepandas.Series","code":""},{"path":"pandas.html","id":"series-and-dataframe","chapter":"15 pandas","heading":"15.2.2 Series and DataFrame","text":"data can ndarray, list, constantsindex must unique length data. Can integer string\ndtype none, inferredcopy copy data. Default false","code":""},{"path":"pandas.html","id":"class-method-4","chapter":"15 pandas","heading":"15.3 Class Method","text":"","code":""},{"path":"pandas.html","id":"creating-timestamp","chapter":"15 pandas","heading":"15.3.1 Creating Timestamp","text":"Pandas to_datetime() can:\n- Convert list dates DateTimeIndex\n- Convert list dates Series Timestamps\n- Convert single date Timestamp Object\n. Source can string, date, datetime object","code":""},{"path":"pandas.html","id":"from-list-to-datetimeindex","chapter":"15 pandas","heading":"15.3.1.1 From List to DateTimeIndex","text":"","code":"dti = pd.to_datetime(['2011-01-03',             # from string\n                       date(2018,4,13),         # from date\n                       datetime(2018,3,1,7,30)] # from datetime\n              )\nprint( dti,\n      '\\nObject Type:  ', type(dti),\n      '\\nObject dtype: ', dti.dtype,\n      '\\nElement Type: ', type(dti[1]))## DatetimeIndex(['2011-01-03 00:00:00', '2018-04-13 00:00:00', '2018-03-01 07:30:00'], dtype='datetime64[ns]', freq=None) \n## Object Type:   <class 'pandas.core.indexes.datetimes.DatetimeIndex'> \n## Object dtype:  datetime64[ns] \n## Element Type:  <class 'pandas._libs.tslibs.timestamps.Timestamp'>"},{"path":"pandas.html","id":"from-list-to-series-of-timestamps","chapter":"15 pandas","heading":"15.3.1.2 From List to Series of Timestamps","text":"","code":"sdt = pd.to_datetime(pd.Series(['2011-01-03',      # from string\n                                date(2018,4,13),        # from date\n                                datetime(2018,3,1,7,30)]# from datetime\n              ))## <string>:1: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])print(sdt,\n      '\\nObject Type:  ',type(sdt),\n      '\\nObject dtype: ', sdt.dtype,\n      '\\nElement Type: ',type(sdt[1]))## 0   2011-01-03 00:00:00\n## 1   2018-04-13 00:00:00\n## 2   2018-03-01 07:30:00\n## dtype: datetime64[ns] \n## Object Type:   <class 'pandas.core.series.Series'> \n## Object dtype:  datetime64[ns] \n## Element Type:  <class 'pandas._libs.tslibs.timestamps.Timestamp'>"},{"path":"pandas.html","id":"from-scalar-to-timestamp","chapter":"15 pandas","heading":"15.3.1.3 From Scalar to Timestamp","text":"","code":"print( pd.to_datetime('2011-01-03'), '\\n',\n       pd.to_datetime(date(2011,1,3)), '\\n',\n       pd.to_datetime(datetime(2011,1,3,5,30)), '\\n',\n       '\\nElement Type: ', type(pd.to_datetime(datetime(2011,1,3,5,30))))## 2011-01-03 00:00:00 \n##  2011-01-03 00:00:00 \n##  2011-01-03 05:30:00 \n##  \n## Element Type:  <class 'pandas._libs.tslibs.timestamps.Timestamp'>"},{"path":"pandas.html","id":"generate-timestamp-sequence","chapter":"15 pandas","heading":"15.3.2 Generate Timestamp Sequence","text":"function date_range() return DateTimeIndex object. Use Series() convert Series desired.","code":""},{"path":"pandas.html","id":"hourly","chapter":"15 pandas","heading":"15.3.2.1 Hourly","text":"start time specified, default 00:00:00.\nstart time specified, honored subsequent Timestamp elements.\nSpecify start end, sequence automatically distribute Timestamp according frequency.","code":"print(\n  pd.date_range('2018-01-01', periods=3, freq='H'),\n  pd.date_range(datetime(2018,1,1,12,30), periods=3, freq='H'),\n  pd.date_range(start='2018-01-03-1230', end='2018-01-03-18:30', freq='H'))## DatetimeIndex(['2018-01-01 00:00:00', '2018-01-01 01:00:00', '2018-01-01 02:00:00'], dtype='datetime64[ns]', freq='H') DatetimeIndex(['2018-01-01 12:30:00', '2018-01-01 13:30:00', '2018-01-01 14:30:00'], dtype='datetime64[ns]', freq='H') DatetimeIndex(['2018-01-03 12:30:00', '2018-01-03 13:30:00', '2018-01-03 14:30:00',\n##                '2018-01-03 15:30:00', '2018-01-03 16:30:00', '2018-01-03 17:30:00',\n##                '2018-01-03 18:30:00'],\n##               dtype='datetime64[ns]', freq='H')"},{"path":"pandas.html","id":"daily","chapter":"15 pandas","heading":"15.3.2.2 Daily","text":"frequency Day time specified, output date distributed.\ntime specified, output honor time.","code":"print(\n  pd.date_range(date(2018,1,2), periods=3, freq='D'),\n  pd.date_range('2018-01-01-1230', periods=4, freq='D'))## DatetimeIndex(['2018-01-02', '2018-01-03', '2018-01-04'], dtype='datetime64[ns]', freq='D') DatetimeIndex(['2018-01-01 12:30:00', '2018-01-02 12:30:00', '2018-01-03 12:30:00',\n##                '2018-01-04 12:30:00'],\n##               dtype='datetime64[ns]', freq='D')"},{"path":"pandas.html","id":"first-day-of-month","chapter":"15 pandas","heading":"15.3.2.3 First Day Of Month","text":"Use freq=MS, M stands montly, S stand Start. day specified, sequence start first day following month.","code":"print(\n  pd.date_range('2018-01', periods=4, freq='MS'),\n  pd.date_range('2018-01-09', periods=4, freq='MS'),\n  pd.date_range('2018-01-09 12:30:00', periods=4, freq='MS') )## DatetimeIndex(['2018-01-01', '2018-02-01', '2018-03-01', '2018-04-01'], dtype='datetime64[ns]', freq='MS') DatetimeIndex(['2018-02-01', '2018-03-01', '2018-04-01', '2018-05-01'], dtype='datetime64[ns]', freq='MS') DatetimeIndex(['2018-02-01 12:30:00', '2018-03-01 12:30:00', '2018-04-01 12:30:00',\n##                '2018-05-01 12:30:00'],\n##               dtype='datetime64[ns]', freq='MS')"},{"path":"pandas.html","id":"last-day-of-month","chapter":"15 pandas","heading":"15.3.2.4 Last Day of Month","text":"Sequence always starts end specified month.","code":"print(\n  pd.date_range('2018-01', periods=4, freq='M'),\n  pd.date_range('2018-01-09', periods=4, freq='M'),\n  pd.date_range('2018-01-09 12:30:00', periods=4, freq='M'))## DatetimeIndex(['2018-01-31', '2018-02-28', '2018-03-31', '2018-04-30'], dtype='datetime64[ns]', freq='M') DatetimeIndex(['2018-01-31', '2018-02-28', '2018-03-31', '2018-04-30'], dtype='datetime64[ns]', freq='M') DatetimeIndex(['2018-01-31 12:30:00', '2018-02-28 12:30:00', '2018-03-31 12:30:00',\n##                '2018-04-30 12:30:00'],\n##               dtype='datetime64[ns]', freq='M')"},{"path":"pandas.html","id":"frequency-table-crosstab","chapter":"15 pandas","heading":"15.3.3 Frequency Table (crosstab)","text":"crosstab returns Dataframe Object","code":"crosstab( index = <SeriesObj>, columns = <new_colName> )                # one dimension table\ncrosstab( index = <SeriesObj>, columns = <SeriesObj> )                  # two dimension table\ncrosstab( index = <SeriesObj>, columns = [<SeriesObj1>, <SeriesObj2>] ) # multi dimension table   \ncrosstab( index = <SeriesObj>, columns = <SeriesObj>, margines=True )   # add column and row margins"},{"path":"pandas.html","id":"sample-data-5","chapter":"15 pandas","heading":"15.3.3.1 Sample Data","text":"","code":"n = 200\ncomp = ['C' + i for i in np.random.randint( 1,4, size  = n).astype(str)] # 3x Company\ndept = ['D' + i for i in np.random.randint( 1,6, size  = n).astype(str)] # 5x Department\ngrp =  ['G' + i for i in np.random.randint( 1,3, size  = n).astype(str)] # 2x Groups\nvalue1 = np.random.normal( loc=50 , scale=5 , size = n)\nvalue2 = np.random.normal( loc=20 , scale=3 , size = n)\nvalue3 = np.random.normal( loc=5 , scale=30 , size = n)\n\nmydf = pd.DataFrame({\n    'comp':comp, \n    'dept':dept, \n    'grp': grp,\n    'value1':value1, \n    'value2':value2,\n    'value3':value3 })\nmydf.head()##   comp dept grp     value1     value2     value3\n## 0   C1   D3  G1  44.284002  18.735396 -83.761652\n## 1   C1   D1  G1  38.390748  14.464917 -15.830956\n## 2   C1   D2  G1  53.050089  17.570626  14.829551\n## 3   C2   D2  G2  53.079227  20.622835 -21.445704\n## 4   C2   D1  G1  41.996647  23.145994 -20.663507"},{"path":"pandas.html","id":"one-dimensiontable","chapter":"15 pandas","heading":"15.3.3.2 One DimensionTable","text":"","code":"## Frequency Countn For Company, Department\nprint(\n  pd.crosstab(index=mydf.comp, columns='counter'),'\\n\\n',\n  pd.crosstab(index=mydf.dept, columns='counter'))## col_0  counter\n## comp          \n## C1          64\n## C2          79\n## C3          57 \n## \n##  col_0  counter\n## dept          \n## D1          41\n## D2          50\n## D3          40\n## D4          32\n## D5          37"},{"path":"pandas.html","id":"two-dimension-table","chapter":"15 pandas","heading":"15.3.3.3 Two Dimension Table","text":"","code":"pd.crosstab(index=mydf.comp, columns=mydf.dept)## dept  D1  D2  D3  D4  D5\n## comp                    \n## C1    10  16  14  14  10\n## C2    20  19  14  10  16\n## C3    11  15  12   8  11"},{"path":"pandas.html","id":"higher-dimension-table","chapter":"15 pandas","heading":"15.3.3.4 Higher Dimension Table","text":"Crosstab header multi-levels index one column specified.Select sub-dataframe using multi-level referencing.","code":"tb = pd.crosstab(index=mydf.comp, columns=[mydf.dept, mydf.grp])\nprint( tb, '\\n\\n',\n       tb.columns )## dept  D1     D2     D3    D4    D5   \n## grp   G1 G2  G1  G2 G1 G2 G1 G2 G1 G2\n## comp                                 \n## C1     8  2  12   4  8  6  7  7  5  5\n## C2    13  7   9  10  6  8  5  5  8  8\n## C3     6  5   6   9  8  4  2  6  6  5 \n## \n##  MultiIndex([('D1', 'G1'),\n##             ('D1', 'G2'),\n##             ('D2', 'G1'),\n##             ('D2', 'G2'),\n##             ('D3', 'G1'),\n##             ('D3', 'G2'),\n##             ('D4', 'G1'),\n##             ('D4', 'G2'),\n##             ('D5', 'G1'),\n##             ('D5', 'G2')],\n##            names=['dept', 'grp'])print( 'Under D2:\\n', tb['D2'], '\\n\\n',\n       'Under D2-G2:\\n',tb['D2','G1'])## Under D2:\n##  grp   G1  G2\n## comp        \n## C1    12   4\n## C2     9  10\n## C3     6   9 \n## \n##  Under D2-G2:\n##  comp\n## C1    12\n## C2     9\n## C3     6\n## Name: (D2, G1), dtype: int64"},{"path":"pandas.html","id":"getting-margin","chapter":"15 pandas","heading":"15.3.3.5 Getting Margin","text":"Extend crosstab ‘margin=True’ sum rows/columns, presented new column/row named ‘’.","code":"tb = pd.crosstab(index=mydf.dept, columns=mydf.grp, margins=True)\ntb## grp    G1  G2  All\n## dept              \n## D1     27  14   41\n## D2     27  23   50\n## D3     22  18   40\n## D4     14  18   32\n## D5     19  18   37\n## All   109  91  200print(\n  'Row Sums:     \\n', tb.loc[:,'All'],\n  '\\n\\nColumn Sums:\\n', tb.loc['All'])## Row Sums:     \n##  dept\n## D1      41\n## D2      50\n## D3      40\n## D4      32\n## D5      37\n## All    200\n## Name: All, dtype: int64 \n## \n## Column Sums:\n##  grp\n## G1     109\n## G2      91\n## All    200\n## Name: All, dtype: int64"},{"path":"pandas.html","id":"getting-proportion","chapter":"15 pandas","heading":"15.3.3.6 Getting Proportion","text":"Use matrix operation divide row respective column sum.","code":"tb/tb.loc['All']## grp         G1        G2    All\n## dept                           \n## D1    0.247706  0.153846  0.205\n## D2    0.247706  0.252747  0.250\n## D3    0.201835  0.197802  0.200\n## D4    0.128440  0.197802  0.160\n## D5    0.174312  0.197802  0.185\n## All   1.000000  1.000000  1.000"},{"path":"pandas.html","id":"concatination","chapter":"15 pandas","heading":"15.3.4 Concatination","text":"","code":""},{"path":"pandas.html","id":"sample-data-6","chapter":"15 pandas","heading":"15.3.4.1 Sample Data","text":"","code":"s1 = pd.Series(['A1','A2','A3','A4'])\ns2 = pd.Series(['B1','B2','B3','B4'], name='B')\ns3 = pd.Series(['C1','C2','C3','C4'], name='C')"},{"path":"pandas.html","id":"column-wise","chapter":"15 pandas","heading":"15.3.4.2 Column-Wise","text":"Combining Multiple Series New DataFrameSeries name become column name DataFrame.Series name, default column names DataFrame 0,1,2,3axis=1 means column-wiseAdd Multiple Series Existing DataFrameNo change original DataFrame column nameAdded columns series 0,1,2,3,.. column name","code":"pd.concat([s1,s2,s3, None], axis=1)  ## observed that None is ignored##     0   B   C\n## 0  A1  B1  C1\n## 1  A2  B2  C2\n## 2  A3  B3  C3\n## 3  A4  B4  C4df = pd.DataFrame({ 'A': s1, 'B': s2})\ndf##     A   B\n## 0  A1  B1\n## 1  A2  B2\n## 2  A3  B3\n## 3  A4  B4pd.concat([df,s3,s2,s1, None],axis=1)##     A   B   C   B   0\n## 0  A1  B1  C1  B1  A1\n## 1  A2  B2  C2  B2  A2\n## 2  A3  B3  C3  B3  A3\n## 3  A4  B4  C4  B4  A4"},{"path":"pandas.html","id":"row-wise","chapter":"15 pandas","heading":"15.3.4.3 Row-Wise","text":"","code":""},{"path":"pandas.html","id":"external-data","chapter":"15 pandas","heading":"15.3.5 External Data","text":"","code":""},{"path":"pandas.html","id":"html_table-parser","chapter":"15 pandas","heading":"15.3.5.1 html_table Parser","text":"method require html5lib library.\n- Read web page, create list: contain one dataframes maps html table found\n- Scrap detectable html tables\n- Auto detect column header\n- Auto create index using number starting 0","code":"read_html(url)  # return list of dataframe(s) that maps to web table(s) structuredf_list = pd.read_html('https://www.malaysiastock.biz/Listed-Companies.aspx?type=S&s1=18')  ## read all tables\ndf = df_list[6]  ## get the specific table\n\nprint ('Total Table(s) Found : ', len(df_list), '\\n',\n       'First Table Found:      ',df)## Total Table(s) Found :  14 \n##  First Table Found:                                                          0  \\\n## 0  0 - 9  A  B  C  D  E  F  G  H  I  J  K  L  M  ...   \n## \n##                                                    1  \n## 0  Bursa Malaysia Market Watch  Top Articles  1. ..."},{"path":"pandas.html","id":"csv-writing","chapter":"15 pandas","heading":"15.3.5.2 CSV Writing","text":"SyntaxExample shows column value containing different special character. Note pandas handles well default.file savedAll content retained reading back Pandas","code":"DataFrame.to_csv(\n  path_or_buf=None,   ## if not provided, result is returned as string\n  sep=', ', \n  na_rep='', \n  float_format=None, \n  columns=None,       ## list of columns name to write, if not provided, all columns are written\n  header=True,        ## write out column names\n  index=True,         ## write row label\n  index_label=None, \n  mode='w', \n  encoding=None,      ## if not provided, default to 'utf-8'\n  quoting=None, quotechar='\"', \n  line_terminator=None, \n  chunksize=None, \n  date_format=None, \n  doublequote=True, \n  escapechar=None, \n  decimal='.')\nmydf = pd.DataFrame({'Id':[10,20,30,40], \n                     'Name':  ['Aaa','Bbb','Ccc','Ddd'],\n                     'Funny': [\"world's most \\clever\", \n                     \"Bloody, damn, good\", \n                     \"many\\nmany\\nline\", \n                     'Quoting \"is\" tough']})\nmydf.set_index('Id', inplace=True)\nmydf.to_csv('data/csv_test.csv', index=True)\nmydf##    Name                 Funny\n## Id                           \n## 10  Aaa  world's most \\clever\n## 20  Bbb    Bloody, damn, good\n## 30  Ccc      many\\nmany\\nline\n## 40  Ddd    Quoting \"is\" tough\nsystem('more data\\\\csv_test.csv')## [1] 0pd.read_csv('data/csv_test.csv', index_col='Id')##    Name                 Funny\n## Id                           \n## 10  Aaa  world's most \\clever\n## 20  Bbb    Bloody, damn, good\n## 30  Ccc      many\\nmany\\nline\n## 40  Ddd    Quoting \"is\" tough"},{"path":"pandas.html","id":"csv-reading","chapter":"15 pandas","heading":"15.3.5.3 CSV Reading","text":"SyntaxRefer full codec Python Codec.Default Importindex sequence integer 0,1,2…two data types detection; number (float64/int64) string (object)date parsed, hence stayed stringSpecify Data TypesTo customize data type, use dtype parameter dict definition.Parse DatetimeYou can specify multiple date-alike column parsingParse Datetime, Set Index\n- Specify names date column parse_dates=\n- date set index, type DateTimeIndex","code":"pandas.read_csv( \n    'url or filePath',                     # path to file or url \n    encoding    = 'utf_8',                 # optional: default is 'utf_8'\n    index_col   = ['colName1', ...],       # optional: specify one or more index column\n    parse_dates = ['dateCol1', ...],       # optional: specify multiple string column to convert to date\n    na_values   = ['.','na','NA','N/A'],   # optional: values that is considered NA\n    names       = ['newColName1', ... ],   # optional: overwrite column names\n    thousands   = '.',                     # optional: thousand seperator symbol\n    nrows       = n,                       # optional: load only first n rows\n    skiprows    = 0,                       # optional: don't load first n rows\n    parse_dates = False,                   # List of date column names\n    infer_datetime_format = False          # automatically parse dates\n)goo = pd.read_csv('data/goog.csv', encoding='utf_8')\nprint(goo.head(), '\\n\\n',\n      goo.info())## <class 'pandas.core.frame.DataFrame'>\n## RangeIndex: 61 entries, 0 to 60\n## Data columns (total 6 columns):\n##  #   Column  Non-Null Count  Dtype  \n## ---  ------  --------------  -----  \n##  0   Date    61 non-null     object \n##  1   Open    61 non-null     float64\n##  2   High    61 non-null     float64\n##  3   Low     61 non-null     float64\n##  4   Close   61 non-null     float64\n##  5   Volume  61 non-null     int64  \n## dtypes: float64(4), int64(1), object(1)\n## memory usage: 3.0+ KB\n##          Date        Open        High         Low       Close   Volume\n## 0  12/19/2016  790.219971  797.659973  786.270020  794.200012  1225900\n## 1  12/20/2016  796.760010  798.650024  793.270020  796.419983   925100\n## 2  12/21/2016  795.840027  796.676025  787.099976  794.559998  1208700\n## 3  12/22/2016  792.359985  793.320007  788.580017  791.260010   969100\n## 4  12/23/2016  790.900024  792.739990  787.280029  789.909973   623400 \n## \n##  Noned_types = {'Volume': str}\npd.read_csv('data/goog.csv', dtype=d_types).info()## <class 'pandas.core.frame.DataFrame'>\n## RangeIndex: 61 entries, 0 to 60\n## Data columns (total 6 columns):\n##  #   Column  Non-Null Count  Dtype  \n## ---  ------  --------------  -----  \n##  0   Date    61 non-null     object \n##  1   Open    61 non-null     float64\n##  2   High    61 non-null     float64\n##  3   Low     61 non-null     float64\n##  4   Close   61 non-null     float64\n##  5   Volume  61 non-null     object \n## dtypes: float64(4), object(2)\n## memory usage: 3.0+ KBpd.read_csv('data/goog.csv', parse_dates=['Date']).info()## <class 'pandas.core.frame.DataFrame'>\n## RangeIndex: 61 entries, 0 to 60\n## Data columns (total 6 columns):\n##  #   Column  Non-Null Count  Dtype         \n## ---  ------  --------------  -----         \n##  0   Date    61 non-null     datetime64[ns]\n##  1   Open    61 non-null     float64       \n##  2   High    61 non-null     float64       \n##  3   Low     61 non-null     float64       \n##  4   Close   61 non-null     float64       \n##  5   Volume  61 non-null     int64         \n## dtypes: datetime64[ns](1), float64(4), int64(1)\n## memory usage: 3.0 KBgoo3 = pd.read_csv('data/goog.csv',index_col='Date', parse_dates=['Date'])\ngoo3.info()## <class 'pandas.core.frame.DataFrame'>\n## DatetimeIndex: 61 entries, 2016-12-19 to 2017-03-17\n## Data columns (total 5 columns):\n##  #   Column  Non-Null Count  Dtype  \n## ---  ------  --------------  -----  \n##  0   Open    61 non-null     float64\n##  1   High    61 non-null     float64\n##  2   Low     61 non-null     float64\n##  3   Close   61 non-null     float64\n##  4   Volume  61 non-null     int64  \n## dtypes: float64(4), int64(1)\n## memory usage: 2.9 KB"},{"path":"pandas.html","id":"inspection","chapter":"15 pandas","heading":"15.3.6 Inspection","text":"","code":""},{"path":"pandas.html","id":"structure-info","chapter":"15 pandas","heading":"15.3.6.1 Structure info","text":"info() function print information screen. doesn’t return object","code":"dataframe.info()  # display columns and number of rows (that has no missing data)goo.info()## <class 'pandas.core.frame.DataFrame'>\n## RangeIndex: 61 entries, 0 to 60\n## Data columns (total 6 columns):\n##  #   Column  Non-Null Count  Dtype  \n## ---  ------  --------------  -----  \n##  0   Date    61 non-null     object \n##  1   Open    61 non-null     float64\n##  2   High    61 non-null     float64\n##  3   Low     61 non-null     float64\n##  4   Close   61 non-null     float64\n##  5   Volume  61 non-null     int64  \n## dtypes: float64(4), int64(1), object(1)\n## memory usage: 3.0+ KB"},{"path":"pandas.html","id":"head","chapter":"15 pandas","heading":"15.3.6.2 head","text":"","code":"goo.head()##          Date        Open        High         Low       Close   Volume\n## 0  12/19/2016  790.219971  797.659973  786.270020  794.200012  1225900\n## 1  12/20/2016  796.760010  798.650024  793.270020  796.419983   925100\n## 2  12/21/2016  795.840027  796.676025  787.099976  794.559998  1208700\n## 3  12/22/2016  792.359985  793.320007  788.580017  791.260010   969100\n## 4  12/23/2016  790.900024  792.739990  787.280029  789.909973   623400"},{"path":"pandas.html","id":"class-timestamp","chapter":"15 pandas","heading":"15.4 Class: Timestamp","text":"enhanced version datetime standard library.https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timestamp.html#pandas.Timestamp","code":""},{"path":"pandas.html","id":"constructor-7","chapter":"15 pandas","heading":"15.4.1 Constructor","text":"","code":""},{"path":"pandas.html","id":"from-number","chapter":"15 pandas","heading":"15.4.1.1 From Number","text":"","code":"print( pd.Timestamp(year=2017, month=1, day=1),'\\n',  #date-like numbers\n       pd.Timestamp(2017,1,1), '\\n',                  # date-like numbers\n       pd.Timestamp(2017,12,11,5,45),'\\n',            # datetime-like numbers\n       pd.Timestamp(2017,12,11,5,45,55,999),'\\n',     # + microseconds\n       pd.Timestamp(2017,12,11,5,45,55,999,8),'\\n',   # + nanoseconds\n       type(pd.Timestamp(2017,12,11,5,45,55,999,8)),'\\n')## 2017-01-01 00:00:00 \n##  2017-01-01 00:00:00 \n##  2017-12-11 05:45:00 \n##  2017-12-11 05:45:55.000999 \n##  2017-12-11 05:45:55.000999008 \n##  <class 'pandas._libs.tslibs.timestamps.Timestamp'>"},{"path":"pandas.html","id":"from-string","chapter":"15 pandas","heading":"15.4.1.2 From String","text":"Observe pandas support many string input formatYear Month Day, default timezoneYMD Hour Minute Second MsWith Timezone can included various ways.","code":"print( pd.Timestamp('2017-12-11'),'\\n',   # date-like string: year-month-day\n       pd.Timestamp('2017 12 11'),'\\n',   # date-like string: year-month-day\n       pd.Timestamp('2017 Dec 11'),'\\n',  # date-like string: year-month-day\n       pd.Timestamp('Dec 11, 2017'))      # date-like string: year-month-day## 2017-12-11 00:00:00 \n##  2017-12-11 00:00:00 \n##  2017-12-11 00:00:00 \n##  2017-12-11 00:00:00print( pd.Timestamp('2017-12-11 0545'),'\\n',     ## hour minute\n       pd.Timestamp('2017-12-11-05:45'),'\\n',\n       pd.Timestamp('2017-12-11T0545'),'\\n',\n       pd.Timestamp('2017-12-11 054533'),'\\n',   ## hour minute seconds\n       pd.Timestamp('2017-12-11 05:45:33'))## 2017-12-11 05:45:00 \n##  2017-12-11 05:45:00 \n##  2017-12-11 05:45:00 \n##  2017-12-11 05:45:33 \n##  2017-12-11 05:45:33print( pd.Timestamp('2017-01-01T0545Z'),'\\n',  # GMT \n       pd.Timestamp('2017-01-01T0545+9'),'\\n', # GMT+9\n       pd.Timestamp('2017-01-01T0545+0800'),'\\n',   # GMT+0800\n       pd.Timestamp('2017-01-01 0545', tz='Asia/Singapore'),'\\n')## 2017-01-01 05:45:00+00:00 \n##  2017-01-01 05:45:00+09:00 \n##  2017-01-01 05:45:00+08:00 \n##  2017-01-01 05:45:00+08:00"},{"path":"pandas.html","id":"from-standard-library-datetime-and-date-object","chapter":"15 pandas","heading":"15.4.1.3 From Standard Library datetime and date Object","text":"","code":"print( pd.Timestamp(date(2017,3,5)),'\\n',           # from date\n       pd.Timestamp(datetime(2017,3,5,4,30)),'\\n',  # from datetime\n       pd.Timestamp(datetime(2017,3,5,4,30), tz='Asia/Kuala_Lumpur')) # from datetime, + tz## 2017-03-05 00:00:00 \n##  2017-03-05 04:30:00 \n##  2017-03-05 04:30:00+08:00"},{"path":"pandas.html","id":"attributes-4","chapter":"15 pandas","heading":"15.4.2 Attributes","text":"can tell many things Timestamp object.Note timezone (tz) pytz object.","code":"ts = pd.Timestamp('2017-01-01T054533+0800') # GMT+0800\nprint( ts.month, '\\n',\n       ts.day, '\\n',\n       ts.year, '\\n',\n       ts.hour, '\\n',\n       ts.minute, '\\n',\n       ts.second, '\\n',\n       ts.microsecond, '\\n',\n       ts.nanosecond, '\\n',\n       ts.tz, '\\n',\n       ts.daysinmonth,'\\n',\n       ts.dayofyear, '\\n',\n       ts.is_leap_year, '\\n',\n       ts.is_month_end, '\\n',\n       ts.is_month_start, '\\n',\n       ts.dayofweek)## 1 \n##  1 \n##  2017 \n##  5 \n##  45 \n##  33 \n##  0 \n##  0 \n##  pytz.FixedOffset(480) \n##  31 \n##  1 \n##  False \n##  False \n##  True \n##  6ts1 = pd.Timestamp(datetime(2017,3,5,4,30), tz='Asia/Kuala_Lumpur')   # from datetime, + tz\nts2 = pd.Timestamp('2017-01-01T054533+0800') # GMT+0800\nts3 = pd.Timestamp('2017-01-01T0545')\n\nprint( ts1.tz, 'Type:', type(ts1.tz), '\\n',\n       ts2.tz, 'Type:', type(ts2.tz), '\\n',\n       ts3.tz, 'Type:', type(ts3.tz)  )## Asia/Kuala_Lumpur Type: <class 'pytz.tzfile.Asia/Kuala_Lumpur'> \n##  pytz.FixedOffset(480) Type: <class 'pytz._FixedOffset'> \n##  None Type: <class 'NoneType'>"},{"path":"pandas.html","id":"instance-methods-1","chapter":"15 pandas","heading":"15.4.3 Instance Methods","text":"","code":""},{"path":"pandas.html","id":"atribute-like-methods","chapter":"15 pandas","heading":"15.4.3.1 Atribute-like Methods","text":"","code":"ts = pd.Timestamp(2017,1,1)\nprint( ' Weekday:    ', ts.weekday(), '\\n',\n       'ISO Weekday:',  ts.isoweekday(), '\\n',\n       'Day Name:   ',  ts.day_name(), '\\n',\n       'ISO Calendar:',  ts.isocalendar()\n       )##  Weekday:     6 \n##  ISO Weekday: 7 \n##  Day Name:    Sunday \n##  ISO Calendar: datetime.IsoCalendarDate(year=2016, week=52, weekday=7)"},{"path":"pandas.html","id":"timezones","chapter":"15 pandas","heading":"15.4.3.2 Timezones","text":"Adding Timezones Clock Shiftingtz_localize add timezone, however shift clock.timestamp gotten timezone, can easily shift clock another timezone using tz_convert()Removing TimezoneJust apply None tz_localize remove TZ infomration.","code":"ts = pd.Timestamp(2017,1,10,10,34)        ## No timezone\nts1 = ts.tz_localize('Asia/Kuala_Lumpur')  ## Add timezone\nts2 = ts1.tz_convert('UTC')                 ## Convert timezone\nprint(' Origininal Timestamp           :', ts,  '\\n',\n      'Loacalized Timestamp (added TZ):', ts1, '\\n',\n      'Converted Timestamp (shifted)  :',ts2)##  Origininal Timestamp           : 2017-01-10 10:34:00 \n##  Loacalized Timestamp (added TZ): 2017-01-10 10:34:00+08:00 \n##  Converted Timestamp (shifted)  : 2017-01-10 02:34:00+00:00ts = pd.Timestamp(2017,1,10,10,34)        ## No timezone\nts = ts.tz_localize('Asia/Kuala_Lumpur')  ## Add timezone\nts = ts.tz_localize(None)                 ## Convert timezone\nts## Timestamp('2017-01-10 10:34:00')"},{"path":"pandas.html","id":"formatting","chapter":"15 pandas","heading":"15.4.3.3 Formatting","text":"strftimeUse strftime() customize string format. complete directive, see : https://docs.python.org/3/library/datetime.html#strftime-strptime-behaviorisoformatUse isoformat() format ISO string (without timezone)","code":"ts = pd.Timestamp(2017,1,10,10,34)        ## No timezone\nts = ts.tz_localize('Asia/Kuala_Lumpur')  ## Add timezone\nts.strftime(\"%m/%d\")## '01/10'ts = pd.Timestamp(2017,1,10,10,34)        \nts1 = ts.tz_localize('Asia/Kuala_Lumpur') \nprint( ' ISO Format without TZ:', ts.isoformat(), '\\n',\n       'ISO Format with TZ   :', ts1.isoformat())##  ISO Format without TZ: 2017-01-10T10:34:00 \n##  ISO Format with TZ   : 2017-01-10T10:34:00+08:00"},{"path":"pandas.html","id":"type-conversion","chapter":"15 pandas","heading":"15.4.3.4 Type Conversion","text":"Convert datetime.datetime/dateUse to_pydatetime() convert standard library datetime.datetime. ‘datetime’ object, apply date() get datetime.dateConvert numpy.datetime64Use to_datetime64() convert numpy.datetime64","code":"ts = pd.Timestamp(2017,1,10,7,30,52)\nprint(\n  'Datetime:',  ts.to_pydatetime(), '\\n',\n  'Date Only:', ts.to_pydatetime().date())## Datetime: 2017-01-10 07:30:52 \n##  Date Only: 2017-01-10ts = pd.Timestamp(2017,1,10,7,30,52)\nts.to_datetime64()## numpy.datetime64('2017-01-10T07:30:52.000000000')"},{"path":"pandas.html","id":"ceil","chapter":"15 pandas","heading":"15.4.3.5 ceil","text":"","code":"print( ts.ceil(freq='D') ) # ceiling to day## 2017-01-11 00:00:00"},{"path":"pandas.html","id":"updating","chapter":"15 pandas","heading":"15.4.3.6 Updating","text":"replace()","code":"ts.replace(year=2000, month=1,day=1)## Timestamp('2000-01-01 07:30:52')"},{"path":"pandas.html","id":"class-datetimeindex","chapter":"15 pandas","heading":"15.5 Class: DateTimeIndex","text":"","code":""},{"path":"pandas.html","id":"creating","chapter":"15 pandas","heading":"15.5.1 Creating","text":"Refer Pandas class method .","code":""},{"path":"pandas.html","id":"instance-method-4","chapter":"15 pandas","heading":"15.5.2 Instance Method","text":"","code":""},{"path":"pandas.html","id":"data-type-conversion","chapter":"15 pandas","heading":"15.5.2.1 Data Type Conversion","text":"Convert datetime.datetime\nUse to_pydatetime convert python standard datetime.datetime object","code":"print('Converted to List:', dti.to_pydatetime(), '\\n\\n',\n      'Converted Type:',    type(dti.to_pydatetime()))## Converted to List: [datetime.datetime(2011, 1, 3, 0, 0) datetime.datetime(2018, 4, 13, 0, 0)\n##  datetime.datetime(2018, 3, 1, 7, 30)] \n## \n##  Converted Type: <class 'numpy.ndarray'>"},{"path":"pandas.html","id":"structure-conversion","chapter":"15 pandas","heading":"15.5.2.2 Structure Conversion","text":"Convert Series: to_series\ncreates Series index data valueConvert DataFrame: to_frame()\nconvert single column DataFrame index value","code":"#dti = pd.date_range('2018-02', periods=4, freq='M')\ndti.to_series()## 2011-01-03 00:00:00   2011-01-03 00:00:00\n## 2018-04-13 00:00:00   2018-04-13 00:00:00\n## 2018-03-01 07:30:00   2018-03-01 07:30:00\n## dtype: datetime64[ns]dti.to_frame()##                                       0\n## 2011-01-03 00:00:00 2011-01-03 00:00:00\n## 2018-04-13 00:00:00 2018-04-13 00:00:00\n## 2018-03-01 07:30:00 2018-03-01 07:30:00"},{"path":"pandas.html","id":"attributes-5","chapter":"15 pandas","heading":"15.5.3 Attributes","text":"Timestamp Attributes can used upon DateTimeIndex.","code":"print( dti.weekday, '\\n',\n       dti.month, '\\n',\n       dti.daysinmonth)## Int64Index([0, 4, 3], dtype='int64') \n##  Int64Index([1, 4, 3], dtype='int64') \n##  Int64Index([31, 30, 31], dtype='int64')"},{"path":"pandas.html","id":"class-series","chapter":"15 pandas","heading":"15.6 class: Series","text":"Series allows different data types (object class) element","code":"pandas.Series(data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)\n- data array-like, iterable, dict or scalar\n- If dtype not specified, it will infer from data."},{"path":"pandas.html","id":"constructor-8","chapter":"15 pandas","heading":"15.6.1 Constructor","text":"","code":""},{"path":"pandas.html","id":"empty-series","chapter":"15 pandas","heading":"15.6.1.1 Empty Series","text":"Passing data constructor result empty series. default, empty series dtype float.","code":"s = pd.Series(dtype='object')\nprint (s, '\\n',\n       type(s))## Series([], dtype: object) \n##  <class 'pandas.core.series.Series'>"},{"path":"pandas.html","id":"from-scalar","chapter":"15 pandas","heading":"15.6.1.2 From Scalar","text":"data scalar value, index must provided. value repeated match length index","code":"pd.Series( 99, index = ['a','b','c','d'])## a    99\n## b    99\n## c    99\n## d    99\n## dtype: int64"},{"path":"pandas.html","id":"from-array-like","chapter":"15 pandas","heading":"15.6.1.3 From array-like","text":"listFrom numpy.array\nindex specified, default 0 continue incrementallyFrom DateTimeIndex","code":"pd.Series(['a','b','c','d','e'])           # from Python list## 0    a\n## 1    b\n## 2    c\n## 3    d\n## 4    e\n## dtype: objectpd.Series(np.array(['a','b','c','d','e']))## 0    a\n## 1    b\n## 2    c\n## 3    d\n## 4    e\n## dtype: objectpd.Series(pd.date_range('2011-1-1','2011-1-3'))## 0   2011-01-01\n## 1   2011-01-02\n## 2   2011-01-03\n## dtype: datetime64[ns]"},{"path":"pandas.html","id":"from-dictionary","chapter":"15 pandas","heading":"15.6.1.4 From Dictionary","text":"dictionary key index. Order sorted.index sequence specifeid, Series forllow index order\nObjerve missing data (index without value) marked NaN","code":"pd.Series({'a' : 0., 'c' : 5., 'b' : 2.})## a    0.0\n## c    5.0\n## b    2.0\n## dtype: float64pd.Series({'a' : 0., 'c' : 1., 'b' : 2.},index = ['a','b','c','d'])## a    0.0\n## b    2.0\n## c    1.0\n## d    NaN\n## dtype: float64"},{"path":"pandas.html","id":"specify-index","chapter":"15 pandas","heading":"15.6.1.5 Specify Index","text":"","code":"pd.Series(['a','b','c','d','e'], index=[10,20,30,40,50])## 10    a\n## 20    b\n## 30    c\n## 40    d\n## 50    e\n## dtype: object"},{"path":"pandas.html","id":"mix-element-types","chapter":"15 pandas","heading":"15.6.1.6 Mix Element Types","text":"dType ‘object’ mixture classes","code":"ser = pd.Series(['a',1,2,3])\nprint('Object Type :  ', type(ser),'\\n',\n      'Object dType:  ', ser.dtype,'\\n',\n      'Element 1 Type: ',type(ser[0]),'\\n',\n      'Elmeent 2 Type: ',type(ser[1]))## Object Type :   <class 'pandas.core.series.Series'> \n##  Object dType:   object \n##  Element 1 Type:  <class 'str'> \n##  Elmeent 2 Type:  <class 'int'>"},{"path":"pandas.html","id":"specify-data-types","chapter":"15 pandas","heading":"15.6.1.7 Specify Data Types","text":"default, dtype inferred data.","code":"ser1 = pd.Series([1,2,3])\nser2 = pd.Series([1,2,3], dtype=\"int8\")\nser3 = pd.Series([1,2,3], dtype=\"object\")\n\nprint(' Inferred:        ',ser1.dtype, '\\n',\n      'Specified int8:  ',ser2.dtype, '\\n',\n      'Specified object:',ser3.dtype)##  Inferred:         int64 \n##  Specified int8:   int8 \n##  Specified object: object"},{"path":"pandas.html","id":"accessing-series","chapter":"15 pandas","heading":"15.6.2 Accessing Series","text":"","code":"series     ( single/list/range_of_row_label/number ) # can cause confusion\nseries.loc ( single/list/range_of_row_label )\nseries.iloc( single/list/range_of_row_number )"},{"path":"pandas.html","id":"sample-data-7","chapter":"15 pandas","heading":"15.6.2.1 Sample Data","text":"","code":"s = pd.Series([1,2,3,4,5],index=['a','b','c','d','e']) \ns## a    1\n## b    2\n## c    3\n## d    4\n## e    5\n## dtype: int64"},{"path":"pandas.html","id":"by-row-numbers","chapter":"15 pandas","heading":"15.6.2.2 by Row Number(s)","text":"Single Item.\nNotice inputing number list number give different result.Multiple ItemsRange (First 3)Range (Last 3)Range ()","code":"print( 'Referencing by number:',s.iloc[1],'\\n\\n',\n       '\\nReferencing by list of number:\\n',s.iloc[[1]])## Referencing by number: 2 \n## \n##  \n## Referencing by list of number:\n##  b    2\n## dtype: int64s.iloc[[1,3]] ## b    2\n## d    4\n## dtype: int64s.iloc[:3]## a    1\n## b    2\n## c    3\n## dtype: int64s.iloc[-3:]## c    3\n## d    4\n## e    5\n## dtype: int64s.iloc[2:3]## c    3\n## dtype: int64"},{"path":"pandas.html","id":"by-indexes","chapter":"15 pandas","heading":"15.6.2.3 by Index(es)","text":"Single Label. Notice difference referencing input: single index list index.Warning: index invalid, result error.Multiple LabelsIf index found, return NaN** Range Labels **","code":"print( s.loc['c'], '\\n',\n       s[['c']])## 3 \n##  c    3\n## dtype: int64s.loc[['k','c']]## Error in py_call_impl(callable, dots$args, dots$keywords): KeyError: \"['k'] not in index\"s.loc['b':'d']## b    2\n## c    3\n## d    4\n## dtype: int64"},{"path":"pandas.html","id":"filtering","chapter":"15 pandas","heading":"15.6.2.4 Filtering","text":"Use logical array filterUse \nmethod application -idiom. element calling Series, cond True element used; otherwise used.","code":"s = pd.Series(range(1,8))\ns[s<5]## 0    1\n## 1    2\n## 2    3\n## 3    4\n## dtype: int64.where(cond, other=nan, inplace=False)print(s.where(s<4),'\\n\\n',\n      s.where(s<4,other=None) )## 0    1.0\n## 1    2.0\n## 2    3.0\n## 3    NaN\n## 4    NaN\n## 5    NaN\n## 6    NaN\n## dtype: float64 \n## \n##  0    1.0\n## 1    2.0\n## 2    3.0\n## 3    NaN\n## 4    NaN\n## 5    NaN\n## 6    NaN\n## dtype: float64"},{"path":"pandas.html","id":"updating-series","chapter":"15 pandas","heading":"15.6.3 Updating Series","text":"","code":""},{"path":"pandas.html","id":"by-row-numbers-1","chapter":"15 pandas","heading":"15.6.3.1 by Row Number(s)","text":"","code":"s = pd.Series(range(1,7), index=['a','b','c','d','e','f'])\ns[2] = 999\ns[[3,4]] = 888,777\ns## a      1\n## b      2\n## c    999\n## d    888\n## e    777\n## f      6\n## dtype: int64"},{"path":"pandas.html","id":"by-indexes-1","chapter":"15 pandas","heading":"15.6.3.2 by Index(es)","text":"","code":"s = pd.Series(range(1,7), index=['a','b','c','d','e','f'])\ns['e'] = 888\ns[['c','d']] = 777,888\ns## a      1\n## b      2\n## c    777\n## d    888\n## e    888\n## f      6\n## dtype: int64"},{"path":"pandas.html","id":"series-attributes","chapter":"15 pandas","heading":"15.6.4 Series Attributes","text":"","code":""},{"path":"pandas.html","id":"the-data","chapter":"15 pandas","heading":"15.6.4.1 The Data","text":"","code":"s = pd.Series([1,2,3,4,5],index=['a','b','c','d','e'],name='SuperHero') \ns## a    1\n## b    2\n## c    3\n## d    4\n## e    5\n## Name: SuperHero, dtype: int64"},{"path":"pandas.html","id":"the-attributes","chapter":"15 pandas","heading":"15.6.4.2 The Attributes","text":"","code":"print( ' Series Index:    ',s.index, '\\n',\n       'Series dType:    ', s.dtype, '\\n',\n       'Series Size:     ', s.size, '\\n',\n       'Series Shape:    ', s.shape, '\\n',\n       'Series Dimension:', s.ndim)##  Series Index:     Index(['a', 'b', 'c', 'd', 'e'], dtype='object') \n##  Series dType:     int64 \n##  Series Size:      5 \n##  Series Shape:     (5,) \n##  Series Dimension: 1"},{"path":"pandas.html","id":"instance-methods-2","chapter":"15 pandas","heading":"15.6.5 Instance Methods","text":"","code":""},{"path":"pandas.html","id":"index-manipulation","chapter":"15 pandas","heading":"15.6.5.1 Index Manipulation","text":".rename_axis().reset_index()Resetting index :\n- Convert index normal column, column named ‘index’\n- Index renumbered 1,2,3\n- Return DataFrame (became two columns)","code":"s.rename_axis('haribulan')## haribulan\n## a    1\n## b    2\n## c    3\n## d    4\n## e    5\n## Name: SuperHero, dtype: int64s.reset_index()##   index  SuperHero\n## 0     a          1\n## 1     b          2\n## 2     c          3\n## 3     d          4\n## 4     e          5"},{"path":"pandas.html","id":"structure-conversion-1","chapter":"15 pandas","heading":"15.6.5.2 Structure Conversion","text":"series structure contain value (numpy array), dtype (data type numpy array).Use values retrieve `numpy.ndarray. Use dtype understand data type.Convert List using .tolist()","code":"s = pd.Series([1,2,3,4,5])\nprint(' Series value:      ', s.values, '\\n', \n      'Series value type: ',  type(s.values), '\\n',\n      'Series dtype:      ',  s.dtype)##  Series value:       [1 2 3 4 5] \n##  Series value type:  <class 'numpy.ndarray'> \n##  Series dtype:       int64pd.Series.tolist(s)## [1, 2, 3, 4, 5]"},{"path":"pandas.html","id":"datatype-conversion","chapter":"15 pandas","heading":"15.6.5.3 DataType Conversion","text":"Use astype() convert another numpy supproted datatypes, results new Series.Warning: casting incompatible type result error","code":"s.astype('int8')## 0    1\n## 1    2\n## 2    3\n## 3    4\n## 4    5\n## dtype: int8"},{"path":"pandas.html","id":"series-operators","chapter":"15 pandas","heading":"15.6.6 Series Operators","text":"result applying operator (arithmetic logic) Series object returns new Series object","code":""},{"path":"pandas.html","id":"arithmetic-operator","chapter":"15 pandas","heading":"15.6.6.1 Arithmetic Operator","text":"Apply One Series ObjectApply Two Series Objects","code":"s1 = pd.Series( [100,200,300,400,500] )\ns2 = pd.Series( [10, 20, 30, 40, 50] )s1 - 100## 0      0\n## 1    100\n## 2    200\n## 3    300\n## 4    400\n## dtype: int64s1 - s2## 0     90\n## 1    180\n## 2    270\n## 3    360\n## 4    450\n## dtype: int64"},{"path":"pandas.html","id":"logic-operator","chapter":"15 pandas","heading":"15.6.6.2 Logic Operator","text":"Apply logic operator Series return new Series boolean resultThis can used Series DataFrame filtering","code":"bs = pd.Series(range(0,10))\nbs>3## 0    False\n## 1    False\n## 2    False\n## 3    False\n## 4     True\n## 5     True\n## 6     True\n## 7     True\n## 8     True\n## 9     True\n## dtype: bool~((bs>3) & (bs<8) | (bs>7))## 0     True\n## 1     True\n## 2     True\n## 3     True\n## 4    False\n## 5    False\n## 6    False\n## 7    False\n## 8    False\n## 9    False\n## dtype: bool"},{"path":"pandas.html","id":"series-.str-accesor","chapter":"15 pandas","heading":"15.6.7 Series .str Accesor","text":"underlying data str type, pandas exposed various properties methos str accessor.Available FunctionsNearly Python’s built-string methods mirrored Pandas vectorized string method. list Pandas str methods mirror Python string methods:len() lower() translate() islower()\nljust() upper() startswith() isupper()\nrjust() find() endswith() isnumeric()\ncenter() rfind() isalnum() isdecimal()\nzfill() index() isalpha() split()\nstrip() rindex() isdigit() rsplit()\nrstrip() capitalize() isspace() partition()\nlstrip() swapcase() istitle() rpartition()","code":"SeriesObj.str.operatorFunction()"},{"path":"pandas.html","id":"regex-extractor","chapter":"15 pandas","heading":"15.6.7.1 Regex Extractor","text":"Extract capture groups regex pattern, default DataFrame (expand=True).ouptut single columne, use expand=False make result Series, instead DataFrame.","code":"Series.str.extract(self, pat, flags=0, expand=True)\n- expand=True: if result is single column, make it a Series instead of Dataframe.s = pd.Series(['a1', 'b2', 'c3'])\nprint( \n  ' Extracted Dataframe:\\n', s.str.extract(r'([ab])(\\d)'),'\\n\\n',\n  'Extracted Dataframe witn Names:\\n', s.str.extract(r'(?P<Letter>[ab])(\\d)'))##  Extracted Dataframe:\n##       0    1\n## 0    a    1\n## 1    b    2\n## 2  NaN  NaN \n## \n##  Extracted Dataframe witn Names:\n##    Letter    1\n## 0      a    1\n## 1      b    2\n## 2    NaN  NaNr = s.str.extract(r'[ab](\\d)', expand=False)\nprint( r, '\\n\\n', type(r) )## 0      1\n## 1      2\n## 2    NaN\n## dtype: object \n## \n##  <class 'pandas.core.series.Series'>"},{"path":"pandas.html","id":"character-extractor","chapter":"15 pandas","heading":"15.6.7.2 Character Extractor","text":"startwithSlicing","code":"monte = pd.Series(['Graham Chapman', 'John Cleese', 'Terry Gilliam',\n                   'Eric Idle', 'Terry Jones', 'Michael Palin'])\nmonte## 0    Graham Chapman\n## 1       John Cleese\n## 2     Terry Gilliam\n## 3         Eric Idle\n## 4       Terry Jones\n## 5     Michael Palin\n## dtype: objectmonte.str.startswith('T')## 0    False\n## 1    False\n## 2     True\n## 3    False\n## 4     True\n## 5    False\n## dtype: boolmonte.str[0:3]## 0    Gra\n## 1    Joh\n## 2    Ter\n## 3    Eri\n## 4    Ter\n## 5    Mic\n## dtype: object"},{"path":"pandas.html","id":"splitting","chapter":"15 pandas","heading":"15.6.7.3 Splitting","text":"Split strings around given separator/delimiter either string regex.str.split() default, split split item arrayexpand=True return dataframe instead series. default, expand split possible columns.possible limit number columns splittedstr.rsplit()rsplit stands reverse split, works way, except reversed","code":"Series.str.split(self, pat=None, n=-1, expand=False)\n- pat: can be string or regexs = pd.Series(['a_b_c', 'c_d_e', np.nan, 'f_g_h_i_j'])\ns## 0        a_b_c\n## 1        c_d_e\n## 2          NaN\n## 3    f_g_h_i_j\n## dtype: objects.str.split('_')## 0          [a, b, c]\n## 1          [c, d, e]\n## 2                NaN\n## 3    [f, g, h, i, j]\n## dtype: objectprint( s.str.split('_', expand=True) )##      0    1    2     3     4\n## 0    a    b    c  None  None\n## 1    c    d    e  None  None\n## 2  NaN  NaN  NaN   NaN   NaN\n## 3    f    g    h     i     jprint( s.str.split('_', expand=True, n=1) )##      0        1\n## 0    a      b_c\n## 1    c      d_e\n## 2  NaN      NaN\n## 3    f  g_h_i_jprint( s.str.rsplit('_', expand=True, n=1) )##          0    1\n## 0      a_b    c\n## 1      c_d    e\n## 2      NaN  NaN\n## 3  f_g_h_i    j"},{"path":"pandas.html","id":"case-conversion","chapter":"15 pandas","heading":"15.6.7.4 Case Conversion","text":"","code":"SeriesObj.str.upper()\nSeriesObj.str.lower()\nSeriesObj.str.capitalize()s = pd.Series(['A', 'B', 'C', 'aAba', 'bBaca', np.nan, 'cCABA', 'dog', 'cat'])\nprint( s.str.upper(), '\\n',\n       s.str.capitalize())## 0        A\n## 1        B\n## 2        C\n## 3     AABA\n## 4    BBACA\n## 5      NaN\n## 6    CCABA\n## 7      DOG\n## 8      CAT\n## dtype: object \n##  0        A\n## 1        B\n## 2        C\n## 3     Aaba\n## 4    Bbaca\n## 5      NaN\n## 6    Ccaba\n## 7      Dog\n## 8      Cat\n## dtype: object"},{"path":"pandas.html","id":"number-of-characters","chapter":"15 pandas","heading":"15.6.7.5 Number of Characters","text":"","code":"s.str.len()## 0    1.0\n## 1    1.0\n## 2    1.0\n## 3    4.0\n## 4    5.0\n## 5    NaN\n## 6    5.0\n## 7    3.0\n## 8    3.0\n## dtype: float64"},{"path":"pandas.html","id":"string-indexing","chapter":"15 pandas","heading":"15.6.7.6 String Indexing","text":"return specified character item.","code":"s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan,'CABA', 'dog', 'cat'])\ns.str[0].values    # first char## array(['A', 'B', 'C', 'A', 'B', nan, 'C', 'd', 'c'], dtype=object)s.str[0:2].values  # first and second char## array(['A', 'B', 'C', 'Aa', 'Ba', nan, 'CA', 'do', 'ca'], dtype=object)"},{"path":"pandas.html","id":"series-substring-extraction","chapter":"15 pandas","heading":"15.6.7.7 Series Substring Extraction","text":"Sample DataExtract absed regex matching\n… improve …","code":"s = pd.Series(['a1', 'b2', 'c3'])\ns## 0    a1\n## 1    b2\n## 2    c3\n## dtype: objecttype(s.str.extract('([ab])(\\d)', expand=False))## <class 'pandas.core.frame.DataFrame'>"},{"path":"pandas.html","id":"series-.dt-accessor","chapter":"15 pandas","heading":"15.6.8 Series .dt Accessor","text":"underlying data datetime64 type, pandas exposed various properties methos dt accessor.","code":""},{"path":"pandas.html","id":"sample-data-8","chapter":"15 pandas","heading":"15.6.8.1 Sample Data","text":"","code":"s = pd.Series([\n    datetime(2000,1,1,0,0,0),\n    datetime(1999,12,15,12,34,55),\n    datetime(2020,3,8,5,7,12),\n    datetime(2018,1,1,0,0,0),\n    datetime(2003,3,4,5,6,7)\n])\ns## 0   2000-01-01 00:00:00\n## 1   1999-12-15 12:34:55\n## 2   2020-03-08 05:07:12\n## 3   2018-01-01 00:00:00\n## 4   2003-03-04 05:06:07\n## dtype: datetime64[ns]"},{"path":"pandas.html","id":"convert-to","chapter":"15 pandas","heading":"15.6.8.2 Convert To","text":"datetime.datetime\nUse to_pydatetime() convert numpy.array standard library datetime.datetimedatetime.date\nUse dt.date convert pandas.Series standard library datetime.date\npossible pandas.Series datetime.datetime ? , Pandas want Timestamp.","code":"pdt  = s.dt.to_pydatetime()\nprint( type(pdt) )## <class 'numpy.ndarray'>pdt## array([datetime.datetime(2000, 1, 1, 0, 0),\n##        datetime.datetime(1999, 12, 15, 12, 34, 55),\n##        datetime.datetime(2020, 3, 8, 5, 7, 12),\n##        datetime.datetime(2018, 1, 1, 0, 0),\n##        datetime.datetime(2003, 3, 4, 5, 6, 7)], dtype=object)sdt = s.dt.date\nprint( type(sdt[1] ))## <class 'datetime.date'>print( type(sdt))## <class 'pandas.core.series.Series'>sdt## 0    2000-01-01\n## 1    1999-12-15\n## 2    2020-03-08\n## 3    2018-01-01\n## 4    2003-03-04\n## dtype: object"},{"path":"pandas.html","id":"timestamp-attributes","chapter":"15 pandas","heading":"15.6.8.3 Timestamp Attributes","text":"Series::DateTime object support properties:\n- date\n- month\n- day\n- year\n- dayofweek\n- dayofyear\n- weekday\n- weekday_name\n- quarter\n- daysinmonth\n- hour\n- minuteFull list :https://pandas.pydata.org/pandas-docs/stable/reference/series.html#datetimelike-properties","code":"s.dt.date## 0    2000-01-01\n## 1    1999-12-15\n## 2    2020-03-08\n## 3    2018-01-01\n## 4    2003-03-04\n## dtype: objects.dt.month## 0     1\n## 1    12\n## 2     3\n## 3     1\n## 4     3\n## dtype: int64s.dt.dayofweek## 0    5\n## 1    2\n## 2    6\n## 3    0\n## 4    1\n## dtype: int64s.dt.weekday## 0    5\n## 1    2\n## 2    6\n## 3    0\n## 4    1\n## dtype: int64s.dt.quarter## 0    1\n## 1    4\n## 2    1\n## 3    1\n## 4    1\n## dtype: int64s.dt.daysinmonth## 0    31\n## 1    31\n## 2    31\n## 3    31\n## 4    31\n## dtype: int64s.dt.time   # extract time as time Object## 0    00:00:00\n## 1    12:34:55\n## 2    05:07:12\n## 3    00:00:00\n## 4    05:06:07\n## dtype: objects.dt.hour  # extract hour as integer## 0     0\n## 1    12\n## 2     5\n## 3     0\n## 4     5\n## dtype: int64s.dt.minute # extract minute as integer## 0     0\n## 1    34\n## 2     7\n## 3     0\n## 4     6\n## dtype: int64"},{"path":"pandas.html","id":"class-dataframe","chapter":"15 pandas","heading":"15.7 Class: DataFrame","text":"","code":""},{"path":"pandas.html","id":"constructor-creation","chapter":"15 pandas","heading":"15.7.1 Constructor (Creation)","text":"pd.DataFrame() constructor creates DataFrame object.index (row label) column names specified (induced data source), default 0,1,2,3…Specify Row Label Column Header columns index parameters constructor.columns specified data source keys can used column names, pandas select column names order specified columns parameter.index row label used interchangeably book","code":""},{"path":"pandas.html","id":"empty-dataframe","chapter":"15 pandas","heading":"15.7.1.1 Empty DataFrame","text":"default, empty dataframe contain columns index.Even though empty, can still initialize Index Columns.initializing multiple empty DataFrame (one line), empty DataFrame refers memory location. Meaning contain similar data.","code":"empty_df1 = pd.DataFrame()\nempty_df2 = pd.DataFrame()\n\nempty_df1\nid(empty_df1)\nid(empty_df2)## Empty DataFrame\n## Columns: []\n## Index: []\n## 2858668190400\n## 2858668190784## empty dataframe with columns\nempty_df = pd.DataFrame(columns=['A','B','C'])\nempty_df  ## index is empty\n\n## empty dataframe with columns and index\nempty_df = pd.DataFrame(columns=['A','B','C'], index=[1,2,3])\nempty_df## Empty DataFrame\n## Columns: [A, B, C]\n## Index: []\n##      A    B    C\n## 1  NaN  NaN  NaN\n## 2  NaN  NaN  NaN\n## 3  NaN  NaN  NaNempty_df1 = empty_df2 = pd.DataFrame()\nid(empty_df1)\nid(empty_df2)## 2858668188192\n## 2858668188192"},{"path":"pandas.html","id":"from-row-oriented-data-list-of-lists","chapter":"15 pandas","heading":"15.7.1.2 From Row Oriented Data (List of Lists)","text":"Create DataFrame object List ListsUse `columns’ select columns preferred order.","code":"DataFrame( [row_list1, row_list2, row_list3] )\nDataFrame( [row_list1, row_list2, row_list3], column = columnName_list )\nDataFrame( [row_list1, row_list2, row_list3], index  = row_label_list )data = [  [101, 'Alice',  40000, 2017],\n          [102, 'Bob',    24000, 2017], \n          [103, 'Charles',31000, 2017]]\n\n## Initialize with default row label and column names  \npd.DataFrame(data)##      0        1      2     3\n## 0  101    Alice  40000  2017\n## 1  102      Bob  24000  2017\n## 2  103  Charles  31000  2017## Initialize with column names and row index\ncol_names  =  ['empID','name','salary','year']\nrow_labels =  ['r1','r2','r3']\npd.DataFrame(data, columns=col_names, index=row_labels)##     empID     name  salary  year\n## r1    101    Alice   40000  2017\n## r2    102      Bob   24000  2017\n## r3    103  Charles   31000  2017"},{"path":"pandas.html","id":"from-record-oriented-data-list-of-dict","chapter":"15 pandas","heading":"15.7.1.3 From Record Oriented Data (List of Dict)","text":"Create DataFrame object List Dicts.default, Column Name follow Dictionary Key, unless manually specified.Certain dict object may missing keys, assumed NaN pandas.Use `columns’ select columns preferred order.","code":"DataFrame( [dict1, dict2, dict3] )\nDataFrame( [dict1, dict2, dict3], column = column_list )\nDataFrame( [dict1, dict2, dict3], index  = row_label_list )data = [\n  {\"name\":\"Yong\", \"id\":1,\"zkey\":101},\n  {\"name\":\"Gan\",  \"id\":2           }]  ## missing zkey in this record\n\n## Default Index and include all detected columns\npd.DataFrame(data)##    name  id   zkey\n## 0  Yong   1  101.0\n## 1   Gan   2    NaN## specify Index, must be same length of DataFrame\npd.DataFrame(data, index=['row1','row2'])##       name  id   zkey\n## row1  Yong   1  101.0\n## row2   Gan   2    NaN## Filter Which Columns To Include, in the prefered order\npd.DataFrame(data, columns=['zkey','name'])##     zkey  name\n## 0  101.0  Yong\n## 1    NaN   Gan"},{"path":"pandas.html","id":"from-column-oriented-data-dict-of-lists","chapter":"15 pandas","heading":"15.7.1.4 From Column Oriented Data (Dict of Lists)","text":"Create DataFrame object Dict Lists.Constructor arrange columns according dict keys order default, unless columns specified.Use `columns’ select columns preferred order. NaN column returned exist.","code":"DataFrame(  data = {'column1': list1,\n                    'column2': list2,\n                    'column3': list3 } , \n            index    = row_label_list, \n            columns  = column_list)## columns arrangement default to dict's keys\ndata = {'empID':  [100,      101,    102,      103,     104],\n        'year1':   [2017,     2017,   2017,      2018,    2018],\n        'year2':   [2027,     2027,   2027,      2028,    2028],\n        'salary': [40000,    24000,  31000,     20000,   30000],\n        'name':   ['Alice', 'Bob',  'Charles', 'David', 'Eric']}\n\n## Default Index and Include All Columns\npd.DataFrame(data)##    empID  year1  year2  salary     name\n## 0    100   2017   2027   40000    Alice\n## 1    101   2017   2027   24000      Bob\n## 2    102   2017   2027   31000  Charles\n## 3    103   2018   2028   20000    David\n## 4    104   2018   2028   30000     Eric## Select What Columns To Show (and its order) Specify row label.\npd.DataFrame(data, columns=['name','salary','year1','year2','not_exist'], index=data.get('empID'))##         name  salary  year1  year2 not_exist\n## 100    Alice   40000   2017   2027       NaN\n## 101      Bob   24000   2017   2027       NaN\n## 102  Charles   31000   2017   2027       NaN\n## 103    David   20000   2018   2028       NaN\n## 104     Eric   30000   2018   2028       NaN"},{"path":"pandas.html","id":"operators-2","chapter":"15 pandas","heading":"15.7.2 Operators","text":"","code":""},{"path":"pandas.html","id":"sample-data-9","chapter":"15 pandas","heading":"15.7.2.1 Sample Data","text":"Two dataframes created, 3 columns 3 rows.However, two matching column row names.shall notice operator perform cell-wise, honoring row/column name.","code":"df1 = pd.DataFrame(data=\n  {'idx': ['row1','row2','row3'],\n   'x': [10, 20, 30],\n   'y': [1,2,3],\n   'z': [0.1, 0.2, 0.3]}).set_index('idx')\n   \ndf2 = pd.DataFrame(data=\n  {'idx': ['row1','row2','row4'],\n   'x': [13, 23, 33],\n   'z': [0.1, 0.2, 0.3],\n   'k': [11,21,31]}).set_index('idx')"},{"path":"pandas.html","id":"addition","chapter":"15 pandas","heading":"15.7.2.2 Addition","text":"Adding Two DataFrameWhen Using + operator, non-matching row/column names result NA..add(), result + default.However, add supports fill_value= parameter. specified, ONE-SIDED none matching cells assumed value specified fill_value. -SIDED non matching cells results NaN.Adding Series DataFrameSpecify appropriate axis depending orientation series data.Column Row names respected operation.However, fill_value applicable available Series.Columns rows Series non-matching DataFrame, created result. behavior similar adding two DataFrames.","code":"df1 + df2\ndf1.add(df2)\ndf1.add(df2, fill_value=1)##        k     x   y    z\n## idx                    \n## row1 NaN  23.0 NaN  0.2\n## row2 NaN  43.0 NaN  0.4\n## row3 NaN   NaN NaN  NaN\n## row4 NaN   NaN NaN  NaN\n##        k     x   y    z\n## idx                    \n## row1 NaN  23.0 NaN  0.2\n## row2 NaN  43.0 NaN  0.4\n## row3 NaN   NaN NaN  NaN\n## row4 NaN   NaN NaN  NaN\n##          k     x    y    z\n## idx                       \n## row1  12.0  23.0  2.0  0.2\n## row2  22.0  43.0  3.0  0.4\n## row3   NaN  31.0  4.0  1.3\n## row4  32.0  34.0  NaN  1.3## Series to add into Rows\ns3 = pd.Series([1,1,1], index=['row1','row2','row4'])\n\n## Series to add into Columns\ns4 = pd.Series([3,3,3], index=['x','y','s'])\n\nprint('Original DataFrame:\\n',df1,'\\n\\n',\n      'Add Series as Rows: \\n', df1.add(s3, axis=0), '\\n\\n',\n      'Add Series as Columns: \\n', df1.add(s4, axis=1))## Original DataFrame:\n##         x  y    z\n## idx             \n## row1  10  1  0.1\n## row2  20  2  0.2\n## row3  30  3  0.3 \n## \n##  Add Series as Rows: \n##           x    y    z\n## row1  11.0  2.0  1.1\n## row2  21.0  3.0  1.2\n## row3   NaN  NaN  NaN\n## row4   NaN  NaN  NaN \n## \n##  Add Series as Columns: \n##         s     x    y   z\n## idx                    \n## row1 NaN  13.0  4.0 NaN\n## row2 NaN  23.0  5.0 NaN\n## row3 NaN  33.0  6.0 NaN"},{"path":"pandas.html","id":"substraction","chapter":"15 pandas","heading":"15.7.2.3 Substraction","text":"Refer .add() fill_value explanation.","code":"df2 - df1\ndf2.sub(df1,fill_value=1000)##        k    x   y    z\n## idx                   \n## row1 NaN  3.0 NaN  0.0\n## row2 NaN  3.0 NaN  0.0\n## row3 NaN  NaN NaN  NaN\n## row4 NaN  NaN NaN  NaN\n##           k      x      y      z\n## idx                             \n## row1 -989.0    3.0  999.0    0.0\n## row2 -979.0    3.0  998.0    0.0\n## row3    NaN  970.0  997.0  999.7\n## row4 -969.0 -967.0    NaN -999.7"},{"path":"pandas.html","id":"operator-1","chapter":"15 pandas","heading":"15.7.2.4 Operator &","text":"Non matching columns returns NaN.Matching columns True value returns TrueMatching columns True False returns False","code":"df1>5\ndf2<20\n(df1>5) & (df2<20)##          x      y      z\n## idx                     \n## row1  True  False  False\n## row2  True  False  False\n## row3  True  False  False\n##           x     z      k\n## idx                     \n## row1   True  True   True\n## row2  False  True  False\n## row4  False  True  False\n##        k      x   y      z\n## idx                       \n## row1 NaN   True NaN  False\n## row2 NaN  False NaN  False\n## row3 NaN  False NaN  False\n## row4 NaN  False NaN  False"},{"path":"pandas.html","id":"attributes-6","chapter":"15 pandas","heading":"15.7.3 Attributes","text":"","code":"df = pd.DataFrame(data)\ndf##    empID  year1  year2  salary     name\n## 0    100   2017   2027   40000    Alice\n## 1    101   2017   2027   24000      Bob\n## 2    102   2017   2027   31000  Charles\n## 3    103   2018   2028   20000    David\n## 4    104   2018   2028   30000     Ericdf.shape          ## tuple (rows, columns)\ndf.index          ## default index is RangeIndex \ndf.index.values   ## array of integer\ndf.columns        ## array of string\ndf.columns.values ## array of string\ndf.values         ## array of list## (5, 5)\n## RangeIndex(start=0, stop=5, step=1)\n## array([0, 1, 2, 3, 4], dtype=int64)\n## Index(['empID', 'year1', 'year2', 'salary', 'name'], dtype='object')\n## array(['empID', 'year1', 'year2', 'salary', 'name'], dtype=object)\n## array([[100, 2017, 2027, 40000, 'Alice'],\n##        [101, 2017, 2027, 24000, 'Bob'],\n##        [102, 2017, 2027, 31000, 'Charles'],\n##        [103, 2018, 2028, 20000, 'David'],\n##        [104, 2018, 2028, 30000, 'Eric']], dtype=object)"},{"path":"pandas.html","id":"index-manipulation-1","chapter":"15 pandas","heading":"15.7.4 Index Manipulation","text":"","code":""},{"path":"pandas.html","id":"sample-data-10","chapter":"15 pandas","heading":"15.7.4.1 Sample Data","text":"","code":"df##    empID  year1  year2  salary     name\n## 0    100   2017   2027   40000    Alice\n## 1    101   2017   2027   24000      Bob\n## 2    102   2017   2027   31000  Charles\n## 3    103   2018   2028   20000    David\n## 4    104   2018   2028   30000     Eric"},{"path":"pandas.html","id":"convert-column-to-index","chapter":"15 pandas","heading":"15.7.4.2 Convert Column To Index","text":"Specified column turn Indexinplace=True means don’t create new dataframe. Modify existing DataFrame.inplace=False means return new DataFrame","code":"set_index('column_name', inplace=False)df.index   ## 0,1,2,3,...\ndf.set_index('empID',inplace=True)\ndf.index   ## 100,101,102,etc\ndf## RangeIndex(start=0, stop=5, step=1)\n## Int64Index([100, 101, 102, 103, 104], dtype='int64', name='empID')\n##        year1  year2  salary     name\n## empID                               \n## 100     2017   2027   40000    Alice\n## 101     2017   2027   24000      Bob\n## 102     2017   2027   31000  Charles\n## 103     2018   2028   20000    David\n## 104     2018   2028   30000     Eric"},{"path":"pandas.html","id":"convert-index-to-column","chapter":"15 pandas","heading":"15.7.4.3 Convert Index To Column","text":"Resetting index re-sequence index 0,1,2 etc.Old index column converted back normal column, name retained column name.Operation support inplace option.","code":"df.reset_index(inplace=True)\ndf##    empID  year1  year2  salary     name\n## 0    100   2017   2027   40000    Alice\n## 1    101   2017   2027   24000      Bob\n## 2    102   2017   2027   31000  Charles\n## 3    103   2018   2028   20000    David\n## 4    104   2018   2028   30000     Eric"},{"path":"pandas.html","id":"updating-index-.index","chapter":"15 pandas","heading":"15.7.4.4 Updating Index ( .index= )","text":"simply replace index new values.Number elements new index must match length DataFrame, otherwise error.Although label allowed repeat, deprecated future.operation reversible.","code":"df.index = [201, 202, 203, 204, 205]\ndf##      empID  year1  year2  salary     name\n## 201    100   2017   2027   40000    Alice\n## 202    101   2017   2027   24000      Bob\n## 203    102   2017   2027   31000  Charles\n## 204    103   2018   2028   20000    David\n## 205    104   2018   2028   30000     Eric"},{"path":"pandas.html","id":"reordering-index-.reindex","chapter":"15 pandas","heading":"15.7.4.5 Reordering Index (.reindex )","text":"Returns new DataFrame according order specified. ‘inplace’ option.Doesn’t work duplicate labels exists (Error)matching rows returned.Non matching index number results NaN, without Error.Change order Index, always return new dataframe","code":"df.reindex([203,202,300])##      empID   year1   year2   salary     name\n## 203  102.0  2017.0  2027.0  31000.0  Charles\n## 202  101.0  2017.0  2027.0  24000.0      Bob\n## 300    NaN     NaN     NaN      NaN      NaN"},{"path":"pandas.html","id":"rename-axis","chapter":"15 pandas","heading":"15.7.4.6 Rename Axis","text":"Example renamed axis index.Use axis=0 row index (default), use axis=1 column index.\n= Use inplace option apply changes DataFrame, otherwise return new DataFrame","code":"df.rename_axis('super_id', axis=0, inplace=True)\ndf##           empID  year1  year2  salary     name\n## super_id                                      \n## 201         100   2017   2027   40000    Alice\n## 202         101   2017   2027   24000      Bob\n## 203         102   2017   2027   31000  Charles\n## 204         103   2018   2028   20000    David\n## 205         104   2018   2028   30000     Eric"},{"path":"pandas.html","id":"subsetting-rows","chapter":"15 pandas","heading":"15.7.5 Subsetting Rows","text":"","code":"dataframe.loc[ row_label       ]  # return series, single row\ndataframe.loc[ row_label_list  ]  # multiple rows\ndataframe.loc[ boolean_list    ]  # multiple rows\n\ndataframe.iloc[ row_number       ]  # return series, single row\ndataframe.iloc[ row_number_list  ]  # multiple rows\ndataframe.iloc[ number_range     ]  # multiple rows\n\ndataframe.sample(frac=)             # frac = 0.6 means sampling 60% of rows randomly"},{"path":"pandas.html","id":"sample-data-11","chapter":"15 pandas","heading":"15.7.5.1 Sample Data","text":"","code":"df  = pd.DataFrame(data).set_index('empID')\ndf\ndf2 = pd.DataFrame(data, index = ['row2','row3','row1','row5','row4'])\ndf2##        year1  year2  salary     name\n## empID                               \n## 100     2017   2027   40000    Alice\n## 101     2017   2027   24000      Bob\n## 102     2017   2027   31000  Charles\n## 103     2018   2028   20000    David\n## 104     2018   2028   30000     Eric\n##       empID  year1  year2  salary     name\n## row2    100   2017   2027   40000    Alice\n## row3    101   2017   2027   24000      Bob\n## row1    102   2017   2027   31000  Charles\n## row5    103   2018   2028   20000    David\n## row4    104   2018   2028   30000     Eric"},{"path":"pandas.html","id":"using-row-label-loc","chapter":"15 pandas","heading":"15.7.5.2 Using Row Label (loc)","text":"Non matching single row label result KeyError.Non matching range row labels trigger error.Row Label numberRow Label string","code":"df.loc[ 101]         # by single row label, return Series## year1      2017\n## year2      2027\n## salary    24000\n## name        Bob\n## Name: 101, dtype: objectdf.loc[ [100,103] ]  # by multiple row labels, returns DataFrame##        year1  year2  salary   name\n## empID                             \n## 100     2017   2027   40000  Alice\n## 103     2018   2028   20000  Daviddf.loc[ 100:103   ]  # by range of row labels, returns DataFrame##        year1  year2  salary     name\n## empID                               \n## 100     2017   2027   40000    Alice\n## 101     2017   2027   24000      Bob\n## 102     2017   2027   31000  Charles\n## 103     2018   2028   20000    Daviddf.loc[ 999:9999  ]  # invalid range, No Error !!## Empty DataFrame\n## Columns: [year1, year2, salary, name]\n## Index: []df.loc[ 999 ]        # invalid key, KeyError## Error in py_call_impl(callable, dots$args, dots$keywords): KeyError: 999df2.loc[ 'row3' ]          # by single row label, return Series## empID       101\n## year1      2017\n## year2      2027\n## salary    24000\n## name        Bob\n## Name: row3, dtype: objectdf2.loc[ ['row1','row3'] ] # by multiple row labels, returns DataFrame##       empID  year1  year2  salary     name\n## row1    102   2017   2027   31000  Charles\n## row3    101   2017   2027   24000      Bobdf2.loc[ 'row1':'row3'  ]  # by range of row labels, return empty DataFrame because there is no row3 after row1## Empty DataFrame\n## Columns: [empID, year1, year2, salary, name]\n## Index: []df2.loc[ 'row1':'row4'  ]  # by range of row labels, returns DataFrame##       empID  year1  year2  salary     name\n## row1    102   2017   2027   31000  Charles\n## row5    103   2018   2028   20000    David\n## row4    104   2018   2028   30000     Ericdf2.loc[ 'row1':'baba'  ]  # Invalid range, KeyError## Error in py_call_impl(callable, dots$args, dots$keywords): KeyError: 'baba'"},{"path":"pandas.html","id":"using-row-number-iloc","chapter":"15 pandas","heading":"15.7.5.3 Using Row Number (iloc)","text":"Multiple rows returned dataframe object","code":"df.iloc[1]          # by single row number\ndf.iloc[ [0,3] ]    # by row numbers\ndf.iloc[  0:3  ]    # by row number range\ndf.iloc[ 0:999 ]    # invalid range, no error\ndf.iloc[999]        # invalid row, IndexError## year1      2017\n## year2      2027\n## salary    24000\n## name        Bob\n## Name: 101, dtype: object\n##        year1  year2  salary   name\n## empID                             \n## 100     2017   2027   40000  Alice\n## 103     2018   2028   20000  David\n##        year1  year2  salary     name\n## empID                               \n## 100     2017   2027   40000    Alice\n## 101     2017   2027   24000      Bob\n## 102     2017   2027   31000  Charles\n##        year1  year2  salary     name\n## empID                               \n## 100     2017   2027   40000    Alice\n## 101     2017   2027   24000      Bob\n## 102     2017   2027   31000  Charles\n## 103     2018   2028   20000    David\n## 104     2018   2028   30000     Eric## Error in py_call_impl(callable, dots$args, dots$keywords): IndexError: single positional indexer is out-of-bounds"},{"path":"pandas.html","id":"using-boolean-list","chapter":"15 pandas","heading":"15.7.5.4 Using Boolean List","text":"","code":"criteria = (df.salary > 30000) & (df.year1==2017)\nprint (criteria)\nprint (df.loc[criteria])## empID\n## 100     True\n## 101    False\n## 102     True\n## 103    False\n## 104    False\n## dtype: bool\n##        year1  year2  salary     name\n## empID                               \n## 100     2017   2027   40000    Alice\n## 102     2017   2027   31000  Charles"},{"path":"pandas.html","id":"using-expression-.query","chapter":"15 pandas","heading":"15.7.5.5 Using Expression (.query)","text":".query(expr, inplace=False)","code":"num1 = 31000\nnum2 = 2017\ndf.query(f'salary<={num1} and year1=={num2}')##        year1  year2  salary     name\n## empID                               \n## 101     2017   2027   24000      Bob\n## 102     2017   2027   31000  Charles"},{"path":"pandas.html","id":"sampling-.sample","chapter":"15 pandas","heading":"15.7.5.6 Sampling (.sample)","text":"Specify percentage random rows returned.","code":"np.random.seed(15)  ## ensure consistentcy of result\ndf.sample(frac=0.7) ## randomly pick 70% of rows, without replacement##        year1  year2  salary     name\n## empID                               \n## 102     2017   2027   31000  Charles\n## 103     2018   2028   20000    David\n## 104     2018   2028   30000     Eric\n## 101     2017   2027   24000      Bob"},{"path":"pandas.html","id":"row-manipulation","chapter":"15 pandas","heading":"15.7.6 Row Manipulation","text":"","code":""},{"path":"pandas.html","id":"sample-data-12","chapter":"15 pandas","heading":"15.7.6.1 Sample Data","text":"","code":"df##        year1  year2  salary     name\n## empID                               \n## 100     2017   2027   40000    Alice\n## 101     2017   2027   24000      Bob\n## 102     2017   2027   31000  Charles\n## 103     2018   2028   20000    David\n## 104     2018   2028   30000     Eric"},{"path":"pandas.html","id":"append-rows","chapter":"15 pandas","heading":"15.7.6.2 Append Rows","text":".append() deprecated. Refer Concatenating section.","code":""},{"path":"pandas.html","id":"drop-rows-.drop","chapter":"15 pandas","heading":"15.7.6.3 Drop Rows (.drop)","text":".drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')Row Label(s)","code":"df.drop(index=100)                         # drop single row\ndf.drop(index=[100,103], columns='salary') # drop selected rows and columns##        year1  year2  salary     name\n## empID                               \n## 101     2017   2027   24000      Bob\n## 102     2017   2027   31000  Charles\n## 103     2018   2028   20000    David\n## 104     2018   2028   30000     Eric\n##        year1  year2     name\n## empID                       \n## 101     2017   2027      Bob\n## 102     2017   2027  Charles\n## 104     2018   2028     Eric"},{"path":"pandas.html","id":"column-manipulation","chapter":"15 pandas","heading":"15.7.7 Column Manipulation","text":"","code":""},{"path":"pandas.html","id":"sample-data-13","chapter":"15 pandas","heading":"15.7.7.1 Sample Data","text":"","code":"df = pd.DataFrame(data)\ndf##    empID  year1  year2  salary     name\n## 0    100   2017   2027   40000    Alice\n## 1    101   2017   2027   24000      Bob\n## 2    102   2017   2027   31000  Charles\n## 3    103   2018   2028   20000    David\n## 4    104   2018   2028   30000     Eric"},{"path":"pandas.html","id":"renaming-columns","chapter":"15 pandas","heading":"15.7.7.2 Renaming Columns","text":"Method 1 : Rename Columns (.columns =).Construct new column names, ensure missing column names, result error.Method 2 : Renaming Specific Column (.rename (columns=) )Change column name rename function.Support inplace option.Specify columns require name change.Non matching columns return error. great.","code":"new_columns = ['empID', 'year.1','year.2','salary', 'glamour']\ndf.columns = new_columns\ndf.head(2)##    empID  year.1  year.2  salary glamour\n## 0    100    2017    2027   40000   Alice\n## 1    101    2017    2027   24000     Bobdf.rename( columns={'year.1':'year1', 'year.2':'year2'}, inplace=True)\ndf.head(2)##    empID  year1  year2  salary glamour\n## 0    100   2017   2027   40000   Alice\n## 1    101   2017   2027   24000     Bob"},{"path":"pandas.html","id":"reordering-columns","chapter":"15 pandas","heading":"15.7.7.3 Reordering Columns","text":"Reordering columns basically returning new DataFrame speicified column list order preferred.Refer Sub-setting Column section.","code":""},{"path":"pandas.html","id":"create-new-column","chapter":"15 pandas","heading":"15.7.7.4 Create New Column","text":"New Column created instantly using [] notationDO USE dot Notation view attribute","code":"df['year3'] = df.year1\ndf##    empID  year1  year2  salary  glamour  year3\n## 0    100   2017   2027   40000    Alice   2017\n## 1    101   2017   2027   24000      Bob   2017\n## 2    102   2017   2027   31000  Charles   2017\n## 3    103   2018   2028   20000    David   2018\n## 4    104   2018   2028   30000     Eric   2018"},{"path":"pandas.html","id":"dropping-columns-.drop","chapter":"15 pandas","heading":"15.7.7.5 Dropping Columns (.drop)","text":"inplace=True means column deleted original dataframe. Default False, return copy dataframeBy Column Name(s)Column Number(s)Use dataframe.columns produce interim list column names","code":"dataframe.drop( columns='column_name',    inplace=True/False)   # delete single column\ndataframe.drop( columns=list_of_colnames, inplace=True/False)   # delete multiple column\n\ndataframe.drop( index='row_label',         inplace=True/False)   # delete single row\ndataframe.drop( index= list_of_row_labels, inplace=True/False)   # delete multiple rows\ndf.drop( columns='year1')           # drop single column\ndf.drop( columns=['year1','year2'])  # drop multiple columns##    empID  year2  salary  glamour  year3\n## 0    100   2027   40000    Alice   2017\n## 1    101   2027   24000      Bob   2017\n## 2    102   2027   31000  Charles   2017\n## 3    103   2028   20000    David   2018\n## 4    104   2028   30000     Eric   2018\n##    empID  salary  glamour  year3\n## 0    100   40000    Alice   2017\n## 1    101   24000      Bob   2017\n## 2    102   31000  Charles   2017\n## 3    103   20000    David   2018\n## 4    104   30000     Eric   2018## before dropping columns\ndf\ndf.drop( columns=df.columns[[1,2]])  # drop second and third columns\ndf.drop( columns=df.columns[0:3] )   # drop first, second and third columns##    empID  year1  year2  salary  glamour  year3\n## 0    100   2017   2027   40000    Alice   2017\n## 1    101   2017   2027   24000      Bob   2017\n## 2    102   2017   2027   31000  Charles   2017\n## 3    103   2018   2028   20000    David   2018\n## 4    104   2018   2028   30000     Eric   2018\n##    empID  salary  glamour  year3\n## 0    100   40000    Alice   2017\n## 1    101   24000      Bob   2017\n## 2    102   31000  Charles   2017\n## 3    103   20000    David   2018\n## 4    104   30000     Eric   2018\n##    salary  glamour  year3\n## 0   40000    Alice   2017\n## 1   24000      Bob   2017\n## 2   31000  Charles   2017\n## 3   20000    David   2018\n## 4   30000     Eric   2018"},{"path":"pandas.html","id":"subsetting-columns","chapter":"15 pandas","heading":"15.7.8 Subsetting Columns","text":"Select Single Column Return SeriesSelect Single/Multiple Columns Return DataFrame","code":"dataframe.columnName               # single column, name based, return Series object\ndataframe[ single_col_name ]       # single column, name based, return Series objectdataframe    [  list_of_col_names   ]  # name based, return Dataframe object\ndataframe.loc[ : , single_col_name  ]  # single column, series\ndataframe.loc[ : , col_name_list    ]  # multiple columns, dataframe\ndataframe.loc[ : , col_name_range   ]  # multiple columns, dataframe\n\ndataframe.iloc[ : , col_number      ]  # single column, series\ndataframe.iloc[ : , col_number_list ]  # multiple columns, dataframe\ndataframe.iloc[ : , number_range    ]  # multiple columns, dataframe"},{"path":"pandas.html","id":"select-single-column-.loc-iloc","chapter":"15 pandas","heading":"15.7.8.1 Select Single Column (.loc, iloc)","text":"Selecting single column always return panda::Series, except using [[ ]] notation.","code":"df = pd.DataFrame(data)\ndf.name\ndf['name']\ndf.loc[:, 'name']\ndf.iloc[:, 3]## 0      Alice\n## 1        Bob\n## 2    Charles\n## 3      David\n## 4       Eric\n## Name: name, dtype: object\n## 0      Alice\n## 1        Bob\n## 2    Charles\n## 3      David\n## 4       Eric\n## Name: name, dtype: object\n## 0      Alice\n## 1        Bob\n## 2    Charles\n## 3      David\n## 4       Eric\n## Name: name, dtype: object\n## 0    40000\n## 1    24000\n## 2    31000\n## 3    20000\n## 4    30000\n## Name: salary, dtype: int64"},{"path":"pandas.html","id":"select-multiple-columns-.loc-iloc","chapter":"15 pandas","heading":"15.7.8.2 Select Multiple Columns (.loc, iloc)","text":"Multiple columns return panda::Dataframe object`Example returns DataFrame Single ColumnSelect Range Columns","code":"df[['name']]                # return one column dataframe\ndf[['name','year1']] \ndf.loc[:,['name','year1']]##       name\n## 0    Alice\n## 1      Bob\n## 2  Charles\n## 3    David\n## 4     Eric\n##       name  year1\n## 0    Alice   2017\n## 1      Bob   2017\n## 2  Charles   2017\n## 3    David   2018\n## 4     Eric   2018\n##       name  year1\n## 0    Alice   2017\n## 1      Bob   2017\n## 2  Charles   2017\n## 3    David   2018\n## 4     Eric   2018df.loc [ : , 'year1':'year2']  ## by range of column names\ndf.loc[ : , ['empID','year2']] ## select two columns only\ndf.iloc[ : , 1:4]              ## by range of column number\ndf.iloc[ : , [0,3]]            ## select two columns only##    year1  year2\n## 0   2017   2027\n## 1   2017   2027\n## 2   2017   2027\n## 3   2018   2028\n## 4   2018   2028\n##    empID  year2\n## 0    100   2027\n## 1    101   2027\n## 2    102   2027\n## 3    103   2028\n## 4    104   2028\n##    year1  year2  salary\n## 0   2017   2027   40000\n## 1   2017   2027   24000\n## 2   2017   2027   31000\n## 3   2018   2028   20000\n## 4   2018   2028   30000\n##    empID  salary\n## 0    100   40000\n## 1    101   24000\n## 2    102   31000\n## 3    103   20000\n## 4    104   30000"},{"path":"pandas.html","id":"by-column-name-.filter-.reindex","chapter":"15 pandas","heading":"15.7.8.3 By Column Name (.filter, .reindex)","text":".filter(items=None, like=None, regex=None, axis=1)Filter like - Sub string Matching, always return DataFrame.Filter items - list exact column namesFilter regex = Regular Expression Matching column namesSelect column names contain integer..reindex(columns = .. )returns new dataframe. inplace option reordering columnsNon Matching columns names result NA values","code":"df.filter( like='year', axis=1)  ## or axis = 1##    year1  year2\n## 0   2017   2027\n## 1   2017   2027\n## 2   2017   2027\n## 3   2018   2028\n## 4   2018   2028df.filter( like='name')##       name\n## 0    Alice\n## 1      Bob\n## 2  Charles\n## 3    David\n## 4     Ericdf.filter( items=('year1','year2', 'name', 'not_exist'),  axis=1)##    year1  year2     name\n## 0   2017   2027    Alice\n## 1   2017   2027      Bob\n## 2   2017   2027  Charles\n## 3   2018   2028    David\n## 4   2018   2028     Ericdf.filter(regex='\\d')  ## default axis=1 if DataFrame##    year1  year2\n## 0   2017   2027\n## 1   2017   2027\n## 2   2017   2027\n## 3   2018   2028\n## 4   2018   2028new_colorder = [ 'salary', 'year1', 'baba']\ndf.reindex(columns = new_colorder)  ## Non matching column name returns as NaN##    salary  year1  baba\n## 0   40000   2017   NaN\n## 1   24000   2017   NaN\n## 2   31000   2017   NaN\n## 3   20000   2018   NaN\n## 4   30000   2018   NaN"},{"path":"pandas.html","id":"by-data-types-.select_dtypes","chapter":"15 pandas","heading":"15.7.8.4 By Data Types (.select_dtypes)","text":"Always return panda::DataFrame, even though single column matches. Allowed types :number (integer float)integer / int64floatdatetimetimedeltacategoryboolobject (string)Use .dtypes.value_counts() insepct available data types.","code":"df.dtypes.value_counts()                       ## inspect available data types\ndf.select_dtypes( exclude='integer')           ## exclude bool cols\ndf.select_dtypes( include=['number','object']) ## include only number cols## int64     4\n## object    1\n## dtype: int64\n##       name\n## 0    Alice\n## 1      Bob\n## 2  Charles\n## 3    David\n## 4     Eric\n##    empID  year1  year2  salary     name\n## 0    100   2017   2027   40000    Alice\n## 1    101   2017   2027   24000      Bob\n## 2    102   2017   2027   31000  Charles\n## 3    103   2018   2028   20000    David\n## 4    104   2018   2028   30000     Eric"},{"path":"pandas.html","id":"concatenating","chapter":"15 pandas","heading":"15.7.9 Concatenating","text":"Concatenating Two DataFramesWhen ignore_index=True, pandas create new index result 0,1,2,3…recommended ignore index data source index unique.New columns rows added result non-matching.","code":"my_df = pd.DataFrame(\n          data= {'Id':   [10,20,30],\n                 'Name': ['Aaa','Bbb','Ccc']})\n#                 .set_index('Id')\n                 \nmy_df_new = pd.DataFrame(\n            data= {'Id':   [40,50],\n                   'Name': ['Ddd','Eee'],\n                   'Age':  [12,13]})  \n                   #.set_index('Id')\n                   \nmy_df_append  = pd.concat( [my_df, my_df_new])\nmy_df_noindex = pd.concat( [my_df, my_df_new], ignore_index=True)\n\nprint(\"Original DataFrame:\\n\", my_df,\n      \"\\n\\nTo Be Appended DataFrame:\\n\", my_df_new,\n      \"\\n\\nAppended DataFrame (index maintained):\\n\", my_df_append,\n      \"\\n\\nAppended DataFrame (index ignored):\\n\", my_df_noindex)## Original DataFrame:\n##     Id Name\n## 0  10  Aaa\n## 1  20  Bbb\n## 2  30  Ccc \n## \n## To Be Appended DataFrame:\n##     Id Name  Age\n## 0  40  Ddd   12\n## 1  50  Eee   13 \n## \n## Appended DataFrame (index maintained):\n##     Id Name   Age\n## 0  10  Aaa   NaN\n## 1  20  Bbb   NaN\n## 2  30  Ccc   NaN\n## 0  40  Ddd  12.0\n## 1  50  Eee  13.0 \n## \n## Appended DataFrame (index ignored):\n##     Id Name   Age\n## 0  10  Aaa   NaN\n## 1  20  Bbb   NaN\n## 2  30  Ccc   NaN\n## 3  40  Ddd  12.0\n## 4  50  Eee  13.0"},{"path":"pandas.html","id":"slicing","chapter":"15 pandas","heading":"15.7.10 Slicing","text":"","code":""},{"path":"pandas.html","id":"sample-data-14","chapter":"15 pandas","heading":"15.7.10.1 Sample Data","text":"","code":"df = pd.DataFrame(data).set_index('empID')\ndf##        year1  year2  salary     name\n## empID                               \n## 100     2017   2027   40000    Alice\n## 101     2017   2027   24000      Bob\n## 102     2017   2027   31000  Charles\n## 103     2018   2028   20000    David\n## 104     2018   2028   30000     Eric"},{"path":"pandas.html","id":"getting-one-cell","chapter":"15 pandas","heading":"15.7.10.2 Getting One Cell","text":"Row Label Column Name (loc)","code":"dataframe.loc [ row_label , col_name   ]    # by row label and column names\ndataframe.loc [ bool_list , col_name   ]    # by row label and column names\ndataframe.iloc[ row_number, col_number ]    # by row and column numberdf.loc [102,'year1']  ## row label 102, column 'year1'\ndf.iloc[2,0]          ## same result as above## 2017\n## 2017"},{"path":"pandas.html","id":"getting-range-of-cells","chapter":"15 pandas","heading":"15.7.10.3 Getting Range of Cells","text":"Specify rows columns (individual range)Index Column Name (loc)Boolean Row Column Names (loc)Row Column Number (iloc)","code":"dataframe.loc [ list/range_of_row_labels , list/range_col_names   ]    # by row label and column names\ndataframe.iloc[ list/range_row_numbers,    list/range_col_numbers ]    # by row numberdf.loc[ [101,103], ['name', 'year1'] ]  # by list of row label and column names\ndf.loc[  101:104 ,  'year1':'year2'  ]  # by range of row label and column names##         name  year1\n## empID              \n## 101      Bob   2017\n## 103    David   2018\n##        year1  year2\n## empID              \n## 101     2017   2027\n## 102     2017   2027\n## 103     2018   2028\n## 104     2018   2028b = df.year1==2017\ndf.loc[ b ]##        year1  year2  salary     name\n## empID                               \n## 100     2017   2027   40000    Alice\n## 101     2017   2027   24000      Bob\n## 102     2017   2027   31000  Charlesprint (df.iloc[ [1,4], [0,3]],'\\n' )   # by individual rows/columns##        year1  name\n## empID             \n## 101     2017   Bob\n## 104     2018  Ericprint (df.iloc[  1:4 ,  0:3], '\\n')    # by range##        year1  year2  salary\n## empID                      \n## 101     2017   2027   24000\n## 102     2017   2027   31000\n## 103     2018   2028   20000"},{"path":"pandas.html","id":"chained-indexing","chapter":"15 pandas","heading":"15.7.11 Chained Indexing","text":"Chained Index Method creates copy dataframe, modification data original dataframe affect copySuggesting, never use chain indexing","code":"dataframe.loc  [...]  [...]\ndataframe.iloc [...]  [...]df = pd.DataFrame(\n    { 'empID':  [100,      101,    102,      103,     104],\n      'year1':   [2017,     2017,   2017,      2018,    2018],\n      'name':   ['Alice',  'Bob',  'Charles','David', 'Eric'],\n      'year2':   [2001,     1907,   2003,      1998,    2011],\n      'salary': [40000,    24000,  31000,     20000,   30000]},\n    columns = ['year1','salary','year2','empID','name']).set_index(['empID'])\ndf##        year1  salary  year2     name\n## empID                               \n## 100     2017   40000   2001    Alice\n## 101     2017   24000   1907      Bob\n## 102     2017   31000   2003  Charles\n## 103     2018   20000   1998    David\n## 104     2018   30000   2011     Ericdf.loc[100]['year'] =2000## <string>:1: SettingWithCopyWarning: \n## A value is trying to be set on a copy of a slice from a DataFrame\n## \n## See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n## <string>:1: SettingWithCopyWarning: \n## A value is trying to be set on a copy of a slice from a DataFrame\n## \n## See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copydf  ## notice row label 100 had not been updated, because data was updated on a copy due to chain indexing##        year1  salary  year2     name\n## empID                               \n## 100     2017   40000   2001    Alice\n## 101     2017   24000   1907      Bob\n## 102     2017   31000   2003  Charles\n## 103     2018   20000   1998    David\n## 104     2018   30000   2011     Eric"},{"path":"pandas.html","id":"find-and-replace","chapter":"15 pandas","heading":"15.7.12 Find and Replace","text":"Slicing deals square cells selection. Use mask select specific cell(s). function respect column row names.","code":""},{"path":"pandas.html","id":"mask","chapter":"15 pandas","heading":"15.7.12.1 mask()","text":"mask() replace cell value = condition met.","code":"data={'x': [1,4,7],\n      'y': [2,5,8],\n      'z': [3,6,9]}\ndf = pd.DataFrame(data)\ndf.mask(df>4, other=999)##      x    y    z\n## 0    1    2    3\n## 1    4  999  999\n## 2  999  999  999"},{"path":"pandas.html","id":"where-1","chapter":"15 pandas","heading":"15.7.12.2 where()","text":"reverse mask(), keep cell value condition met. met, replace value.","code":"df.where(df>4, other=0)##    x  y  z\n## 0  0  0  0\n## 1  0  5  6\n## 2  7  8  9"},{"path":"pandas.html","id":"iteration-2","chapter":"15 pandas","heading":"15.7.13 Iteration","text":"","code":""},{"path":"pandas.html","id":"iterating-rows-.iterrows","chapter":"15 pandas","heading":"15.7.13.1 Iterating Rows (.iterrows)","text":"","code":"df = pd.DataFrame(data=\n    { 'empID':  [100,      101,    102,      103,     104],\n      'Name':   ['Alice',  'Bob',  'Charles','David', 'Eric'],\n      'Year':   [1999,     1988,   2001,     2010,     2020]}).set_index(['empID'])\n\nfor idx, row in df.iterrows():\n  print(idx, row.Name)## 100 Alice\n## 101 Bob\n## 102 Charles\n## 103 David\n## 104 Eric"},{"path":"pandas.html","id":"iterating-columns-.items","chapter":"15 pandas","heading":"15.7.13.2 Iterating Columns (.items)","text":"","code":"for label, content in df.items():\n  print('Column Label:',              label,   '\\n\\n', \n        'Column Content (Series):\\n', content, '\\n\\n')## Column Label: Name \n## \n##  Column Content (Series):\n##  empID\n## 100      Alice\n## 101        Bob\n## 102    Charles\n## 103      David\n## 104       Eric\n## Name: Name, dtype: object \n## \n## \n## Column Label: Year \n## \n##  Column Content (Series):\n##  empID\n## 100    1999\n## 101    1988\n## 102    2001\n## 103    2010\n## 104    2020\n## Name: Year, dtype: int64"},{"path":"pandas.html","id":"data-structure","chapter":"15 pandas","heading":"15.7.14 Data Structure","text":"","code":""},{"path":"pandas.html","id":"inspect-structure","chapter":"15 pandas","heading":"15.7.14.1 Inspect Structure","text":"Find column names, data type summary. Output display , data object","code":"df.info()  # return text output## <class 'pandas.core.frame.DataFrame'>\n## Int64Index: 5 entries, 100 to 104\n## Data columns (total 2 columns):\n##  #   Column  Non-Null Count  Dtype \n## ---  ------  --------------  ----- \n##  0   Name    5 non-null      object\n##  1   Year    5 non-null      int64 \n## dtypes: int64(1), object(1)\n## memory usage: 120.0+ bytesdf.dtypes.value_counts() # return Series## object    1\n## int64     1\n## dtype: int64"},{"path":"pandas.html","id":"format-conversion","chapter":"15 pandas","heading":"15.7.14.2 Format Conversion","text":".to_dict()","code":"df.to_dict('dict')    ## dict of dict by column## {'Name': {100: 'Alice', 101: 'Bob', 102: 'Charles', 103: 'David', 104: 'Eric'}, 'Year': {100: 1999, 101: 1988, 102: 2001, 103: 2010, 104: 2020}}df.to_dict('index')   ## dict of dict by row index## {100: {'Name': 'Alice', 'Year': 1999}, 101: {'Name': 'Bob', 'Year': 1988}, 102: {'Name': 'Charles', 'Year': 2001}, 103: {'Name': 'David', 'Year': 2010}, 104: {'Name': 'Eric', 'Year': 2020}}df.to_dict('list')    ## dict of list## {'Name': ['Alice', 'Bob', 'Charles', 'David', 'Eric'], 'Year': [1999, 1988, 2001, 2010, 2020]}df.to_dict('records') ## list of dict## [{'Name': 'Alice', 'Year': 1999}, {'Name': 'Bob', 'Year': 1988}, {'Name': 'Charles', 'Year': 2001}, {'Name': 'David', 'Year': 2010}, {'Name': 'Eric', 'Year': 2020}]"},{"path":"pandas.html","id":"importexport","chapter":"15 pandas","heading":"15.7.15 Import/Export","text":"","code":""},{"path":"pandas.html","id":"csv","chapter":"15 pandas","heading":"15.7.15.1 CSV","text":"","code":"df.to_csv()## 'empID,Name,Year\\r\\n100,Alice,1999\\r\\n101,Bob,1988\\r\\n102,Charles,2001\\r\\n103,David,2010\\r\\n104,Eric,2020\\r\\n'"},{"path":"pandas.html","id":"class-multiindex","chapter":"15 pandas","heading":"15.8 Class: MultiIndex","text":"MultiIndexing columns levels headers.","code":""},{"path":"pandas.html","id":"the-data-1","chapter":"15 pandas","heading":"15.8.1 The Data","text":"","code":"df = pd.DataFrame({\n     'myindex': [0, 1, 2],\n     'One_X':   [1.1,  1.1,  1.1],\n     'One_Y':   [1.2,  1.2,  1.2],\n     'Two_X':   [1.11, 1.11, 1.11],\n     'Two_Y':   [1.22, 1.22, 1.22]})\ndf.set_index('myindex',inplace=True)\ndf##          One_X  One_Y  Two_X  Two_Y\n## myindex                            \n## 0          1.1    1.2   1.11   1.22\n## 1          1.1    1.2   1.11   1.22\n## 2          1.1    1.2   1.11   1.22"},{"path":"pandas.html","id":"creating-multiindex-object","chapter":"15 pandas","heading":"15.8.2 Creating MultiIndex Object","text":"","code":""},{"path":"pandas.html","id":"create-from-tuples","chapter":"15 pandas","heading":"15.8.2.1 Create From Tuples","text":"MultiIndex can easily created typles:\n- Step 1: Create MultiIndex object splitting column name tuples\n- Step 2: Assign MultiIndex Object dataframe columns property.","code":"my_tuples = [tuple(c.split('_')) for c in df.columns]\ndf.columns = pd.MultiIndex.from_tuples(my_tuples)\n\nprint(' Column Headers :\\n\\n',           my_tuples,\n        '\\n\\nNew Columns: \\n\\n',         df.columns,\n        '\\n\\nTwo Layers Header DF:\\n\\n', df)##  Column Headers :\n## \n##  [('One', 'X'), ('One', 'Y'), ('Two', 'X'), ('Two', 'Y')] \n## \n## New Columns: \n## \n##  MultiIndex([('One', 'X'),\n##             ('One', 'Y'),\n##             ('Two', 'X'),\n##             ('Two', 'Y')],\n##            ) \n## \n## Two Layers Header DF:\n## \n##           One        Two      \n##            X    Y     X     Y\n## myindex                      \n## 0        1.1  1.2  1.11  1.22\n## 1        1.1  1.2  1.11  1.22\n## 2        1.1  1.2  1.11  1.22"},{"path":"pandas.html","id":"multiindex-object","chapter":"15 pandas","heading":"15.8.3 MultiIndex Object","text":"","code":""},{"path":"pandas.html","id":"levels","chapter":"15 pandas","heading":"15.8.3.1 Levels","text":"MultiIndex object contain multiple leveels, level (header) Index object.Use MultiIndex.get_level_values() entire header desired level. Note level Index objectMultiIndex.levels return unique values level.","code":"print(df.columns.get_level_values(0), '\\n',\n      df.columns.get_level_values(1))## Index(['One', 'One', 'Two', 'Two'], dtype='object') \n##  Index(['X', 'Y', 'X', 'Y'], dtype='object')print(df.columns.levels[0], '\\n',\n      df.columns.levels[1])## Index(['One', 'Two'], dtype='object') \n##  Index(['X', 'Y'], dtype='object')"},{"path":"pandas.html","id":"convert-multiindex-back-to-tuples","chapter":"15 pandas","heading":"15.8.3.2 Convert MultiIndex Back To Tuples","text":"","code":"df.columns.to_list()## [('One', 'X'), ('One', 'Y'), ('Two', 'X'), ('Two', 'Y')]"},{"path":"pandas.html","id":"selecting-columns","chapter":"15 pandas","heading":"15.8.4 Selecting Column(s)","text":"","code":""},{"path":"pandas.html","id":"sample-data-15","chapter":"15 pandas","heading":"15.8.4.1 Sample Data","text":"","code":"import itertools\ntest_df = pd.DataFrame\nmax_age = 100\n\n### Create The Columns Tuple\nlevel0_sex = ['Male','Female','Pondan']\nlevel1_age = ['Medium','High','Low']\nmy_columns = list(itertools.product(level0_sex, level1_age))\n\ntest_df = pd.DataFrame([\n             [1,2,3,4,5,6,7,8,9],\n             [11,12,13,14,15,16,17,18,19],\n             [21,22,23,24,25,26,27,28,29]], index=['row1','row2','row3'])\n\n### Create Multiindex From Tuple\ntest_df.columns = pd.MultiIndex.from_tuples(my_columns)\nprint( test_df ) ##        Male          Female          Pondan         \n##      Medium High Low Medium High Low Medium High Low\n## row1      1    2   3      4    5   6      7    8   9\n## row2     11   12  13     14   15  16     17   18  19\n## row3     21   22  23     24   25  26     27   28  29"},{"path":"pandas.html","id":"select-level0-headers","chapter":"15 pandas","heading":"15.8.4.2 Select Level0 Header(s)","text":"Use [L0] notation, L0 list header namesUsing .loc[]Use .loc[ :, L0 ], L0 list headers names","code":"print( test_df[['Male','Pondan']] ,'\\n\\n',  ## Include multiple Level0 Header\n       test_df['Male'] ,          '\\n\\n',   ## Include single Level0 Header\n       test_df.Male )                       ## Same as above##        Male          Pondan         \n##      Medium High Low Medium High Low\n## row1      1    2   3      7    8   9\n## row2     11   12  13     17   18  19\n## row3     21   22  23     27   28  29 \n## \n##        Medium  High  Low\n## row1       1     2    3\n## row2      11    12   13\n## row3      21    22   23 \n## \n##        Medium  High  Low\n## row1       1     2    3\n## row2      11    12   13\n## row3      21    22   23print( test_df.loc[:, ['Male','Pondan']] , '\\n\\n',  ## Multiple Level0 Header\n       test_df.loc[:, 'Male'] )                     ## Single Level0 Header##        Male          Pondan         \n##      Medium High Low Medium High Low\n## row1      1    2   3      7    8   9\n## row2     11   12  13     17   18  19\n## row3     21   22  23     27   28  29 \n## \n##        Medium  High  Low\n## row1       1     2    3\n## row2      11    12   13\n## row3      21    22   23"},{"path":"pandas.html","id":"selecting-level-1-headers","chapter":"15 pandas","heading":"15.8.4.3 Selecting Level 1 Header(s)","text":"Use .loc[ :, (, L1)], L1 list headers names","code":"All = slice(None)\nprint( test_df.loc[ : , (All, 'High')],  '\\n\\n',  ## Signle L1 header\n       test_df.loc[ : , (All, ['High','Low'])] )  ## Multiple L1 headers##      Male Female Pondan\n##      High   High   High\n## row1    2      5      8\n## row2   12     15     18\n## row3   22     25     28 \n## \n##       Male Female Pondan Male Female Pondan\n##      High   High   High  Low    Low    Low\n## row1    2      5      8    3      6      9\n## row2   12     15     18   13     16     19\n## row3   22     25     28   23     26     29"},{"path":"pandas.html","id":"select-level-0-and-level1-headers","chapter":"15 pandas","heading":"15.8.4.4 Select Level 0 and Level1 Headers","text":"Use .loc[ :, (L0, L1)], L0 L1 list headers names","code":"test_df.loc[ : , (['Male','Pondan'], ['Medium','High'])]##        Male      Pondan     \n##      Medium High Medium High\n## row1      1    2      7    8\n## row2     11   12     17   18\n## row3     21   22     27   28"},{"path":"pandas.html","id":"select-single-l0l1-header","chapter":"15 pandas","heading":"15.8.4.5 Select single L0,L1 Header","text":"Use .loc[:, (L0,  L1) ], result Series\nUse .loc[:, (L0 ,[L1])], result DataFrame","code":"print( test_df.loc[ : , ('Female', 'High')], '\\n\\n',\n       test_df.loc[ : , ('Female', ['High'])])## row1     5\n## row2    15\n## row3    25\n## Name: (Female, High), dtype: int64 \n## \n##       Female\n##        High\n## row1      5\n## row2     15\n## row3     25"},{"path":"pandas.html","id":"headers-ordering","chapter":"15 pandas","heading":"15.8.5 Headers Ordering","text":"Note columns order specifeid [ ] selection respected. can remediated either Sorting rearranging.","code":""},{"path":"pandas.html","id":"sort-headers","chapter":"15 pandas","heading":"15.8.5.1 Sort Headers","text":"Use .sort_index() DataFrame sort headers. Note level1 sorted, jumble level0 headers.","code":"test_df_sorted_l0 = test_df.sort_index(axis=1, level=0)\ntest_df_sorted_l1 = test_df.sort_index(axis=1, level=1, ascending=False)\nprint(test_df, '\\n\\n',test_df_sorted_l0, '\\n\\n', test_df_sorted_l1)##        Male          Female          Pondan         \n##      Medium High Low Medium High Low Medium High Low\n## row1      1    2   3      4    5   6      7    8   9\n## row2     11   12  13     14   15  16     17   18  19\n## row3     21   22  23     24   25  26     27   28  29 \n## \n##       Female            Male            Pondan           \n##        High Low Medium High Low Medium   High Low Medium\n## row1      5   6      4    2   3      1      8   9      7\n## row2     15  16     14   12  13     11     18  19     17\n## row3     25  26     24   22  23     21     28  29     27 \n## \n##       Pondan   Male Female Pondan Male Female Pondan Male Female\n##      Medium Medium Medium    Low  Low    Low   High High   High\n## row1      7      1      4      9    3      6      8    2      5\n## row2     17     11     14     19   13     16     18   12     15\n## row3     27     21     24     29   23     26     28   22     25"},{"path":"pandas.html","id":"rearranging-headers","chapter":"15 pandas","heading":"15.8.5.2 Rearranging Headers","text":"Use **.reindex()** arrange columns specific order. Example shows control specific order level1 headers.","code":"cats = ['Low','Medium','High']\ntest_df.reindex(cats, level=1, axis=1)##      Male             Female             Pondan            \n##       Low Medium High    Low Medium High    Low Medium High\n## row1    3      1    2      6      4    5      9      7    8\n## row2   13     11   12     16     14   15     19     17   18\n## row3   23     21   22     26     24   25     29     27   28"},{"path":"pandas.html","id":"stacking-and-unstacking","chapter":"15 pandas","heading":"15.8.6 Stacking and Unstacking","text":"","code":"df.stack()##            One   Two\n## myindex             \n## 0       X  1.1  1.11\n##         Y  1.2  1.22\n## 1       X  1.1  1.11\n##         Y  1.2  1.22\n## 2       X  1.1  1.11\n##         Y  1.2  1.22"},{"path":"pandas.html","id":"stacking-columns-to-rows","chapter":"15 pandas","heading":"15.8.6.1 Stacking Columns to Rows","text":"Stacking DataFrame.stack(level_no) moving wide columns row.","code":"print('Stacking Header Level 0: \\n\\n', df.stack(0),\n      '\\n\\nStacking Header Level 1: \\n\\n', df.stack(1))## Stacking Header Level 0: \n## \n##                  X     Y\n## myindex                \n## 0       One  1.10  1.20\n##         Two  1.11  1.22\n## 1       One  1.10  1.20\n##         Two  1.11  1.22\n## 2       One  1.10  1.20\n##         Two  1.11  1.22 \n## \n## Stacking Header Level 1: \n## \n##             One   Two\n## myindex             \n## 0       X  1.1  1.11\n##         Y  1.2  1.22\n## 1       X  1.1  1.11\n##         Y  1.2  1.22\n## 2       X  1.1  1.11\n##         Y  1.2  1.22"},{"path":"pandas.html","id":"exploratory-analysis","chapter":"15 pandas","heading":"15.8.7 Exploratory Analysis","text":"","code":""},{"path":"pandas.html","id":"sample-data-16","chapter":"15 pandas","heading":"15.8.7.1 Sample Data","text":"","code":"df##          One        Two      \n##            X    Y     X     Y\n## myindex                      \n## 0        1.1  1.2  1.11  1.22\n## 1        1.1  1.2  1.11  1.22\n## 2        1.1  1.2  1.11  1.22"},{"path":"pandas.html","id":"all-stats-in-one---.describe","chapter":"15 pandas","heading":"15.8.7.2 All Stats in One - .describe()","text":"applied DataFrame object, describe shows basic statistic numeric columns:\n- Count (non-NA)\n- Unique (string)\n- Top (string)\n- Frequency (string)\n- Percentile\n- Mean\n- Min / Max\n- Standard DeviationFor Numeric Columns \ncan customize percentiles requred. Notice 0.5 percentile always although specifiedFor Numeric Object","code":"df.describe(include='number') # default\ndf.describe(include='object') # display for non-numeric columns\ndf.describe(include='all')    # display both numeric and non-numericdf.describe()##        One        Two      \n##          X    Y     X     Y\n## count  3.0  3.0  3.00  3.00\n## mean   1.1  1.2  1.11  1.22\n## std    0.0  0.0  0.00  0.00\n## min    1.1  1.2  1.11  1.22\n## 25%    1.1  1.2  1.11  1.22\n## 50%    1.1  1.2  1.11  1.22\n## 75%    1.1  1.2  1.11  1.22\n## max    1.1  1.2  1.11  1.22df.describe(percentiles=[0.9,0.3,0.2,0.1])##        One        Two      \n##          X    Y     X     Y\n## count  3.0  3.0  3.00  3.00\n## mean   1.1  1.2  1.11  1.22\n## std    0.0  0.0  0.00  0.00\n## min    1.1  1.2  1.11  1.22\n## 10%    1.1  1.2  1.11  1.22\n## 20%    1.1  1.2  1.11  1.22\n## 30%    1.1  1.2  1.11  1.22\n## 50%    1.1  1.2  1.11  1.22\n## 90%    1.1  1.2  1.11  1.22\n## max    1.1  1.2  1.11  1.22df.describe(include='all')##        One        Two      \n##          X    Y     X     Y\n## count  3.0  3.0  3.00  3.00\n## mean   1.1  1.2  1.11  1.22\n## std    0.0  0.0  0.00  0.00\n## min    1.1  1.2  1.11  1.22\n## 25%    1.1  1.2  1.11  1.22\n## 50%    1.1  1.2  1.11  1.22\n## 75%    1.1  1.2  1.11  1.22\n## max    1.1  1.2  1.11  1.22"},{"path":"pandas.html","id":"minmaxmeanmedian","chapter":"15 pandas","heading":"15.8.7.3 min/max/mean/median","text":"Observe, sum string concatenate column-wise, whereas row-wise sum numeric fields","code":"df.min()  # default axis=0, column-wise## One  X    1.10\n##      Y    1.20\n## Two  X    1.11\n##      Y    1.22\n## dtype: float64df.min(axis=1) # axis=1, row-wise## myindex\n## 0    1.1\n## 1    1.1\n## 2    1.1\n## dtype: float64df.sum(0)## One  X    3.30\n##      Y    3.60\n## Two  X    3.33\n##      Y    3.66\n## dtype: float64df.sum(1)## myindex\n## 0    4.63\n## 1    4.63\n## 2    4.63\n## dtype: float64"},{"path":"pandas.html","id":"plotting","chapter":"15 pandas","heading":"15.8.8 Plotting","text":"","code":""},{"path":"pandas.html","id":"class-categories","chapter":"15 pandas","heading":"15.9 Class: Categories","text":"","code":""},{"path":"pandas.html","id":"creating-1","chapter":"15 pandas","heading":"15.9.1 Creating","text":"","code":""},{"path":"pandas.html","id":"from-list","chapter":"15 pandas","heading":"15.9.1.1 From List","text":"Basic (Auto Category Mapping)\nBasic syntax return categorical index sequence code 0,1,2,3… mapping first found category\ncase, low(0), high(1), medium(2)Manual Category Mapping\ncreation, can specify mapping codes category: low(0), medium(1), high(2)","code":"temp = ['low','high','medium','high','high','low','medium','medium','high']\ntemp_cat = pd.Categorical(temp)\ntemp_cat## ['low', 'high', 'medium', 'high', 'high', 'low', 'medium', 'medium', 'high']\n## Categories (3, object): ['high', 'low', 'medium']type( temp_cat )## <class 'pandas.core.arrays.categorical.Categorical'>temp_cat = pd.Categorical(temp, categories=['low','medium','high'])\ntemp_cat## ['low', 'high', 'medium', 'high', 'high', 'low', 'medium', 'medium', 'high']\n## Categories (3, object): ['low', 'medium', 'high']"},{"path":"pandas.html","id":"from-series","chapter":"15 pandas","heading":"15.9.1.2 From Series","text":"can ‘add’ categorical structure Series. methods, additional property (.cat) added categorical accessorThrough accessor, gain access various properties category .codes, .categories. .get_values() information Series itselfCan manual map category ?????Method result using .astype(‘category’)useful adding category structure existing series.","code":"temp = ['low','high','medium','high','high','low','medium','medium','high']\ntemp_cat = pd.Series(temp, dtype='category')\nprint (type(temp_cat))       # Series object## <class 'pandas.core.series.Series'>print (type(temp_cat.cat))   # Categorical Accessor## <class 'pandas.core.arrays.categorical.CategoricalAccessor'>temp_ser = pd.Series(temp)\ntemp_cat = pd.Series(temp).astype('category')\nprint (type(temp_cat))       # Series object## <class 'pandas.core.series.Series'>print (type(temp_cat.cat))   # Categorical Accessor## <class 'pandas.core.arrays.categorical.CategoricalAccessor'>temp_cat.cat.categories## Index(['high', 'low', 'medium'], dtype='object')"},{"path":"pandas.html","id":"ordering-category","chapter":"15 pandas","heading":"15.9.1.3 Ordering Category","text":"","code":"temp = ['low','high','medium','high','high','low','medium','medium','high']\ntemp_cat = pd.Categorical(temp, categories=['low','medium','high'], ordered=True)\ntemp_cat## ['low', 'high', 'medium', 'high', 'high', 'low', 'medium', 'medium', 'high']\n## Categories (3, object): ['low' < 'medium' < 'high']temp_cat.codes## array([0, 2, 1, 2, 2, 0, 1, 1, 2], dtype=int8)temp_cat[0] < temp_cat[3]## False"},{"path":"pandas.html","id":"properties","chapter":"15 pandas","heading":"15.9.2 Properties","text":"","code":""},{"path":"pandas.html","id":"categories","chapter":"15 pandas","heading":"15.9.2.1 .categories","text":"first element’s code = 0\nsecond element’s code = 1\nthird element’s code = 2","code":"temp_cat.categories## Index(['low', 'medium', 'high'], dtype='object')"},{"path":"pandas.html","id":"codes","chapter":"15 pandas","heading":"15.9.2.2 .codes","text":"Codes actual integer value stored array. 1 represent ‘high’,","code":"temp_cat.codes## array([0, 2, 1, 2, 2, 0, 1, 1, 2], dtype=int8)"},{"path":"pandas.html","id":"rename-category","chapter":"15 pandas","heading":"15.9.3 Rename Category","text":"","code":""},{"path":"pandas.html","id":"renamce-to-new-category-object","chapter":"15 pandas","heading":"15.9.3.1 Renamce To New Category Object","text":".rename_categories() method return new category object new changed categories","code":"temp = ['low','high','medium','high','high','low','medium','medium','high']\nnew_temp_cat = temp_cat.rename_categories(['sejuk','sederhana','panas'])\nnew_temp_cat ## ['sejuk', 'panas', 'sederhana', 'panas', 'panas', 'sejuk', 'sederhana', 'sederhana', 'panas']\n## Categories (3, object): ['sejuk' < 'sederhana' < 'panas']temp_cat   # original category object categories not changed## ['low', 'high', 'medium', 'high', 'high', 'low', 'medium', 'medium', 'high']\n## Categories (3, object): ['low' < 'medium' < 'high']"},{"path":"pandas.html","id":"rename-inplace","chapter":"15 pandas","heading":"15.9.3.2 Rename Inplace","text":"Observe original categories changed using .rename()","code":"temp_cat.categories = ['sejuk','sederhana','panas']\ntemp_cat   # original category object categories is changed## ['sejuk', 'panas', 'sederhana', 'panas', 'panas', 'sejuk', 'sederhana', 'sederhana', 'panas']\n## Categories (3, object): ['sejuk' < 'sederhana' < 'panas']"},{"path":"pandas.html","id":"adding-new-category","chapter":"15 pandas","heading":"15.9.4 Adding New Category","text":"return new category object added categories","code":"temp_cat_more = temp_cat.add_categories(['susah','senang'])\ntemp_cat_more## ['sejuk', 'panas', 'sederhana', 'panas', 'panas', 'sejuk', 'sederhana', 'sederhana', 'panas']\n## Categories (5, object): ['sejuk' < 'sederhana' < 'panas' < 'susah' < 'senang']"},{"path":"pandas.html","id":"removing-category","chapter":"15 pandas","heading":"15.9.5 Removing Category","text":"place, hence return new categorical object","code":""},{"path":"pandas.html","id":"remove-specific-categories","chapter":"15 pandas","heading":"15.9.5.1 Remove Specific Categor(ies)","text":"Elements category removed become NaN","code":"temp = ['low','high','medium','high','high','low','medium','medium','high']\ntemp_cat = pd.Categorical(temp)\ntemp_cat_removed = temp_cat.remove_categories('low')\ntemp_cat_removed## [NaN, 'high', 'medium', 'high', 'high', NaN, 'medium', 'medium', 'high']\n## Categories (2, object): ['high', 'medium']"},{"path":"pandas.html","id":"remove-unused-category","chapter":"15 pandas","heading":"15.9.5.2 Remove Unused Category","text":"Since categories removed used, impact element","code":"print (temp_cat_more)## ['sejuk', 'panas', 'sederhana', 'panas', 'panas', 'sejuk', 'sederhana', 'sederhana', 'panas']\n## Categories (5, object): ['sejuk' < 'sederhana' < 'panas' < 'susah' < 'senang']temp_cat_more.remove_unused_categories()## ['sejuk', 'panas', 'sederhana', 'panas', 'panas', 'sejuk', 'sederhana', 'sederhana', 'panas']\n## Categories (3, object): ['sejuk' < 'sederhana' < 'panas']"},{"path":"pandas.html","id":"add-and-remove-categories-in-one-step---set","chapter":"15 pandas","heading":"15.9.6 Add and Remove Categories In One Step - Set()","text":"","code":"temp = ['low','high','medium','high','high','low','medium','medium','high']\ntemp_cat = pd.Categorical(temp, ordered=True)\ntemp_cat## ['low', 'high', 'medium', 'high', 'high', 'low', 'medium', 'medium', 'high']\n## Categories (3, object): ['high' < 'low' < 'medium']temp_cat.set_categories(['low','medium','sederhana','susah','senang'])## ['low', NaN, 'medium', NaN, NaN, 'low', 'medium', 'medium', NaN]\n## Categories (5, object): ['low' < 'medium' < 'sederhana' < 'susah' < 'senang']"},{"path":"pandas.html","id":"categorical-descriptive-analysis","chapter":"15 pandas","heading":"15.9.7 Categorical Descriptive Analysis","text":"","code":""},{"path":"pandas.html","id":"at-one-glance","chapter":"15 pandas","heading":"15.9.7.1 At One Glance","text":"","code":"temp_cat.describe()##             counts     freqs\n## categories                  \n## high             4  0.444444\n## low              2  0.222222\n## medium           3  0.333333"},{"path":"pandas.html","id":"frequency-count","chapter":"15 pandas","heading":"15.9.7.2 Frequency Count","text":"","code":"temp_cat.value_counts()## high      4\n## low       2\n## medium    3\n## dtype: int64"},{"path":"pandas.html","id":"least-frequent-category-most-frequent-category-and-most-frequent-category","chapter":"15 pandas","heading":"15.9.7.3 Least Frequent Category, Most Frequent Category, and Most Frequent Category","text":"","code":"( temp_cat.min(), temp_cat.max(), temp_cat.mode() )## ('high', 'medium', ['high']\n## Categories (3, object): ['high' < 'low' < 'medium'])\n## \n## <string>:1: FutureWarning: Categorical.mode is deprecated and will be removed in a future version. Use Series.mode instead."},{"path":"pandas.html","id":"other-methods","chapter":"15 pandas","heading":"15.9.8 Other Methods","text":"","code":""},{"path":"pandas.html","id":"get_values","chapter":"15 pandas","heading":"15.9.8.1 .get_values()","text":"Since actual value stored categorical object integer codes, get_values() function return values translated *.codes** property","code":"temp_cat#array## ['low', 'high', 'medium', 'high', 'high', 'low', 'medium', 'medium', 'high']\n## Categories (3, object): ['high' < 'low' < 'medium']"},{"path":"pandas.html","id":"dummies","chapter":"15 pandas","heading":"15.10 Dummies","text":"get_dummies creates columns categoriesThe underlying data can string pd.CategoricalIt produces new pd.DataFrame","code":""},{"path":"pandas.html","id":"sample-data-17","chapter":"15 pandas","heading":"15.10.1 Sample Data","text":"","code":"df = pd.DataFrame (\n    {'A': ['A1','A2','A3','A1','A3','A1'], \n     'B': ['B1','B2','B3','B1','B1','B3'],\n     'C': ['C1','C2','C3','C1',np.nan,np.nan]})\ndf##     A   B    C\n## 0  A1  B1   C1\n## 1  A2  B2   C2\n## 2  A3  B3   C3\n## 3  A1  B1   C1\n## 4  A3  B1  NaN\n## 5  A1  B3  NaN"},{"path":"pandas.html","id":"dummies-on-array-like-data","chapter":"15 pandas","heading":"15.10.2 Dummies on Array-Like Data","text":"","code":"pd.get_dummies(df.A)##    A1  A2  A3\n## 0   1   0   0\n## 1   0   1   0\n## 2   0   0   1\n## 3   1   0   0\n## 4   0   0   1\n## 5   1   0   0"},{"path":"pandas.html","id":"dummies-on-dataframe-multiple-columns","chapter":"15 pandas","heading":"15.10.3 Dummies on DataFrame (multiple columns)","text":"","code":""},{"path":"pandas.html","id":"all-columns","chapter":"15 pandas","heading":"15.10.3.1 All Columns","text":"","code":"pd.get_dummies(df)##    A_A1  A_A2  A_A3  B_B1  B_B2  B_B3  C_C1  C_C2  C_C3\n## 0     1     0     0     1     0     0     1     0     0\n## 1     0     1     0     0     1     0     0     1     0\n## 2     0     0     1     0     0     1     0     0     1\n## 3     1     0     0     1     0     0     1     0     0\n## 4     0     0     1     1     0     0     0     0     0\n## 5     1     0     0     0     0     1     0     0     0"},{"path":"pandas.html","id":"selected-columns","chapter":"15 pandas","heading":"15.10.3.2 Selected Columns","text":"","code":"cols = ['A','B']\npd.get_dummies(df[cols])##    A_A1  A_A2  A_A3  B_B1  B_B2  B_B3\n## 0     1     0     0     1     0     0\n## 1     0     1     0     0     1     0\n## 2     0     0     1     0     0     1\n## 3     1     0     0     1     0     0\n## 4     0     0     1     1     0     0\n## 5     1     0     0     0     0     1"},{"path":"pandas.html","id":"dummies-with-na","chapter":"15 pandas","heading":"15.10.4 Dummies with na","text":"default, nan values ignoredMake NaN dummy variable","code":"pd.get_dummies(df.C)##    C1  C2  C3\n## 0   1   0   0\n## 1   0   1   0\n## 2   0   0   1\n## 3   1   0   0\n## 4   0   0   0\n## 5   0   0   0pd.get_dummies(df.C,dummy_na=True)##    C1  C2  C3  NaN\n## 0   1   0   0    0\n## 1   0   1   0    0\n## 2   0   0   1    0\n## 3   1   0   0    0\n## 4   0   0   0    1\n## 5   0   0   0    1"},{"path":"pandas.html","id":"specify-prefixes","chapter":"15 pandas","heading":"15.10.5 Specify Prefixes","text":"","code":"pd.get_dummies(df.A, prefix='col')##    col_A1  col_A2  col_A3\n## 0       1       0       0\n## 1       0       1       0\n## 2       0       0       1\n## 3       1       0       0\n## 4       0       0       1\n## 5       1       0       0pd.get_dummies(df[cols], prefix=['colA','colB'])##    colA_A1  colA_A2  colA_A3  colB_B1  colB_B2  colB_B3\n## 0        1        0        0        1        0        0\n## 1        0        1        0        0        1        0\n## 2        0        0        1        0        0        1\n## 3        1        0        0        1        0        0\n## 4        0        0        1        1        0        0\n## 5        1        0        0        0        0        1"},{"path":"pandas.html","id":"dropping-first-column","chapter":"15 pandas","heading":"15.10.6 Dropping First Column","text":"Dummies cause colinearity issue regression redundant column.Dropping column loose information technically","code":"pd.get_dummies(df[cols],drop_first=True)##    A_A2  A_A3  B_B2  B_B3\n## 0     0     0     0     0\n## 1     1     0     1     0\n## 2     0     1     0     1\n## 3     0     0     0     0\n## 4     0     1     0     0\n## 5     0     0     0     1"},{"path":"pandas.html","id":"dataframegroupby","chapter":"15 pandas","heading":"15.11 DataFrameGroupBy","text":"groupby() DataFrame method, returns DataFrameGroupBy objectDataFrameGroupBy object open doors dataframe aggregation summarizationDataFrameGroupBy object flexible abstraction. many ways, can simply treat DataFrameGroup ’s collection DataFrames, difficult things hood","code":""},{"path":"pandas.html","id":"sample-data-18","chapter":"15 pandas","heading":"15.11.1 Sample Data","text":"","code":"company = pd.read_csv('data/company.csv')\ncompany##    Company Department      Name  Age  Salary  Birthdate\n## 0       C1         D1      Yong   45   15000   1/1/1970\n## 1       C1         D1      Chew   35   12000   2/1/1980\n## 2       C1         D2       Lim   34    8000  2/19/1977\n## 3       C1         D3     Jessy   23    2500  3/15/1990\n## 4       C1         D3  Hoi Ming   55   25000  4/15/1987\n## ..     ...        ...       ...  ...     ...        ...\n## 13      C3         D3     Chang   32    7900  7/26/1973\n## 14      C3         D1       Ong   44   17500  8/21/1980\n## 15      C3         D2      Lily   41   15300  7/17/1990\n## 16      C3         D3     Sally   54   21000  7/19/1968\n## 17      C3         D3    Esther   37   13500  3/16/1969\n## \n## [18 rows x 6 columns]"},{"path":"pandas.html","id":"creating-groups","chapter":"15 pandas","heading":"15.11.2 Creating Groups","text":"Group can created single multiple columns","code":"com_grp = company.groupby('Company') ## Single Column\ncom_dep_grp = company.groupby(['Company','Department'])  ## Multiple Column\ntype(com_dep_grp)## <class 'pandas.core.groupby.generic.DataFrameGroupBy'>"},{"path":"pandas.html","id":"properties-1","chapter":"15 pandas","heading":"15.11.3 Properties","text":"","code":""},{"path":"pandas.html","id":"number-of-groups","chapter":"15 pandas","heading":"15.11.3.1 Number of Groups","text":"","code":"com_dep_grp.ngroups## 9"},{"path":"pandas.html","id":"row-numbers-association","chapter":"15 pandas","heading":"15.11.3.2 Row Numbers Association","text":".groups property dictionary containing group key (identifying group) values (underlying row indexes group)","code":"gdict = com_dep_grp.groups       # return Dictionary\nprint( gdict.keys()   , '\\n\\n',  # group identifier\n       gdict.values()   )        # group row indexes## dict_keys([('C1', 'D1'), ('C1', 'D2'), ('C1', 'D3'), ('C2', 'D1'), ('C2', 'D2'), ('C2', 'D3'), ('C3', 'D1'), ('C3', 'D2'), ('C3', 'D3')]) \n## \n##  dict_values([Int64Index([0, 1], dtype='int64'), Int64Index([2], dtype='int64'), Int64Index([3, 4, 5], dtype='int64'), Int64Index([6], dtype='int64'), Int64Index([7, 8, 9], dtype='int64'), Int64Index([10, 11, 12], dtype='int64'), Int64Index([14], dtype='int64'), Int64Index([15], dtype='int64'), Int64Index([13, 16, 17], dtype='int64')])"},{"path":"pandas.html","id":"methods-1","chapter":"15 pandas","heading":"15.11.4 Methods","text":"","code":""},{"path":"pandas.html","id":"number-of-rows-in-each-group","chapter":"15 pandas","heading":"15.11.4.1 Number of Rows In Each Group","text":"","code":"com_dep_grp.size()  # return panda Series object## Company  Department\n## C1       D1            2\n##          D2            1\n##          D3            3\n## C2       D1            1\n##          D2            3\n##          D3            3\n## C3       D1            1\n##          D2            1\n##          D3            3\n## dtype: int64"},{"path":"pandas.html","id":"retrieve-rows","chapter":"15 pandas","heading":"15.11.5 Retrieve Rows","text":"","code":""},{"path":"pandas.html","id":"retrieve-n-th-row-of-each-grou","chapter":"15 pandas","heading":"15.11.5.1 Retrieve n-th Row Of Each Grou","text":"Row number 0-basedFor First row, use .first() nth(0)Last row, use .last() nth(-1)`","code":"print( com_dep_grp.nth(0)  , '\\n',\n       com_dep_grp.first())##                        Name  Age  Salary   Birthdate\n## Company Department                                  \n## C1      D1             Yong   45   15000    1/1/1970\n##         D2              Lim   34    8000   2/19/1977\n##         D3            Jessy   23    2500   3/15/1990\n## C2      D1             Anne   18     400   7/15/1997\n##         D2          Deborah   30    8600   8/15/1984\n##         D3          Michael   38   17000  11/30/1997\n## C3      D1              Ong   44   17500   8/21/1980\n##         D2             Lily   41   15300   7/17/1990\n##         D3            Chang   32    7900   7/26/1973 \n##                         Name  Age  Salary   Birthdate\n## Company Department                                  \n## C1      D1             Yong   45   15000    1/1/1970\n##         D2              Lim   34    8000   2/19/1977\n##         D3            Jessy   23    2500   3/15/1990\n## C2      D1             Anne   18     400   7/15/1997\n##         D2          Deborah   30    8600   8/15/1984\n##         D3          Michael   38   17000  11/30/1997\n## C3      D1              Ong   44   17500   8/21/1980\n##         D2             Lily   41   15300   7/17/1990\n##         D3            Chang   32    7900   7/26/1973print( com_dep_grp.nth(-1)  , '\\n',\n       com_dep_grp.last())##                        Name  Age  Salary   Birthdate\n## Company Department                                  \n## C1      D1             Chew   35   12000    2/1/1980\n##         D2              Lim   34    8000   2/19/1977\n##         D3          Sui Wei   56    3000   6/15/1990\n## C2      D1             Anne   18     400   7/15/1997\n##         D2            Jimmy   46   14000  10/31/1988\n##         D3          Bernard   29    9800   12/1/1963\n## C3      D1              Ong   44   17500   8/21/1980\n##         D2             Lily   41   15300   7/17/1990\n##         D3           Esther   37   13500   3/16/1969 \n##                         Name  Age  Salary   Birthdate\n## Company Department                                  \n## C1      D1             Chew   35   12000    2/1/1980\n##         D2              Lim   34    8000   2/19/1977\n##         D3          Sui Wei   56    3000   6/15/1990\n## C2      D1             Anne   18     400   7/15/1997\n##         D2            Jimmy   46   14000  10/31/1988\n##         D3          Bernard   29    9800   12/1/1963\n## C3      D1              Ong   44   17500   8/21/1980\n##         D2             Lily   41   15300   7/17/1990\n##         D3           Esther   37   13500   3/16/1969"},{"path":"pandas.html","id":"retrieve-n-rows-of-each-groups","chapter":"15 pandas","heading":"15.11.5.2 Retrieve N Rows Of Each Groups","text":"Example retrieve 2 rows group","code":"com_dep_grp.head(2)##    Company Department      Name  Age  Salary   Birthdate\n## 0       C1         D1      Yong   45   15000    1/1/1970\n## 1       C1         D1      Chew   35   12000    2/1/1980\n## 2       C1         D2       Lim   34    8000   2/19/1977\n## 3       C1         D3     Jessy   23    2500   3/15/1990\n## 4       C1         D3  Hoi Ming   55   25000   4/15/1987\n## ..     ...        ...       ...  ...     ...         ...\n## 11      C2         D3   Jeannie   30   12500  12/31/1980\n## 13      C3         D3     Chang   32    7900   7/26/1973\n## 14      C3         D1       Ong   44   17500   8/21/1980\n## 15      C3         D2      Lily   41   15300   7/17/1990\n## 16      C3         D3     Sally   54   21000   7/19/1968\n## \n## [14 rows x 6 columns]"},{"path":"pandas.html","id":"retrieve-all-rows-of-specific-group","chapter":"15 pandas","heading":"15.11.5.3 Retrieve All Rows Of Specific Group","text":"get_group() retrieves rows within specified group.","code":"com_dep_grp.get_group(('C1','D3'))##   Company Department      Name  Age  Salary  Birthdate\n## 3      C1         D3     Jessy   23    2500  3/15/1990\n## 4      C1         D3  Hoi Ming   55   25000  4/15/1987\n## 5      C1         D3   Sui Wei   56    3000  6/15/1990"},{"path":"pandas.html","id":"single-statistic-per-group","chapter":"15 pandas","heading":"15.11.6 Single Statistic Per Group","text":"","code":""},{"path":"pandas.html","id":"count","chapter":"15 pandas","heading":"15.11.6.1 count()","text":"count() valid data (null) fields within group","code":"com_dep_grp.count()  # return panda DataFrame object##                     Name  Age  Salary  Birthdate\n## Company Department                              \n## C1      D1             2    2       2          2\n##         D2             1    1       1          1\n##         D3             3    3       3          3\n## C2      D1             1    1       1          1\n##         D2             3    3       3          3\n##         D3             3    3       3          3\n## C3      D1             1    1       1          1\n##         D2             1    1       1          1\n##         D3             3    3       3          3"},{"path":"pandas.html","id":"sum","chapter":"15 pandas","heading":"15.11.6.2 sum()","text":"sums numeric columns groupTo sum specific columns group, use ['columnName'] select column.\nsingle column selected, output Series","code":"com_dep_grp.sum()##                     Age  Salary\n## Company Department             \n## C1      D1           80   27000\n##         D2           34    8000\n##         D3          134   30500\n## C2      D1           18     400\n##         D2          127   34600\n##         D3           97   39300\n## C3      D1           44   17500\n##         D2           41   15300\n##         D3          123   42400com_dep_grp['Age'].sum()## Company  Department\n## C1       D1             80\n##          D2             34\n##          D3            134\n## C2       D1             18\n##          D2            127\n##          D3             97\n## C3       D1             44\n##          D2             41\n##          D3            123\n## Name: Age, dtype: int64"},{"path":"pandas.html","id":"mean","chapter":"15 pandas","heading":"15.11.6.3 mean()","text":"average numeric columns groupTo average specific columns group, use ['columnName'] select column.\nsingle column selected, output Series","code":"com_dep_grp.mean()##                           Age        Salary\n## Company Department                         \n## C1      D1          40.000000  13500.000000\n##         D2          34.000000   8000.000000\n##         D3          44.666667  10166.666667\n## C2      D1          18.000000    400.000000\n##         D2          42.333333  11533.333333\n##         D3          32.333333  13100.000000\n## C3      D1          44.000000  17500.000000\n##         D2          41.000000  15300.000000\n##         D3          41.000000  14133.333333com_dep_grp['Age'].mean()## Company  Department\n## C1       D1            40.000000\n##          D2            34.000000\n##          D3            44.666667\n## C2       D1            18.000000\n##          D2            42.333333\n##          D3            32.333333\n## C3       D1            44.000000\n##          D2            41.000000\n##          D3            41.000000\n## Name: Age, dtype: float64"},{"path":"pandas.html","id":"multi-statistic-per-group","chapter":"15 pandas","heading":"15.11.7 Multi Statistic Per Group","text":"","code":""},{"path":"pandas.html","id":"single-function-to-columns","chapter":"15 pandas","heading":"15.11.7.1 Single Function To Column(s)","text":"Instructions aggregation provided form dictionary. Dictionary keys specifies column name, value function runCan use lambda x: customize calclulation entire column (x)Python built-function names can supplied without wrapping string 'function'","code":"com_dep_grp.agg({\n  'Age': sum ,                 ## Total age of the group\n  'Salary': lambda x: max(x),  ## Highest salary of the group\n  'Birthdate': 'first'         ## First birthday of the group\n})##                     Age  Salary   Birthdate\n## Company Department                         \n## C1      D1           80   15000    1/1/1970\n##         D2           34    8000   2/19/1977\n##         D3          134   25000   3/15/1990\n## C2      D1           18     400   7/15/1997\n##         D2          127   14000   8/15/1984\n##         D3           97   17000  11/30/1997\n## C3      D1           44   17500   8/21/1980\n##         D2           41   15300   7/17/1990\n##         D3          123   21000   7/26/1973"},{"path":"pandas.html","id":"multiple-function-to-columns","chapter":"15 pandas","heading":"15.11.7.2 Multiple Function to Column(s)","text":"Use list function names specify functions applied particular columnNotice output columns MultiIndex , indicating name funcitons appled level 1","code":"ag = com_dep_grp.agg({\n      'Age': ['mean', sum ],       ## Average age of the group\n      'Salary': lambda x: max(x),  ## Highest salary of the group\n      'Birthdate': 'first'         ## First birthday of the group\n    })\n    \nprint (ag, '\\n\\n', ag.columns)##                           Age        Salary   Birthdate\n##                          mean  sum <lambda>       first\n## Company Department                                     \n## C1      D1          40.000000   80    15000    1/1/1970\n##         D2          34.000000   34     8000   2/19/1977\n##         D3          44.666667  134    25000   3/15/1990\n## C2      D1          18.000000   18      400   7/15/1997\n##         D2          42.333333  127    14000   8/15/1984\n##         D3          32.333333   97    17000  11/30/1997\n## C3      D1          44.000000   44    17500   8/21/1980\n##         D2          41.000000   41    15300   7/17/1990\n##         D3          41.000000  123    21000   7/26/1973 \n## \n##  MultiIndex([(      'Age',     'mean'),\n##             (      'Age',      'sum'),\n##             (   'Salary', '<lambda>'),\n##             ('Birthdate',    'first')],\n##            )"},{"path":"pandas.html","id":"column-relabling","chapter":"15 pandas","heading":"15.11.7.3 Column Relabling","text":"Introduced Pandas 0.25.0, groupby aggregation relabelling supported using “named aggregation” simple tuples","code":"com_dep_grp.agg(\n  max_age     = ('Age', max),\n  salary_m100 = ('Salary',  lambda x: max(x)+100),  \n  first_bd    = ('Birthdate', 'first')\n)##                     max_age  salary_m100    first_bd\n## Company Department                                  \n## C1      D1               45        15100    1/1/1970\n##         D2               34         8100   2/19/1977\n##         D3               56        25100   3/15/1990\n## C2      D1               18          500   7/15/1997\n##         D2               51        14100   8/15/1984\n##         D3               38        17100  11/30/1997\n## C3      D1               44        17600   8/21/1980\n##         D2               41        15400   7/17/1990\n##         D3               54        21100   7/26/1973"},{"path":"pandas.html","id":"iteration-3","chapter":"15 pandas","heading":"15.11.8 Iteration","text":"DataFrameGroupBy object can thought collection named groups","code":"def print_groups (g):\n    for name,group in g:\n        print (name)\n        print (group[:2])\n        \nprint_groups (com_grp)## C1\n##   Company Department  Name  Age  Salary Birthdate\n## 0      C1         D1  Yong   45   15000  1/1/1970\n## 1      C1         D1  Chew   35   12000  2/1/1980\n## C2\n##   Company Department     Name  Age  Salary  Birthdate\n## 6      C2         D1     Anne   18     400  7/15/1997\n## 7      C2         D2  Deborah   30    8600  8/15/1984\n## C3\n##    Company Department   Name  Age  Salary  Birthdate\n## 13      C3         D3  Chang   32    7900  7/26/1973\n## 14      C3         D1    Ong   44   17500  8/21/1980com_grp## <pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000029995FD8310>"},{"path":"pandas.html","id":"transform","chapter":"15 pandas","heading":"15.11.9 Transform","text":"Transform operation used combined DataFrameGroupBy objecttransform() return new DataFrame objecttransform() perform function group, expands replicate multiple rows according original DataFrame","code":"grp = company.groupby('Company')\ngrp.size()## Company\n## C1    6\n## C2    7\n## C3    5\n## dtype: int64grp[['Age','Salary']].transform('sum')##     Age  Salary\n## 0   248   65500\n## 1   248   65500\n## 2   248   65500\n## 3   248   65500\n## 4   248   65500\n## ..  ...     ...\n## 13  208   75200\n## 14  208   75200\n## 15  208   75200\n## 16  208   75200\n## 17  208   75200\n## \n## [18 rows x 2 columns]grp.transform( lambda x:x+10 )##     Age  Salary\n## 0    55   15010\n## 1    45   12010\n## 2    44    8010\n## 3    33    2510\n## 4    65   25010\n## ..  ...     ...\n## 13   42    7910\n## 14   54   17510\n## 15   51   15310\n## 16   64   21010\n## 17   47   13510\n## \n## [18 rows x 2 columns]\n## \n## <string>:1: FutureWarning: Dropping invalid columns in DataFrameGroupBy.transform is deprecated. In a future version, a TypeError will be raised. Before calling .transform, select only columns which should be valid for the function.\n## <string>:1: FutureWarning: Dropping invalid columns in DataFrameGroupBy.transform is deprecated. In a future version, a TypeError will be raised. Before calling .transform, select only columns which should be valid for the function."},{"path":"pandas.html","id":"fundamental-analysis","chapter":"15 pandas","heading":"15.12 Fundamental Analysis","text":"","code":""},{"path":"pandas.html","id":"missing-data","chapter":"15 pandas","heading":"15.13 Missing Data","text":"","code":""},{"path":"pandas.html","id":"sample-data-19","chapter":"15 pandas","heading":"15.13.1 Sample Data","text":"Missing Data Column ?","code":"df = pd.DataFrame( np.random.randn(5, 3), \n                   index   =['a', 'c', 'e', 'f', 'h'],\n                   columns =['one', 'two', 'three'])\ndf['four'] = 'bar'\ndf['five'] = df['one'] > 0\n#df\ndf.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])##         one       two     three four   five\n## a -0.155909 -0.501790  0.235569  bar  False\n## b       NaN       NaN       NaN  NaN    NaN\n## c -1.763605 -1.095862 -1.087766  bar  False\n## d       NaN       NaN       NaN  NaN    NaN\n## e -0.305170 -0.473748 -0.200595  bar  False\n## f  0.355197  0.689518  0.410590  bar   True\n## g       NaN       NaN       NaN  NaN    NaN\n## h -0.564978  0.599391 -0.162936  bar  Falsedf.count()## one      5\n## two      5\n## three    5\n## four     5\n## five     5\n## dtype: int64len(df.index) - df.count()## one      0\n## two      0\n## three    0\n## four     0\n## five     0\n## dtype: int64df.isnull()##      one    two  three   four   five\n## a  False  False  False  False  False\n## c  False  False  False  False  False\n## e  False  False  False  False  False\n## f  False  False  False  False  False\n## h  False  False  False  False  Falsedf.describe()##             one       two     three\n## count  5.000000  5.000000  5.000000\n## mean  -0.486893 -0.156498 -0.161028\n## std    0.788635  0.772882  0.579752\n## min   -1.763605 -1.095862 -1.087766\n## 25%   -0.564978 -0.501790 -0.200595\n## 50%   -0.305170 -0.473748 -0.162936\n## 75%   -0.155909  0.599391  0.235569\n## max    0.355197  0.689518  0.410590"},{"path":"plydata-dplyr-for-python.html","id":"plydata-dplyr-for-python","chapter":"16 Plydata (dplyr for Python)","heading":"16 Plydata (dplyr for Python)","text":"","code":""},{"path":"plydata-dplyr-for-python.html","id":"sample-data-20","chapter":"16 Plydata (dplyr for Python)","heading":"16.1 Sample Data","text":"","code":"import pandas as pd\nimport numpy as np\nfrom plydata import define, query, if_else, ply, select, rename, arrange, group_by, summarize\n\nn = 200\ncomp = ['C' + i for i in np.random.randint( 1,4, size  = n).astype(str)] # 3x Company\ndept = ['D' + i for i in np.random.randint( 1,6, size  = n).astype(str)] # 5x Department\ngrp =  ['G' + i for i in np.random.randint( 1,3, size  = n).astype(str)] # 2x Groups\nvalue1 = np.random.normal( loc=50 , scale=5 , size = n)\nvalue2 = np.random.normal( loc=20 , scale=3 , size = n)\n#value3 = np.random.normal( loc=5 , scale=30 , size = n)\n\nmydf = pd.DataFrame({\n    'comp':comp, \n    'dept':dept, \n    'grp': grp,\n    'value1':value1, \n    'value2':value2\n    #'value3':value3 \n})\nmydf.head()##   comp dept grp     value1     value2\n## 0   C3   D4  G2  45.458891  23.268149\n## 1   C3   D2  G2  41.297968  18.753723\n## 2   C1   D4  G2  44.330892  20.857712\n## 3   C3   D3  G1  46.160095  22.016012\n## 4   C1   D2  G1  56.582156  20.679935"},{"path":"plydata-dplyr-for-python.html","id":"column-manipulation-1","chapter":"16 Plydata (dplyr for Python)","heading":"16.2 Column Manipulation","text":"","code":""},{"path":"plydata-dplyr-for-python.html","id":"copy-column","chapter":"16 Plydata (dplyr for Python)","heading":"16.2.1 Copy Column","text":"","code":"mydf >> define(newcol = 'value1')                 # simple method for one column##     comp dept grp     value1     value2     newcol\n## 0     C3   D4  G2  45.458891  23.268149  45.458891\n## 1     C3   D2  G2  41.297968  18.753723  41.297968\n## 2     C1   D4  G2  44.330892  20.857712  44.330892\n## 3     C3   D3  G1  46.160095  22.016012  46.160095\n## 4     C1   D2  G1  56.582156  20.679935  56.582156\n## ..   ...  ...  ..        ...        ...        ...\n## 195   C2   D4  G1  61.154225  23.103160  61.154225\n## 196   C3   D5  G1  41.214654  21.592592  41.214654\n## 197   C3   D5  G1  40.361441  15.997338  40.361441\n## 198   C2   D3  G1  55.828641  17.372102  55.828641\n## 199   C1   D4  G2  50.582033  25.292302  50.582033\n## \n## [200 rows x 6 columns]mydf >> define (('newcol1', 'value1'), newcol2='value2')  # method for muiltiple new columns##     comp dept grp     value1     value2    newcol1    newcol2\n## 0     C3   D4  G2  45.458891  23.268149  45.458891  23.268149\n## 1     C3   D2  G2  41.297968  18.753723  41.297968  18.753723\n## 2     C1   D4  G2  44.330892  20.857712  44.330892  20.857712\n## 3     C3   D3  G1  46.160095  22.016012  46.160095  22.016012\n## 4     C1   D2  G1  56.582156  20.679935  56.582156  20.679935\n## ..   ...  ...  ..        ...        ...        ...        ...\n## 195   C2   D4  G1  61.154225  23.103160  61.154225  23.103160\n## 196   C3   D5  G1  41.214654  21.592592  41.214654  21.592592\n## 197   C3   D5  G1  40.361441  15.997338  40.361441  15.997338\n## 198   C2   D3  G1  55.828641  17.372102  55.828641  17.372102\n## 199   C1   D4  G2  50.582033  25.292302  50.582033  25.292302\n## \n## [200 rows x 7 columns]"},{"path":"plydata-dplyr-for-python.html","id":"new-column-from-existing-column","chapter":"16 Plydata (dplyr for Python)","heading":"16.2.2 New Column from existing Column","text":"Without specify new column name, derived expressionSpecify new column nameDefine multiple new columns one go. Observe three ways specify new columns","code":"mydf >> define ('value1*2')##     comp dept grp     value1     value2    value1*2\n## 0     C3   D4  G2  45.458891  23.268149   90.917782\n## 1     C3   D2  G2  41.297968  18.753723   82.595935\n## 2     C1   D4  G2  44.330892  20.857712   88.661784\n## 3     C3   D3  G1  46.160095  22.016012   92.320190\n## 4     C1   D2  G1  56.582156  20.679935  113.164311\n## ..   ...  ...  ..        ...        ...         ...\n## 195   C2   D4  G1  61.154225  23.103160  122.308450\n## 196   C3   D5  G1  41.214654  21.592592   82.429308\n## 197   C3   D5  G1  40.361441  15.997338   80.722882\n## 198   C2   D3  G1  55.828641  17.372102  111.657282\n## 199   C1   D4  G2  50.582033  25.292302  101.164066\n## \n## [200 rows x 6 columns]mydf >> define(value3 = 'value1*2')##     comp dept grp     value1     value2      value3\n## 0     C3   D4  G2  45.458891  23.268149   90.917782\n## 1     C3   D2  G2  41.297968  18.753723   82.595935\n## 2     C1   D4  G2  44.330892  20.857712   88.661784\n## 3     C3   D3  G1  46.160095  22.016012   92.320190\n## 4     C1   D2  G1  56.582156  20.679935  113.164311\n## ..   ...  ...  ..        ...        ...         ...\n## 195   C2   D4  G1  61.154225  23.103160  122.308450\n## 196   C3   D5  G1  41.214654  21.592592   82.429308\n## 197   C3   D5  G1  40.361441  15.997338   80.722882\n## 198   C2   D3  G1  55.828641  17.372102  111.657282\n## 199   C1   D4  G2  50.582033  25.292302  101.164066\n## \n## [200 rows x 6 columns]mydf >> define('value1*2',('newcol2','value2*2'),newcol3='value2*3')##     comp dept grp     value1     value2    value1*2    newcol2    newcol3\n## 0     C3   D4  G2  45.458891  23.268149   90.917782  46.536298  69.804446\n## 1     C3   D2  G2  41.297968  18.753723   82.595935  37.507445  56.261168\n## 2     C1   D4  G2  44.330892  20.857712   88.661784  41.715423  62.573135\n## 3     C3   D3  G1  46.160095  22.016012   92.320190  44.032024  66.048035\n## 4     C1   D2  G1  56.582156  20.679935  113.164311  41.359869  62.039804\n## ..   ...  ...  ..        ...        ...         ...        ...        ...\n## 195   C2   D4  G1  61.154225  23.103160  122.308450  46.206320  69.309479\n## 196   C3   D5  G1  41.214654  21.592592   82.429308  43.185185  64.777777\n## 197   C3   D5  G1  40.361441  15.997338   80.722882  31.994675  47.992013\n## 198   C2   D3  G1  55.828641  17.372102  111.657282  34.744204  52.116306\n## 199   C1   D4  G2  50.582033  25.292302  101.164066  50.584604  75.876906\n## \n## [200 rows x 8 columns]"},{"path":"plydata-dplyr-for-python.html","id":"select-columns","chapter":"16 Plydata (dplyr for Python)","heading":"16.2.3 Select Column(s)","text":"","code":"mydf2 = mydf >> define(newcol1='value1',newcol2='value2')\nmydf2.info()## <class 'pandas.core.frame.DataFrame'>\n## RangeIndex: 200 entries, 0 to 199\n## Data columns (total 7 columns):\n##  #   Column   Non-Null Count  Dtype  \n## ---  ------   --------------  -----  \n##  0   comp     200 non-null    object \n##  1   dept     200 non-null    object \n##  2   grp      200 non-null    object \n##  3   value1   200 non-null    float64\n##  4   value2   200 non-null    float64\n##  5   newcol1  200 non-null    float64\n##  6   newcol2  200 non-null    float64\n## dtypes: float64(4), object(3)\n## memory usage: 11.1+ KB"},{"path":"plydata-dplyr-for-python.html","id":"by-column-names","chapter":"16 Plydata (dplyr for Python)","heading":"16.2.3.1 By Column Names","text":"Exact Coumn NameColumn Name Starts …Column Name Ends …Column Name Contains …","code":"mydf2 >> select ('comp','dept','value1')##     comp dept     value1\n## 0     C3   D4  45.458891\n## 1     C3   D2  41.297968\n## 2     C1   D4  44.330892\n## 3     C3   D3  46.160095\n## 4     C1   D2  56.582156\n## ..   ...  ...        ...\n## 195   C2   D4  61.154225\n## 196   C3   D5  41.214654\n## 197   C3   D5  40.361441\n## 198   C2   D3  55.828641\n## 199   C1   D4  50.582033\n## \n## [200 rows x 3 columns]mydf2 >> select ('comp', startswith='val')##     comp     value1     value2\n## 0     C3  45.458891  23.268149\n## 1     C3  41.297968  18.753723\n## 2     C1  44.330892  20.857712\n## 3     C3  46.160095  22.016012\n## 4     C1  56.582156  20.679935\n## ..   ...        ...        ...\n## 195   C2  61.154225  23.103160\n## 196   C3  41.214654  21.592592\n## 197   C3  40.361441  15.997338\n## 198   C2  55.828641  17.372102\n## 199   C1  50.582033  25.292302\n## \n## [200 rows x 3 columns]mydf2 >> select ('comp',endswith=('1','2','3'))##     comp     value1     value2    newcol1    newcol2\n## 0     C3  45.458891  23.268149  45.458891  23.268149\n## 1     C3  41.297968  18.753723  41.297968  18.753723\n## 2     C1  44.330892  20.857712  44.330892  20.857712\n## 3     C3  46.160095  22.016012  46.160095  22.016012\n## 4     C1  56.582156  20.679935  56.582156  20.679935\n## ..   ...        ...        ...        ...        ...\n## 195   C2  61.154225  23.103160  61.154225  23.103160\n## 196   C3  41.214654  21.592592  41.214654  21.592592\n## 197   C3  40.361441  15.997338  40.361441  15.997338\n## 198   C2  55.828641  17.372102  55.828641  17.372102\n## 199   C1  50.582033  25.292302  50.582033  25.292302\n## \n## [200 rows x 5 columns]mydf2 >> select('comp', contains=('col','val'))##     comp     value1     value2    newcol1    newcol2\n## 0     C3  45.458891  23.268149  45.458891  23.268149\n## 1     C3  41.297968  18.753723  41.297968  18.753723\n## 2     C1  44.330892  20.857712  44.330892  20.857712\n## 3     C3  46.160095  22.016012  46.160095  22.016012\n## 4     C1  56.582156  20.679935  56.582156  20.679935\n## ..   ...        ...        ...        ...        ...\n## 195   C2  61.154225  23.103160  61.154225  23.103160\n## 196   C3  41.214654  21.592592  41.214654  21.592592\n## 197   C3  40.361441  15.997338  40.361441  15.997338\n## 198   C2  55.828641  17.372102  55.828641  17.372102\n## 199   C1  50.582033  25.292302  50.582033  25.292302\n## \n## [200 rows x 5 columns]"},{"path":"plydata-dplyr-for-python.html","id":"specify-column-range","chapter":"16 Plydata (dplyr for Python)","heading":"16.2.3.2 Specify Column Range","text":"","code":"mydf2 >> select ('comp', slice('value1','newcol2'))##     comp     value1     value2    newcol1    newcol2\n## 0     C3  45.458891  23.268149  45.458891  23.268149\n## 1     C3  41.297968  18.753723  41.297968  18.753723\n## 2     C1  44.330892  20.857712  44.330892  20.857712\n## 3     C3  46.160095  22.016012  46.160095  22.016012\n## 4     C1  56.582156  20.679935  56.582156  20.679935\n## ..   ...        ...        ...        ...        ...\n## 195   C2  61.154225  23.103160  61.154225  23.103160\n## 196   C3  41.214654  21.592592  41.214654  21.592592\n## 197   C3  40.361441  15.997338  40.361441  15.997338\n## 198   C2  55.828641  17.372102  55.828641  17.372102\n## 199   C1  50.582033  25.292302  50.582033  25.292302\n## \n## [200 rows x 5 columns]"},{"path":"plydata-dplyr-for-python.html","id":"drop-columns","chapter":"16 Plydata (dplyr for Python)","heading":"16.2.4 Drop Column(s)","text":"Combined Method\nCombine assignment dictionary method","code":"mydf2 >> select('newcol1','newcol2',drop=True)##     comp dept grp     value1     value2\n## 0     C3   D4  G2  45.458891  23.268149\n## 1     C3   D2  G2  41.297968  18.753723\n## 2     C1   D4  G2  44.330892  20.857712\n## 3     C3   D3  G1  46.160095  22.016012\n## 4     C1   D2  G1  56.582156  20.679935\n## ..   ...  ...  ..        ...        ...\n## 195   C2   D4  G1  61.154225  23.103160\n## 196   C3   D5  G1  41.214654  21.592592\n## 197   C3   D5  G1  40.361441  15.997338\n## 198   C2   D3  G1  55.828641  17.372102\n## 199   C1   D4  G2  50.582033  25.292302\n## \n## [200 rows x 5 columns]mydf >> rename( {'val.1' : 'value1',\n                 'val.2' : 'value2' })##     comp dept grp      val.1      val.2\n## 0     C3   D4  G2  45.458891  23.268149\n## 1     C3   D2  G2  41.297968  18.753723\n## 2     C1   D4  G2  44.330892  20.857712\n## 3     C3   D3  G1  46.160095  22.016012\n## 4     C1   D2  G1  56.582156  20.679935\n## ..   ...  ...  ..        ...        ...\n## 195   C2   D4  G1  61.154225  23.103160\n## 196   C3   D5  G1  41.214654  21.592592\n## 197   C3   D5  G1  40.361441  15.997338\n## 198   C2   D3  G1  55.828641  17.372102\n## 199   C1   D4  G2  50.582033  25.292302\n## \n## [200 rows x 5 columns]mydf >> rename( {'val.1' : 'value1',\n                 'val.2' : 'value2'\n              }, group = 'grp' )##     comp dept group      val.1      val.2\n## 0     C3   D4    G2  45.458891  23.268149\n## 1     C3   D2    G2  41.297968  18.753723\n## 2     C1   D4    G2  44.330892  20.857712\n## 3     C3   D3    G1  46.160095  22.016012\n## 4     C1   D2    G1  56.582156  20.679935\n## ..   ...  ...   ...        ...        ...\n## 195   C2   D4    G1  61.154225  23.103160\n## 196   C3   D5    G1  41.214654  21.592592\n## 197   C3   D5    G1  40.361441  15.997338\n## 198   C2   D3    G1  55.828641  17.372102\n## 199   C1   D4    G2  50.582033  25.292302\n## \n## [200 rows x 5 columns]"},{"path":"plydata-dplyr-for-python.html","id":"sorting-arrange","chapter":"16 Plydata (dplyr for Python)","heading":"16.3 Sorting (arrange)","text":"Use ‘-colName’ decending","code":"mydf >> arrange('comp', '-value1')##     comp dept grp     value1     value2\n## 58    C1   D4  G1  60.307045  21.083403\n## 102   C1   D4  G2  58.981952  16.308049\n## 145   C1   D5  G1  58.549771  22.272869\n## 6     C1   D1  G2  56.802031  26.452286\n## 4     C1   D2  G1  56.582156  20.679935\n## ..   ...  ...  ..        ...        ...\n## 197   C3   D5  G1  40.361441  15.997338\n## 83    C3   D1  G2  40.047849  18.358584\n## 61    C3   D3  G1  39.956896  21.562009\n## 149   C3   D1  G1  39.856548  23.031184\n## 28    C3   D2  G2  36.070489  23.934250\n## \n## [200 rows x 5 columns]"},{"path":"plydata-dplyr-for-python.html","id":"grouping","chapter":"16 Plydata (dplyr for Python)","heading":"16.4 Grouping","text":"","code":"mydf.info()## <class 'pandas.core.frame.DataFrame'>\n## RangeIndex: 200 entries, 0 to 199\n## Data columns (total 5 columns):\n##  #   Column  Non-Null Count  Dtype  \n## ---  ------  --------------  -----  \n##  0   comp    200 non-null    object \n##  1   dept    200 non-null    object \n##  2   grp     200 non-null    object \n##  3   value1  200 non-null    float64\n##  4   value2  200 non-null    float64\n## dtypes: float64(2), object(3)\n## memory usage: 7.9+ KBgdf = mydf >> group_by('comp','dept')\ntype(gdf)## <class 'plydata.types.GroupedDataFrame'>"},{"path":"plydata-dplyr-for-python.html","id":"summarization","chapter":"16 Plydata (dplyr for Python)","heading":"16.5 Summarization","text":"","code":""},{"path":"plydata-dplyr-for-python.html","id":"simple-method","chapter":"16 Plydata (dplyr for Python)","heading":"16.5.1 Simple Method","text":"Passing Multiple Expressions","code":"gdf >> summarize('n()','sum(value1)','mean(value2)')##    comp dept  n()  sum(value1)  mean(value2)\n## 0    C3   D4   13   655.633704     20.896871\n## 1    C3   D2   11   530.387391     20.529975\n## 2    C1   D4   13   639.888892     20.612384\n## 3    C3   D3   15   763.036828     20.875640\n## 4    C1   D2   16   751.949590     20.329274\n## 5    C1   D1   12   603.518253     22.128551\n## 6    C2   D3   10   500.064084     20.009526\n## 7    C3   D5   18   862.395615     19.219902\n## 8    C1   D5   16   795.520165     19.880989\n## 9    C2   D2   17   864.823873     19.937338\n## 10   C2   D1    8   371.848479     19.471002\n## 11   C2   D4   16   808.174763     19.555901\n## 12   C1   D3   11   537.281264     20.370518\n## 13   C3   D1   12   594.712175     20.054976\n## 14   C2   D5   12   588.679310     18.745307"},{"path":"plydata-dplyr-for-python.html","id":"specify-summarized-column-name","chapter":"16 Plydata (dplyr for Python)","heading":"16.5.2 Specify Summarized Column Name","text":"Assignment Method\n- Passing colName=‘expression’**\n- Column name contain special characterTuple Method (‘colName’,‘expression’)\nUse column name contain special character","code":"gdf >> summarize(count='n()',v1sum='sum(value1)',v2_mean='mean(value2)')##    comp dept  count       v1sum    v2_mean\n## 0    C3   D4     13  655.633704  20.896871\n## 1    C3   D2     11  530.387391  20.529975\n## 2    C1   D4     13  639.888892  20.612384\n## 3    C3   D3     15  763.036828  20.875640\n## 4    C1   D2     16  751.949590  20.329274\n## 5    C1   D1     12  603.518253  22.128551\n## 6    C2   D3     10  500.064084  20.009526\n## 7    C3   D5     18  862.395615  19.219902\n## 8    C1   D5     16  795.520165  19.880989\n## 9    C2   D2     17  864.823873  19.937338\n## 10   C2   D1      8  371.848479  19.471002\n## 11   C2   D4     16  808.174763  19.555901\n## 12   C1   D3     11  537.281264  20.370518\n## 13   C3   D1     12  594.712175  20.054976\n## 14   C2   D5     12  588.679310  18.745307gdf >> summarize(('count','n()'),('v1.sum','sum(value1)'),('s2.sum','sum(value2)'),v2mean=np.mean(value2))##    comp dept  count      v1.sum      s2.sum     v2mean\n## 0    C3   D4     13  655.633704  271.659328  20.154106\n## 1    C3   D2     11  530.387391  225.829729  20.154106\n## 2    C1   D4     13  639.888892  267.960991  20.154106\n## 3    C3   D3     15  763.036828  313.134597  20.154106\n## 4    C1   D2     16  751.949590  325.268389  20.154106\n## 5    C1   D1     12  603.518253  265.542609  20.154106\n## 6    C2   D3     10  500.064084  200.095255  20.154106\n## 7    C3   D5     18  862.395615  345.958232  20.154106\n## 8    C1   D5     16  795.520165  318.095818  20.154106\n## 9    C2   D2     17  864.823873  338.934747  20.154106\n## 10   C2   D1      8  371.848479  155.768018  20.154106\n## 11   C2   D4     16  808.174763  312.894411  20.154106\n## 12   C1   D3     11  537.281264  224.075693  20.154106\n## 13   C3   D1     12  594.712175  240.659716  20.154106\n## 14   C2   D5     12  588.679310  224.943680  20.154106"},{"path":"plydata-dplyr-for-python.html","id":"number-of-rows-in-group","chapter":"16 Plydata (dplyr for Python)","heading":"16.5.3 Number of Rows in Group","text":"n() : total rows groupn_unique() : total rows unique value","code":"gdf >> summarize(count='n()', va11_unique='n_unique(value1)')##    comp dept  count  va11_unique\n## 0    C3   D4     13           13\n## 1    C3   D2     11           11\n## 2    C1   D4     13           13\n## 3    C3   D3     15           15\n## 4    C1   D2     16           16\n## 5    C1   D1     12           12\n## 6    C2   D3     10           10\n## 7    C3   D5     18           18\n## 8    C1   D5     16           16\n## 9    C2   D2     17           17\n## 10   C2   D1      8            8\n## 11   C2   D4     16           16\n## 12   C1   D3     11           11\n## 13   C3   D1     12           12\n## 14   C2   D5     12           12"},{"path":"sklearn.html","id":"sklearn","chapter":"17 sklearn","heading":"17 sklearn","text":"machine learning library.","code":"from IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container { width:75% !important; margin-left:350px; }<\/style>\"))\n#matplotlib inline## <IPython.core.display.HTML object>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport math\npd.set_option( 'display.notebook_repr_html', False)  # render Series and DataFrame as text, not HTML\npd.set_option( 'display.max_column', 10)    # number of columns\npd.set_option( 'display.max_rows', 10)     # number of rows\npd.set_option( 'display.width', 90)        # number of characters per row\n\nimport os\nos.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = \"C:\\ProgramData\\Anaconda3\\Library\\plugins\\platforms\"\n#import matplotlib\n#matplotlib.use('Qt5Agg')"},{"path":"sklearn.html","id":"the-library","chapter":"17 sklearn","heading":"17.1 The Library","text":"sklearn automatically import subpackages. Therefore subpakcages must specifically loaded use.","code":"# Sample Data\nfrom sklearn                 import datasets\n\n# Model Selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import LeaveOneOut\nfrom sklearn.model_selection import cross_validate\n\n# Preprocessing\nfrom sklearn.impute   import SimpleImputer\nfrom sklearn.preprocessing   import MinMaxScaler\nfrom sklearn.preprocessing   import StandardScaler\nfrom sklearn.preprocessing   import Normalizer\nfrom sklearn.preprocessing   import PolynomialFeatures\n\n# Model and Pipeline\nfrom sklearn.linear_model    import LinearRegression,Lasso\nfrom sklearn.pipeline        import make_pipeline\n\n# Measurement\nfrom sklearn.metrics         import *\n\nimport statsmodels.formula.api as smf"},{"path":"sklearn.html","id":"model-fitting","chapter":"17 sklearn","heading":"17.2 Model Fitting","text":"split","code":""},{"path":"sklearn.html","id":"underfitting","chapter":"17 sklearn","heading":"17.2.1 Underfitting","text":"model fit training data therefore misses trends dataThe model generalized new data, usually result simple model (enough predictors/independent variables)model poor predictive abilityFor example, fit linear model (like linear regression) data linear","code":""},{"path":"sklearn.html","id":"overfitting","chapter":"17 sklearn","heading":"17.2.2 Overfitting","text":"model trained ?well? now, well, fit closely training datasetThe model complex (.e. many features/variables compared number observations)model accurate training data probably accurate untrained new dataThe model generalized (generalized), meaning can generalize resultsThe model learns describes ?noise? training data instead actual relationships variables data","code":""},{"path":"sklearn.html","id":"just-right","chapter":"17 sklearn","heading":"17.2.3 Just Right","text":"worth noting underfitting prevalent overfittingNevertheless, want avoid problems data analysisWe want find middle ground overfitting model","code":""},{"path":"sklearn.html","id":"model-tuning","chapter":"17 sklearn","heading":"17.3 Model Tuning","text":"highly complex model tend overfitA flexible model tend underfitComplexity can reduced :\n- Less features\n- Less degree polynomial features\n- Apply generalization (tuning hyperparameters)split","code":""},{"path":"sklearn.html","id":"high-level-ml-process","chapter":"17 sklearn","heading":"17.4 High Level ML Process","text":"split","code":""},{"path":"sklearn.html","id":"built-in-datasets","chapter":"17 sklearn","heading":"17.5 Built-in Datasets","text":"sklearn included popular datasets play \ndataset type Bunch.\nuseful data (array) form properties:\n- keys (display data availabe within dataset)\n- data (common)\n- target (common)\n- DESCR (common)\n- feature_names (dataset)\n- target_names (dataset)\n- images (dataset)","code":""},{"path":"sklearn.html","id":"diabetes-regression","chapter":"17 sklearn","heading":"17.5.1 diabetes (regression)","text":"","code":""},{"path":"sklearn.html","id":"load-dataset","chapter":"17 sklearn","heading":"17.5.1.1 Load Dataset","text":"","code":"diabetes = datasets.load_diabetes()\nprint (type(diabetes))## <class 'sklearn.utils._bunch.Bunch'>"},{"path":"sklearn.html","id":"keys","chapter":"17 sklearn","heading":"17.5.1.2 keys","text":"","code":"diabetes.keys()## dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename', 'data_module'])"},{"path":"sklearn.html","id":"features-and-target","chapter":"17 sklearn","heading":"17.5.1.3 Features and Target","text":".data = features - two dimension array\n.target = target - one dimension array","code":"print (type(diabetes.data))## <class 'numpy.ndarray'>print (type(diabetes.target))## <class 'numpy.ndarray'>print (diabetes.data.shape)## (442, 10)print (diabetes.target.shape)## (442,)"},{"path":"sklearn.html","id":"load-with-xy-convenient-method","chapter":"17 sklearn","heading":"17.5.1.4 Load with X,y (Convenient Method)","text":"using return_X_y = True, data loaded X, target loaded y","code":"X,y      = datasets.load_diabetes(return_X_y=True)print (X.shape)## (442, 10)print (y.shape)## (442,)"},{"path":"sklearn.html","id":"digits-classification","chapter":"17 sklearn","heading":"17.5.2 digits (Classification)","text":"copy test set UCI ML hand-written digits datasets","code":"digits = datasets.load_digits()\nprint (type(digits))## <class 'sklearn.utils._bunch.Bunch'>print (type(digits.data))## <class 'numpy.ndarray'>digits.keys()## dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])digits.target_names## array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"},{"path":"sklearn.html","id":"data","chapter":"17 sklearn","heading":"17.5.2.1 data","text":"","code":"digits.data.shape  # features## (1797, 64)digits.target.shape # target## (1797,)"},{"path":"sklearn.html","id":"images","chapter":"17 sklearn","heading":"17.5.2.2 Images","text":"images 3 dimensional arrayThere 1797 samples, sample 8x8 pixelsEach element represent data make target","code":"digits.images.shape## (1797, 8, 8)type(digits.images)## <class 'numpy.ndarray'>print (digits.target[100])## 4print (digits.images[100])## [[ 0.  0.  0.  2. 13.  0.  0.  0.]\n##  [ 0.  0.  0.  8. 15.  0.  0.  0.]\n##  [ 0.  0.  5. 16.  5.  2.  0.  0.]\n##  [ 0.  0. 15. 12.  1. 16.  4.  0.]\n##  [ 0.  4. 16.  2.  9. 16.  8.  0.]\n##  [ 0.  0. 10. 14. 16. 16.  4.  0.]\n##  [ 0.  0.  0.  0. 13.  8.  0.  0.]\n##  [ 0.  0.  0.  0. 13.  6.  0.  0.]]plt.matshow(digits.images[100]) "},{"path":"sklearn.html","id":"loading-into-xy-convenient-method","chapter":"17 sklearn","heading":"17.5.2.3 Loading Into X,y (Convenient Method)","text":"","code":"X,y = datasets.load_digits(return_X_y=True)X.shape## (1797, 64)y.shape## (1797,)"},{"path":"sklearn.html","id":"iris-classification","chapter":"17 sklearn","heading":"17.5.3 iris (Classification)","text":"","code":"iris = datasets.load_iris()iris.keys()## dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"},{"path":"sklearn.html","id":"feature-names","chapter":"17 sklearn","heading":"17.5.3.1 Feature Names","text":"","code":"iris.feature_names## ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']"},{"path":"sklearn.html","id":"target","chapter":"17 sklearn","heading":"17.5.3.2 target","text":"","code":"iris.target_names## array(['setosa', 'versicolor', 'virginica'], dtype='<U10')iris.target## array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n##        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n##        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n##        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n##        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n##        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n##        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"},{"path":"sklearn.html","id":"train-test-data-splitting","chapter":"17 sklearn","heading":"17.6 Train Test Data Splitting","text":"","code":""},{"path":"sklearn.html","id":"sample-data-21","chapter":"17 sklearn","heading":"17.6.1 Sample Data","text":"Generate 100 rows data, 3x features (X1,X2,X3), one dependant variable (Y)","code":"n = 21  # number of samples\nI = 5  # intercept value\nE = np.random.randint( 1,20, n)  # Error\nx1 = np.random.randint( 1,n+1, n)\nx2 = np.random.randint( 1,n+1, n)\nx3 = np.random.randint( 1,n+1, n)\ny = 0.1*x1 + 0.2*x2 + 0.3*x3 + E + I\nmydf = pd.DataFrame({\n    'y':y,\n    'x1':x1,\n    'x2':x2,\n    'x3':x3\n})\nmydf.shape## (21, 4)"},{"path":"sklearn.html","id":"one-time-split","chapter":"17 sklearn","heading":"17.6.2 One Time Split","text":"sklearn::train_test_split() two forms:\n- Take one DF, split 2 DF (sklearn modeling use method\n- Take two DFs, split 4 DF","code":"mydf.head()##       y  x1  x2  x3\n## 0  19.4   2  16  10\n## 1  17.3  15   9  10\n## 2  26.1  10   4  11\n## 3  21.2   1  20  17\n## 4  25.7   9   1   2"},{"path":"sklearn.html","id":"method-1-split-one-dataframe-into-two-train-test","chapter":"17 sklearn","heading":"17.6.2.1 Method 1: Split One Dataframe Into Two (Train & Test)","text":"split","code":"traindf, testdf = train_test_split( df, test_size=, random_state= ) \n # random_state : seed number (integer), optional\n # test_size    : fraction of 1, 0.2 means 20%traindf, testdf = train_test_split(mydf,test_size=0.2, random_state=25)print (len(traindf))## 16print (len(testdf))## 5"},{"path":"sklearn.html","id":"method-2-split-two-dataframe-xy-into-four-x_traintest-y_traintest","chapter":"17 sklearn","heading":"17.6.2.2 Method 2: Split Two DataFrame (X,Y) into Four x_train/test, y_train/test","text":"splitSplit DataFrame X Y FirstThen Split X/Y x_train/test, y_train/test","code":"x_train, x_test, y_train, y_test = train_test_split( X,Y, test_size=, random_state= )\n # random_state : seed number (integer), optional\n # test_size    : fraction of 1, 0.2 means 20%feature_cols = ['x1','x2','x3']\nX = mydf[feature_cols]\nY = mydf.yx_train, x_test, y_train, y_test = train_test_split( X,Y, test_size=0.2, random_state=25)\nprint (len(x_train))## 16print (len(x_test))## 5"},{"path":"sklearn.html","id":"k-fold","chapter":"17 sklearn","heading":"17.6.3 K-Fold","text":"splitsuffle=False (default), meaning index number taken continouslyshuffle=True","code":"KFold(n_splits=3, shuffle=False, random_state=None)kf = KFold(n_splits=7)for train_index, test_index in kf.split(X):\n  print (train_index, test_index)## [ 3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20] [0 1 2]\n## [ 0  1  2  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20] [3 4 5]\n## [ 0  1  2  3  4  5  9 10 11 12 13 14 15 16 17 18 19 20] [6 7 8]\n## [ 0  1  2  3  4  5  6  7  8 12 13 14 15 16 17 18 19 20] [ 9 10 11]\n## [ 0  1  2  3  4  5  6  7  8  9 10 11 15 16 17 18 19 20] [12 13 14]\n## [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 18 19 20] [15 16 17]\n## [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17] [18 19 20]kf = KFold(n_splits=7, shuffle=True)for train_index, test_index in kf.split(X):\n  print (train_index, test_index)## [ 0  1  2  3  4  5  6  7  8 11 12 13 14 15 16 18 19 20] [ 9 10 17]\n## [ 0  1  2  3  4  5  6  8  9 10 11 13 14 15 16 17 18 19] [ 7 12 20]\n## [ 0  2  4  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20] [1 3 5]\n## [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 16 17 19 20] [13 15 18]\n## [ 0  1  3  4  5  6  7  9 10 11 12 13 14 15 17 18 19 20] [ 2  8 16]\n## [ 0  1  2  3  5  6  7  8  9 10 11 12 13 15 16 17 18 20] [ 4 14 19]\n## [ 1  2  3  4  5  7  8  9 10 12 13 14 15 16 17 18 19 20] [ 0  6 11]"},{"path":"sklearn.html","id":"leave-one-out","chapter":"17 sklearn","heading":"17.6.4 Leave One Out","text":"dataset N rows, Leave One split N-1 times, time leaving one row test, remaning training set.Due high number test sets (number samples-1) cross-validation method can costly. large datasets one favor KFold.","code":"loo = LeaveOneOut()for train_index, test_index in loo.split(X):\n  print (train_index, test_index)## [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20] [0]\n## [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20] [1]\n## [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20] [2]\n## [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20] [3]\n## [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20] [4]\n## [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20] [5]\n## [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14 15 16 17 18 19 20] [6]\n## [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20] [7]\n## [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15 16 17 18 19 20] [8]\n## [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20] [9]\n## [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14 15 16 17 18 19 20] [10]\n## [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14 15 16 17 18 19 20] [11]\n## [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15 16 17 18 19 20] [12]\n## [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15 16 17 18 19 20] [13]\n## [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 15 16 17 18 19 20] [14]\n## [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 16 17 18 19 20] [15]\n## [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 18 19 20] [16]\n## [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19 20] [17]\n## [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 19 20] [18]\n## [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 20] [19]\n## [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] [20]X##     x1  x2  x3\n## 0    2  16  10\n## 1   15   9  10\n## 2   10   4  11\n## 3    1  20  17\n## 4    9   1   2\n## ..  ..  ..  ..\n## 16  12  11   2\n## 17  13   1  11\n## 18   2  12  16\n## 19  16   2  13\n## 20  15   2   1\n## \n## [21 rows x 3 columns]"},{"path":"sklearn.html","id":"polynomial-transform","chapter":"17 sklearn","heading":"17.7 Polynomial Transform","text":"can used part feature engineering, introduce new features data seems fit quadradic model.","code":""},{"path":"sklearn.html","id":"single-variable","chapter":"17 sklearn","heading":"17.7.1 Single Variable","text":"","code":""},{"path":"sklearn.html","id":"sample-data-22","chapter":"17 sklearn","heading":"17.7.1.1 Sample Data","text":"Data must 2-D polynomial features can applied. Code convert 1D array 2D array.","code":"x = np.array([1, 2, 3, 4, 5])\nX = x[:,np.newaxis]\nX## array([[1],\n##        [2],\n##        [3],\n##        [4],\n##        [5]])"},{"path":"sklearn.html","id":"degree-1","chapter":"17 sklearn","heading":"17.7.1.2 Degree 1","text":"One Degree means maintain original features. new features created.","code":"PolynomialFeatures(degree=1, include_bias=False).fit_transform(X)## array([[1.],\n##        [2.],\n##        [3.],\n##        [4.],\n##        [5.]])"},{"path":"sklearn.html","id":"degree-2","chapter":"17 sklearn","heading":"17.7.1.3 Degree 2","text":"Degree-1 original feature: x\nDegree-2 additional features: x^2","code":"PolynomialFeatures(degree=2, include_bias=False).fit_transform(X)## array([[ 1.,  1.],\n##        [ 2.,  4.],\n##        [ 3.,  9.],\n##        [ 4., 16.],\n##        [ 5., 25.]])"},{"path":"sklearn.html","id":"degree-3","chapter":"17 sklearn","heading":"17.7.1.4 Degree 3","text":"Degree-1 original feature: x\nDegree-2 additional features: x^2\nDegree-3 additional features: x^3","code":"PolynomialFeatures(degree=3, include_bias=False).fit_transform(X)## array([[  1.,   1.,   1.],\n##        [  2.,   4.,   8.],\n##        [  3.,   9.,  27.],\n##        [  4.,  16.,  64.],\n##        [  5.,  25., 125.]])"},{"path":"sklearn.html","id":"degree-4","chapter":"17 sklearn","heading":"17.7.1.5 Degree 4","text":"Degree-1 original feature: x\nDegree-2 additional features: x^2\nDegree-3 additional features: x^3\nDegree-3 additional features: x^4","code":"PolynomialFeatures(degree=4, include_bias=False).fit_transform(X)## array([[  1.,   1.,   1.,   1.],\n##        [  2.,   4.,   8.,  16.],\n##        [  3.,   9.,  27.,  81.],\n##        [  4.,  16.,  64., 256.],\n##        [  5.,  25., 125., 625.]])"},{"path":"sklearn.html","id":"two-variables","chapter":"17 sklearn","heading":"17.7.2 Two Variables","text":"","code":""},{"path":"sklearn.html","id":"sample-data-23","chapter":"17 sklearn","heading":"17.7.2.1 Sample Data","text":"","code":"X = pd.DataFrame( {'x1': [1, 2, 3, 4, 5 ],\n                   'x2': [6, 7, 8, 9, 10]})\nX##    x1  x2\n## 0   1   6\n## 1   2   7\n## 2   3   8\n## 3   4   9\n## 4   5  10"},{"path":"sklearn.html","id":"degree-2-1","chapter":"17 sklearn","heading":"17.7.2.2 Degree 2","text":"","code":"Degree-1 original   features:  x1,     x2  \nDegree-2 additional features:  x1^2,   x2^2,   x1:x2 PolynomialFeatures(degree=2, include_bias=False).fit_transform(X)## array([[  1.,   6.,   1.,   6.,  36.],\n##        [  2.,   7.,   4.,  14.,  49.],\n##        [  3.,   8.,   9.,  24.,  64.],\n##        [  4.,   9.,  16.,  36.,  81.],\n##        [  5.,  10.,  25.,  50., 100.]])"},{"path":"sklearn.html","id":"degree-3-1","chapter":"17 sklearn","heading":"17.7.2.3 Degree 3","text":"","code":"Degree-1 original   features:  x1,       x2  \nDegree-2 additional features:  x1^2,     x2^2,   x1:x2 \nDegree-3 additional features:  x1^3,     x2^3    x1:x2^2    x2:x1^2PolynomialFeatures(degree=3, include_bias=False).fit_transform(X)## array([[   1.,    6.,    1.,    6.,   36.,    1.,    6.,   36.,  216.],\n##        [   2.,    7.,    4.,   14.,   49.,    8.,   28.,   98.,  343.],\n##        [   3.,    8.,    9.,   24.,   64.,   27.,   72.,  192.,  512.],\n##        [   4.,    9.,   16.,   36.,   81.,   64.,  144.,  324.,  729.],\n##        [   5.,   10.,   25.,   50.,  100.,  125.,  250.,  500., 1000.]])"},{"path":"sklearn.html","id":"imputation-of-missing-data","chapter":"17 sklearn","heading":"17.8 Imputation of Missing Data","text":"","code":""},{"path":"sklearn.html","id":"sample-data-24","chapter":"17 sklearn","heading":"17.8.1 Sample Data","text":"","code":"from numpy import nan\nX = np.array([[ nan, 0,   3  ],\n              [ 3,   7,   9  ],\n              [ 3,   5,   2  ],\n              [ 4,   nan, 6  ],\n              [ 8,   8,   1  ]])\n\ny = np.array([14, 16, -1,  8, -5])"},{"path":"sklearn.html","id":"imputer","chapter":"17 sklearn","heading":"17.8.2 Imputer","text":"","code":""},{"path":"sklearn.html","id":"mean-strategy","chapter":"17 sklearn","heading":"17.8.2.1 mean strategy","text":"","code":"imp = SimpleImputer(strategy='mean')\nX2 = imp.fit_transform(X)\nX2## array([[4.5, 0. , 3. ],\n##        [3. , 7. , 9. ],\n##        [3. , 5. , 2. ],\n##        [4. , 5. , 6. ],\n##        [8. , 8. , 1. ]])"},{"path":"sklearn.html","id":"scaling","chapter":"17 sklearn","heading":"17.9 Scaling","text":"possible insignificant variable larger range dominating objective function.\ncan remove problem scaling features range.","code":""},{"path":"sklearn.html","id":"sample-data-25","chapter":"17 sklearn","heading":"17.9.1 Sample Data","text":"","code":"X=mydf.filter(like='x')[:5]\nX##    x1  x2  x3\n## 0   2  16  10\n## 1  15   9  10\n## 2  10   4  11\n## 3   1  20  17\n## 4   9   1   2"},{"path":"sklearn.html","id":"minmax-scaler","chapter":"17 sklearn","heading":"17.9.2 MinMax Scaler","text":"Define Scaler ObjectTransform DataScaler Attributes","code":"MinMaxScaler( feature_range(0,1), copy=True )\n# default feature range (output result) from 0 to 1\n# default return a copy of new array, copy=False will inplace original arrayscaler = MinMaxScaler()scaler.fit_transform(X)## array([[0.07142857, 0.78947368, 0.53333333],\n##        [1.        , 0.42105263, 0.53333333],\n##        [0.64285714, 0.15789474, 0.6       ],\n##        [0.        , 1.        , 1.        ],\n##        [0.57142857, 0.        , 0.        ]])data_min_: minimum value of the feature (before scaling)  \ndata_max_: maximum value of the feature (before scaling)  pd.DataFrame(list(zip(scaler.data_min_, scaler.data_max_)), \n             columns=['data_min','data_max'], \n             index=X.columns)##     data_min  data_max\n## x1       1.0      15.0\n## x2       1.0      20.0\n## x3       2.0      17.0"},{"path":"sklearn.html","id":"standard-scaler","chapter":"17 sklearn","heading":"17.9.3 Standard Scaler","text":"suitable techniques assume Gaussian distribution input variables work better rescaled data, linear regression, logistic regression linear discriminate analysis.Define Scaler ObjectTransform DataScaler Attributes\ndata transformation step , scaler mean variance information feature.","code":"StandardScaler(copy=True, with_mean=True, with_std=True)\n# copy=True : return a copy of data, instead of inplace\n# with_mean=True : centre all features by substracting with its mean\n# with_std=True  : centre all features by dividing with its stdscaler = StandardScaler()scaler.fit_transform(X)## array([[-1.03086479,  0.8418203 ,  0.        ],\n##        [ 1.45084674, -0.14030338,  0.        ],\n##        [ 0.49634231, -0.8418203 ,  0.20942695],\n##        [-1.22176568,  1.40303383,  1.46598868],\n##        [ 0.30544142, -1.26273045, -1.67541563]])pd.DataFrame(list(zip(scaler.mean_, scaler.var_)), \n             columns=['mean','variance'], \n             index=X.columns)##     mean  variance\n## x1   7.4     27.44\n## x2  10.0     50.80\n## x3  10.0     22.80"},{"path":"sklearn.html","id":"pipeline","chapter":"17 sklearn","heading":"17.10 Pipeline","text":"preceding examples, can quickly become tedious transformations hand, especially wish string together multiple steps. example, might want processing pipeline looks something like :Impute missing values using meanTransform features quadraticFit linear regressionmake_pipeline takes list functions parameters. calling fit() pipeline object, functions performed sequential data flow one function another.","code":"make_pipeline (\n    function_1 (),\n    function_2 (),\n    function_3 ()\n )"},{"path":"sklearn.html","id":"sample-data-26","chapter":"17 sklearn","heading":"17.10.1 Sample Data","text":"","code":"X##    x1  x2  x3\n## 0   2  16  10\n## 1  15   9  10\n## 2  10   4  11\n## 3   1  20  17\n## 4   9   1   2y## array([14, 16, -1,  8, -5])"},{"path":"sklearn.html","id":"create-pipeline","chapter":"17 sklearn","heading":"17.10.2 Create Pipeline","text":"","code":"my_pipe = make_pipeline (\n    SimpleImputer            (strategy='mean'),\n    PolynomialFeatures (degree=2),\n    LinearRegression   ()\n)\ntype(my_pipe)## <class 'sklearn.pipeline.Pipeline'>my_pipePipeline(steps=[('simpleimputer', SimpleImputer()),\n                ('polynomialfeatures', PolynomialFeatures()),\n                ('linearregression', LinearRegression())])Pipeline(steps=[('simpleimputer', SimpleImputer()),\n                ('polynomialfeatures', PolynomialFeatures()),\n                ('linearregression', LinearRegression())])SimpleImputer()PolynomialFeatures()LinearRegression()"},{"path":"sklearn.html","id":"executing-pipeline","chapter":"17 sklearn","heading":"17.10.3 Executing Pipeline","text":"","code":"my_pipe.fit( X, y) # execute the pipelinePipeline(steps=[('simpleimputer', SimpleImputer()),\n                ('polynomialfeatures', PolynomialFeatures()),\n                ('linearregression', LinearRegression())])Pipeline(steps=[('simpleimputer', SimpleImputer()),\n                ('polynomialfeatures', PolynomialFeatures()),\n                ('linearregression', LinearRegression())])SimpleImputer()PolynomialFeatures()LinearRegression()print (y)## [14 16 -1  8 -5]print (my_pipe.predict(X))## [14. 16. -1.  8. -5.]type(my_pipe)## <class 'sklearn.pipeline.Pipeline'>"},{"path":"sklearn.html","id":"cross-validation","chapter":"17 sklearn","heading":"17.11 Cross Validation","text":"","code":""},{"path":"sklearn.html","id":"load-data","chapter":"17 sklearn","heading":"17.11.1 Load Data","text":"","code":"X,y = datasets.load_diabetes(return_X_y=True)"},{"path":"sklearn.html","id":"choose-an-cross-validator","chapter":"17 sklearn","heading":"17.11.2 Choose An Cross Validator","text":"","code":"kf = KFold(n_splits=5)"},{"path":"sklearn.html","id":"run-cross-validation","chapter":"17 sklearn","heading":"17.11.3 Run Cross Validation","text":"Single Scorer\nUse default scorer estimator (available)Multiple Scorer\nSpecify scorer\nhttp://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter","code":"lasso = Lasso()\ncv_results1 = cross_validate(lasso, X,y,cv=kf,\n    return_train_score=False)cv_results2 = cross_validate(lasso, X,y,cv=kf,\n    scoring=(\"neg_mean_absolute_error\",\"neg_mean_squared_error\",\"r2\"),\n    return_train_score=False)"},{"path":"sklearn.html","id":"the-result","chapter":"17 sklearn","heading":"17.11.4 The Result","text":"Result dictionary","code":"cv_results1.keys()## dict_keys(['fit_time', 'score_time', 'test_score'])cv_results2.keys()## dict_keys(['fit_time', 'score_time', 'test_neg_mean_absolute_error', 'test_neg_mean_squared_error', 'test_r2'])cv_results1## {'fit_time': array([0., 0., 0., 0., 0.]), 'score_time': array([0.       , 0.       , 0.       , 0.       , 0.0148561]), 'test_score': array([0.28349006, 0.35157952, 0.35338233, 0.33481253, 0.36453239])}cv_results2## {'fit_time': array([0.00572038, 0.        , 0.        , 0.        , 0.00852919]), 'score_time': array([0.00050497, 0.        , 0.        , 0.        , 0.00113416]), 'test_neg_mean_absolute_error': array([-50.09006473, -52.54118496, -55.02819607, -50.8112893 ,\n##        -55.60479053]), 'test_neg_mean_squared_error': array([-3491.74208572, -4113.86049974, -4046.91135088, -3489.75176794,\n##        -4111.92674103]), 'test_r2': array([0.28349006, 0.35157952, 0.35338233, 0.33481253, 0.36453239])}"},{"path":"web-scrapping.html","id":"web-scrapping","chapter":"18 Web Scrapping","heading":"18 Web Scrapping","text":"","code":""},{"path":"web-scrapping.html","id":"requests","chapter":"18 Web Scrapping","heading":"18.1 requests","text":"","code":""},{"path":"web-scrapping.html","id":"creating-a-session","chapter":"18 Web Scrapping","heading":"18.1.1 Creating A Session","text":"","code":"import requests\nfrom requests.adapters import HTTPAdapter\nfrom urllib3.util.retry import Retry\nimport random\n\n\n_retries = Retry(connect=10,read=10,backoff_factor=1)   # backoff is incremental interval in seconds between retries\n_timeout = (10,10)  ## connect, read timeout in seconds\n\nrqs = requests.Session()\nrqs.mount( 'http://' ,  HTTPAdapter(max_retries= _retries))\nrqs.mount( 'https://' , HTTPAdapter(max_retries= _retries))link1 = 'https://www.yahoo.com'\nlink2 = 'http://mamamia777.com.au'\n#user_agent = {'User-Agent': random.choice(_USER_AGENTS)}\n#response1  = rqs.get(link1, timeout=_timeout)\n#response2  = rqs.get(link2, timeout=_timeout)  #print (page1.status_code)"},{"path":"web-scrapping.html","id":"rotating-broswer","chapter":"18 Web Scrapping","heading":"18.1.2 Rotating Broswer","text":"","code":"_USER_AGENTS = [\n   #Chrome\n    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n    'Mozilla/5.0 (Windows NT 5.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n    'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n    'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n    #Firefox\n    'Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1)',\n    'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko',\n    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)',\n    'Mozilla/5.0 (Windows NT 6.1; Trident/7.0; rv:11.0) like Gecko',\n    'Mozilla/5.0 (Windows NT 6.2; WOW64; Trident/7.0; rv:11.0) like Gecko',\n    'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko',\n    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.0; Trident/5.0)',\n    'Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko',\n    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)',\n    'Mozilla/5.0 (Windows NT 6.1; Win64; x64; Trident/7.0; rv:11.0) like Gecko',\n    'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)',\n    'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0)',\n    'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729)']"},{"path":"web-scrapping.html","id":"beautifulsoup","chapter":"18 Web Scrapping","heading":"18.2 BeautifulSoup","text":"","code":""},{"path":"web-scrapping.html","id":"module-import-2","chapter":"18 Web Scrapping","heading":"18.2.1 Module Import","text":"","code":"from bs4 import BeautifulSoup"},{"path":"web-scrapping.html","id":"html-tag-parsing","chapter":"18 Web Scrapping","heading":"18.2.2 HTML Tag Parsing","text":"","code":""},{"path":"web-scrapping.html","id":"sample-data-27","chapter":"18 Web Scrapping","heading":"18.2.2.1 Sample Data","text":"","code":"my_html = '''\n<div id=\"my-id1\" class='title'> \n    <p>This Is My Title<\/p>\n    \n    <div id=\"my-id2\" class='subtitle' custom_attr='funny'>\n        <p>This is Subtitle<\/p>\n    <\/div>\n    \n    <div id=\"my-id3\" class='title',   custom_attr='funny'>\n        <p>This is paragraph1<\/p>\n        <p>This is paragraph2<\/p>\n        <h3>This is paragraph3<\/h3>\n    <\/div>\n<\/div>\n'''\nsoup = BeautifulSoup(my_html)"},{"path":"web-scrapping.html","id":"first-match","chapter":"18 Web Scrapping","heading":"18.2.2.2 First Match","text":"ID Selector\nEverthing selected tag returned.Class SelectorAttribute Selector","code":"soup.find(id='my-id1')## <div class=\"title\" id=\"my-id1\">\n## <p>This Is My Title<\/p>\n## <div class=\"subtitle\" custom_attr=\"funny\" id=\"my-id2\">\n## <p>This is Subtitle<\/p>\n## <\/div>\n## <div class=\"title\" custom_attr=\"funny\" id=\"my-id3\">\n## <p>This is paragraph1<\/p>\n## <p>This is paragraph2<\/p>\n## <h3>This is paragraph3<\/h3>\n## <\/div>\n## <\/div>soup.find(class_='subtitle')## <div class=\"subtitle\" custom_attr=\"funny\" id=\"my-id2\">\n## <p>This is Subtitle<\/p>\n## <\/div>soup.find(custom_attr='funny')## <div class=\"subtitle\" custom_attr=\"funny\" id=\"my-id2\">\n## <p>This is Subtitle<\/p>\n## <\/div>soup.find(       custom_attr='funny')## <div class=\"subtitle\" custom_attr=\"funny\" id=\"my-id2\">\n## <p>This is Subtitle<\/p>\n## <\/div>soup.find('div', custom_attr='funny')## <div class=\"subtitle\" custom_attr=\"funny\" id=\"my-id2\">\n## <p>This is Subtitle<\/p>\n## <\/div>"},{"path":"web-scrapping.html","id":"find-all-matches","chapter":"18 Web Scrapping","heading":"18.2.2.3 Find All Matches","text":"find_allCSS Selector using select()can achieved using css selector. return array result (multiple matches).granular exmaple css selector.Using contains()Combining ID, Class Custom Attribute selector","code":"soup = BeautifulSoup(my_html)\nmultiple_result = soup.find_all(class_='title')\nprint( 'Item 0: \\n',     multiple_result[0],\n       '\\n\\nItem 1: \\n', multiple_result[1])## Item 0: \n##  <div class=\"title\" id=\"my-id1\">\n## <p>This Is My Title<\/p>\n## <div class=\"subtitle\" custom_attr=\"funny\" id=\"my-id2\">\n## <p>This is Subtitle<\/p>\n## <\/div>\n## <div class=\"title\" custom_attr=\"funny\" id=\"my-id3\">\n## <p>This is paragraph1<\/p>\n## <p>This is paragraph2<\/p>\n## <h3>This is paragraph3<\/h3>\n## <\/div>\n## <\/div> \n## \n## Item 1: \n##  <div class=\"title\" custom_attr=\"funny\" id=\"my-id3\">\n## <p>This is paragraph1<\/p>\n## <p>This is paragraph2<\/p>\n## <h3>This is paragraph3<\/h3>\n## <\/div>multiple_result = soup.select('.title')\nprint( 'Item 0: \\n',     multiple_result[0],\n       '\\n\\nItem 1: \\n', multiple_result[1])## Item 0: \n##  <div class=\"title\" id=\"my-id1\">\n## <p>This Is My Title<\/p>\n## <div class=\"subtitle\" custom_attr=\"funny\" id=\"my-id2\">\n## <p>This is Subtitle<\/p>\n## <\/div>\n## <div class=\"title\" custom_attr=\"funny\" id=\"my-id3\">\n## <p>This is paragraph1<\/p>\n## <p>This is paragraph2<\/p>\n## <h3>This is paragraph3<\/h3>\n## <\/div>\n## <\/div> \n## \n## Item 1: \n##  <div class=\"title\" custom_attr=\"funny\" id=\"my-id3\">\n## <p>This is paragraph1<\/p>\n## <p>This is paragraph2<\/p>\n## <h3>This is paragraph3<\/h3>\n## <\/div>soup.select('#my-id1 div.subtitle')## [<div class=\"subtitle\" custom_attr=\"funny\" id=\"my-id2\">\n## <p>This is Subtitle<\/p>\n## <\/div>]soup.select(\"p:contains('This is paragraph')\")## [<p>This is paragraph1<\/p>, <p>This is paragraph2<\/p>]\n## \n## C:\\PROGRA~3\\Anaconda3\\lib\\site-packages\\soupsieve\\css_parser.py:876: FutureWarning: The pseudo class ':contains' is deprecated, ':-soup-contains' should be used moving forward.\n##   warnings.warn(soup.select(\"div#my-id3.title[custom_attr='funny']:contains('This is paragraph')\")## [<div class=\"title\" custom_attr=\"funny\" id=\"my-id3\">\n## <p>This is paragraph1<\/p>\n## <p>This is paragraph2<\/p>\n## <h3>This is paragraph3<\/h3>\n## <\/div>]"},{"path":"web-scrapping.html","id":"meta-parsing","chapter":"18 Web Scrapping","heading":"18.2.3 Meta Parsing","text":"","code":"my_meta = '''\n<meta property=\"description\"   content=\"KUALA LUMPUR: blah blah\"   category=\"Malaysia\">\n<meta property=\"publish-date\"  content=\"2012-01-03\">\n'''\nsoup = BeautifulSoup(my_meta)\nsoup.find('meta', property='description')['content']## 'KUALA LUMPUR: blah blah'soup.find('meta', property='description')['category']## 'Malaysia'soup.find('meta', property='publish-date')['content']## '2012-01-03'soup.find('meta', category='Malaysia')['property']## 'description'"},{"path":"web-scrapping.html","id":"getting-content","chapter":"18 Web Scrapping","heading":"18.2.4 Getting Content","text":"","code":""},{"path":"web-scrapping.html","id":"get-content-get_textstrip-separator","chapter":"18 Web Scrapping","heading":"18.2.4.1 Get Content get_text(strip=, separator=)","text":"Use strip=True strip whitespace beginning end bit textUse `separator=‘’ specify string used join bits text togetherIt recommended use strip=True, separator='\\n' result different operating system consistantstrip=True combine separator retain user readable text portion tag, separator seperating ","code":"soup = BeautifulSoup(my_html)\nelem = soup.find(id = \"my-id3\")\nelem.get_text(strip=False)## '\\nThis is paragraph1\\nThis is paragraph2\\nThis is paragraph3\\n'elem.get_text(strip=True, separator='\\n')## 'This is paragraph1\\nThis is paragraph2\\nThis is paragraph3'"},{"path":"web-scrapping.html","id":"splitting-content","chapter":"18 Web Scrapping","heading":"18.2.4.2 Splitting Content","text":"useful split using separator list string.","code":"elem = soup.find(id = \"my-id3\")\nelem.get_text(strip=True, separator='\\n').split('\\n')## ['This is paragraph1', 'This is paragraph2', 'This is paragraph3']"},{"path":"web-scrapping.html","id":"traversing","chapter":"18 Web Scrapping","heading":"18.2.5 Traversing","text":"","code":""},{"path":"web-scrapping.html","id":"get-the-element","chapter":"18 Web Scrapping","heading":"18.2.5.1 Get The Element","text":"","code":"elems = soup.select(\"div#my-id3.title[custom_attr='funny']:contains('This is paragraph')\")\nelem = elems[0]\nelem## <div class=\"title\" custom_attr=\"funny\" id=\"my-id3\">\n## <p>This is paragraph1<\/p>\n## <p>This is paragraph2<\/p>\n## <h3>This is paragraph3<\/h3>\n## <\/div>"},{"path":"web-scrapping.html","id":"traversing-children","chapter":"18 Web Scrapping","heading":"18.2.5.2 Traversing Children","text":"Children List findChildren()Next Children findNext()element children, get immediate childIf element children, find next element hierechy","code":"elem.findChildren()## [<p>This is paragraph1<\/p>, <p>This is paragraph2<\/p>, <h3>This is paragraph3<\/h3>]first_child = elem.fin\nprint( \nelem.findNext().get_text(strip=True), '\\n', \nelem.findNext().findNext().get_text(strip=True), '\\n')## This is paragraph1 \n##  This is paragraph2"},{"path":"web-scrapping.html","id":"traversing-to-parent-parent","chapter":"18 Web Scrapping","heading":"18.2.5.3 Traversing To Parent parent()","text":"","code":"elem_parent = elem.parent\nelem_parent.attrs## {'id': 'my-id1', 'class': ['title']}"},{"path":"web-scrapping.html","id":"get-the-sibling-findprevioussibling","chapter":"18 Web Scrapping","heading":"18.2.5.4 Get The Sibling findPreviousSibling()","text":"Sibling element level hierachy","code":"elem_prev_sib = elem.findPreviousSibling()\nelem_prev_sib.attrs## {'id': 'my-id2', 'class': ['subtitle'], 'custom_attr': 'funny'}"}]
