[["web-scrapping.html", "Chapter 6 Web Scrapping 6.1 requests 6.2 BeautifulSoup", " Chapter 6 Web Scrapping 6.1 requests 6.1.1 Creating A Session import requests from requests.adapters import HTTPAdapter from urllib3.util.retry import Retry import random _retries = Retry(connect=10,read=10,backoff_factor=1) # backoff is incremental interval in seconds between retries _timeout = (10,10) ## connect, read timeout in seconds rqs = requests.Session() rqs.mount( &#39;http://&#39; , HTTPAdapter(max_retries= _retries)) rqs.mount( &#39;https://&#39; , HTTPAdapter(max_retries= _retries)) link1 = &#39;https://www.yahoo.com&#39; link2 = &#39;http://mamamia777.com.au&#39; #user_agent = {&#39;User-Agent&#39;: random.choice(_USER_AGENTS)} #response1 = rqs.get(link1, timeout=_timeout) #response2 = rqs.get(link2, timeout=_timeout) #print (page1.status_code) 6.1.2 Rotating Broswer _USER_AGENTS = [ #Chrome &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36&#39;, &#39;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36&#39;, &#39;Mozilla/5.0 (Windows NT 5.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36&#39;, &#39;Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36&#39;, &#39;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36&#39;, &#39;Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36&#39;, &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36&#39;, &#39;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36&#39;, &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36&#39;, &#39;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36&#39;, #Firefox &#39;Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1)&#39;, &#39;Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko&#39;, &#39;Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)&#39;, &#39;Mozilla/5.0 (Windows NT 6.1; Trident/7.0; rv:11.0) like Gecko&#39;, &#39;Mozilla/5.0 (Windows NT 6.2; WOW64; Trident/7.0; rv:11.0) like Gecko&#39;, &#39;Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko&#39;, &#39;Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.0; Trident/5.0)&#39;, &#39;Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko&#39;, &#39;Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)&#39;, &#39;Mozilla/5.0 (Windows NT 6.1; Win64; x64; Trident/7.0; rv:11.0) like Gecko&#39;, &#39;Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)&#39;, &#39;Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0)&#39;, &#39;Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729)&#39;] 6.2 BeautifulSoup 6.2.1 Module Import from bs4 import BeautifulSoup 6.2.2 HTML Tag Parsing 6.2.2.1 Sample Data my_html = &#39;&#39;&#39; &lt;div id=&quot;my-id1&quot; class=&#39;title&#39;&gt; &lt;p&gt;This Is My Title&lt;/p&gt; &lt;div id=&quot;my-id2&quot; class=&#39;subtitle&#39; custom_attr=&#39;funny&#39;&gt; &lt;p&gt;This is Subtitle&lt;/p&gt; &lt;/div&gt; &lt;div id=&quot;my-id3&quot; class=&#39;title&#39;, custom_attr=&#39;funny&#39;&gt; &lt;p&gt;This is paragraph1&lt;/p&gt; &lt;p&gt;This is paragraph2&lt;/p&gt; &lt;h3&gt;This is paragraph3&lt;/h3&gt; &lt;/div&gt; &lt;/div&gt; &#39;&#39;&#39; soup = BeautifulSoup(my_html) 6.2.2.2 First Match ID Selector Everthing under the selected tag will be returned. soup.find(id=&#39;my-id1&#39;) ## &lt;div class=&quot;title&quot; id=&quot;my-id1&quot;&gt; ## &lt;p&gt;This Is My Title&lt;/p&gt; ## &lt;div class=&quot;subtitle&quot; custom_attr=&quot;funny&quot; id=&quot;my-id2&quot;&gt; ## &lt;p&gt;This is Subtitle&lt;/p&gt; ## &lt;/div&gt; ## &lt;div class=&quot;title&quot; custom_attr=&quot;funny&quot; id=&quot;my-id3&quot;&gt; ## &lt;p&gt;This is paragraph1&lt;/p&gt; ## &lt;p&gt;This is paragraph2&lt;/p&gt; ## &lt;h3&gt;This is paragraph3&lt;/h3&gt; ## &lt;/div&gt; ## &lt;/div&gt; Class Selector soup.find(class_=&#39;subtitle&#39;) ## &lt;div class=&quot;subtitle&quot; custom_attr=&quot;funny&quot; id=&quot;my-id2&quot;&gt; ## &lt;p&gt;This is Subtitle&lt;/p&gt; ## &lt;/div&gt; Attribute Selector soup.find(custom_attr=&#39;funny&#39;) ## &lt;div class=&quot;subtitle&quot; custom_attr=&quot;funny&quot; id=&quot;my-id2&quot;&gt; ## &lt;p&gt;This is Subtitle&lt;/p&gt; ## &lt;/div&gt; soup.find( custom_attr=&#39;funny&#39;) ## &lt;div class=&quot;subtitle&quot; custom_attr=&quot;funny&quot; id=&quot;my-id2&quot;&gt; ## &lt;p&gt;This is Subtitle&lt;/p&gt; ## &lt;/div&gt; soup.find(&#39;div&#39;, custom_attr=&#39;funny&#39;) ## &lt;div class=&quot;subtitle&quot; custom_attr=&quot;funny&quot; id=&quot;my-id2&quot;&gt; ## &lt;p&gt;This is Subtitle&lt;/p&gt; ## &lt;/div&gt; 6.2.2.3 Find All Matches find_all soup = BeautifulSoup(my_html) multiple_result = soup.find_all(class_=&#39;title&#39;) print( &#39;Item 0: \\n&#39;, multiple_result[0], &#39;\\n\\nItem 1: \\n&#39;, multiple_result[1]) ## Item 0: ## &lt;div class=&quot;title&quot; id=&quot;my-id1&quot;&gt; ## &lt;p&gt;This Is My Title&lt;/p&gt; ## &lt;div class=&quot;subtitle&quot; custom_attr=&quot;funny&quot; id=&quot;my-id2&quot;&gt; ## &lt;p&gt;This is Subtitle&lt;/p&gt; ## &lt;/div&gt; ## &lt;div class=&quot;title&quot; custom_attr=&quot;funny&quot; id=&quot;my-id3&quot;&gt; ## &lt;p&gt;This is paragraph1&lt;/p&gt; ## &lt;p&gt;This is paragraph2&lt;/p&gt; ## &lt;h3&gt;This is paragraph3&lt;/h3&gt; ## &lt;/div&gt; ## &lt;/div&gt; ## ## Item 1: ## &lt;div class=&quot;title&quot; custom_attr=&quot;funny&quot; id=&quot;my-id3&quot;&gt; ## &lt;p&gt;This is paragraph1&lt;/p&gt; ## &lt;p&gt;This is paragraph2&lt;/p&gt; ## &lt;h3&gt;This is paragraph3&lt;/h3&gt; ## &lt;/div&gt; CSS Selector using select() Above can be achieved using css selector. It return an array of result (multiple matches). multiple_result = soup.select(&#39;.title&#39;) print( &#39;Item 0: \\n&#39;, multiple_result[0], &#39;\\n\\nItem 1: \\n&#39;, multiple_result[1]) ## Item 0: ## &lt;div class=&quot;title&quot; id=&quot;my-id1&quot;&gt; ## &lt;p&gt;This Is My Title&lt;/p&gt; ## &lt;div class=&quot;subtitle&quot; custom_attr=&quot;funny&quot; id=&quot;my-id2&quot;&gt; ## &lt;p&gt;This is Subtitle&lt;/p&gt; ## &lt;/div&gt; ## &lt;div class=&quot;title&quot; custom_attr=&quot;funny&quot; id=&quot;my-id3&quot;&gt; ## &lt;p&gt;This is paragraph1&lt;/p&gt; ## &lt;p&gt;This is paragraph2&lt;/p&gt; ## &lt;h3&gt;This is paragraph3&lt;/h3&gt; ## &lt;/div&gt; ## &lt;/div&gt; ## ## Item 1: ## &lt;div class=&quot;title&quot; custom_attr=&quot;funny&quot; id=&quot;my-id3&quot;&gt; ## &lt;p&gt;This is paragraph1&lt;/p&gt; ## &lt;p&gt;This is paragraph2&lt;/p&gt; ## &lt;h3&gt;This is paragraph3&lt;/h3&gt; ## &lt;/div&gt; More granular exmaple of css selector. soup.select(&#39;#my-id1 div.subtitle&#39;) ## [&lt;div class=&quot;subtitle&quot; custom_attr=&quot;funny&quot; id=&quot;my-id2&quot;&gt; ## &lt;p&gt;This is Subtitle&lt;/p&gt; ## &lt;/div&gt;] Using contains() soup.select(&quot;p:contains(&#39;This is paragraph&#39;)&quot;) ## [&lt;p&gt;This is paragraph1&lt;/p&gt;, &lt;p&gt;This is paragraph2&lt;/p&gt;] ## ## C:\\PROGRA~3\\Anaconda3\\lib\\site-packages\\soupsieve\\css_parser.py:876: FutureWarning: The pseudo class &#39;:contains&#39; is deprecated, &#39;:-soup-contains&#39; should be used moving forward. ## warnings.warn( Combining ID, Class and Custom Attribute in the selector soup.select(&quot;div#my-id3.title[custom_attr=&#39;funny&#39;]:contains(&#39;This is paragraph&#39;)&quot;) ## [&lt;div class=&quot;title&quot; custom_attr=&quot;funny&quot; id=&quot;my-id3&quot;&gt; ## &lt;p&gt;This is paragraph1&lt;/p&gt; ## &lt;p&gt;This is paragraph2&lt;/p&gt; ## &lt;h3&gt;This is paragraph3&lt;/h3&gt; ## &lt;/div&gt;] 6.2.3 Meta Parsing my_meta = &#39;&#39;&#39; &lt;meta property=&quot;description&quot; content=&quot;KUALA LUMPUR: blah blah&quot; category=&quot;Malaysia&quot;&gt; &lt;meta property=&quot;publish-date&quot; content=&quot;2012-01-03&quot;&gt; &#39;&#39;&#39; soup = BeautifulSoup(my_meta) soup.find(&#39;meta&#39;, property=&#39;description&#39;)[&#39;content&#39;] ## &#39;KUALA LUMPUR: blah blah&#39; soup.find(&#39;meta&#39;, property=&#39;description&#39;)[&#39;category&#39;] ## &#39;Malaysia&#39; soup.find(&#39;meta&#39;, property=&#39;publish-date&#39;)[&#39;content&#39;] ## &#39;2012-01-03&#39; soup.find(&#39;meta&#39;, category=&#39;Malaysia&#39;)[&#39;property&#39;] ## &#39;description&#39; 6.2.4 Getting Content 6.2.4.1 Get Content get_text(strip=, separator=) Use strip=True to strip whitespace from the beginning and end of each bit of text Use `separator=‘’ to specify a string to be used to join the bits of text together It is recommended to use strip=True, separator='\\n' so that result from different operating system will be consistant soup = BeautifulSoup(my_html) elem = soup.find(id = &quot;my-id3&quot;) elem.get_text(strip=False) ## &#39;\\nThis is paragraph1\\nThis is paragraph2\\nThis is paragraph3\\n&#39; strip=True combine with separator will retain only the user readable text portion of each tag, with separator seperating them elem.get_text(strip=True, separator=&#39;\\n&#39;) ## &#39;This is paragraph1\\nThis is paragraph2\\nThis is paragraph3&#39; 6.2.4.2 Splitting Content It is useful to split using separator into list of string. elem = soup.find(id = &quot;my-id3&quot;) elem.get_text(strip=True, separator=&#39;\\n&#39;).split(&#39;\\n&#39;) ## [&#39;This is paragraph1&#39;, &#39;This is paragraph2&#39;, &#39;This is paragraph3&#39;] 6.2.5 Traversing 6.2.5.1 Get The Element elems = soup.select(&quot;div#my-id3.title[custom_attr=&#39;funny&#39;]:contains(&#39;This is paragraph&#39;)&quot;) elem = elems[0] elem ## &lt;div class=&quot;title&quot; custom_attr=&quot;funny&quot; id=&quot;my-id3&quot;&gt; ## &lt;p&gt;This is paragraph1&lt;/p&gt; ## &lt;p&gt;This is paragraph2&lt;/p&gt; ## &lt;h3&gt;This is paragraph3&lt;/h3&gt; ## &lt;/div&gt; 6.2.5.2 Traversing Children All Children In List findChildren() elem.findChildren() ## [&lt;p&gt;This is paragraph1&lt;/p&gt;, &lt;p&gt;This is paragraph2&lt;/p&gt;, &lt;h3&gt;This is paragraph3&lt;/h3&gt;] Next Children findNext() If the element has children, this will get the immediate child If the element has no children, this will find the next element in the hierechy first_child = elem.fin print( elem.findNext().get_text(strip=True), &#39;\\n&#39;, elem.findNext().findNext().get_text(strip=True), &#39;\\n&#39;) ## This is paragraph1 ## This is paragraph2 6.2.5.3 Traversing To Parent parent() elem_parent = elem.parent elem_parent.attrs ## {&#39;id&#39;: &#39;my-id1&#39;, &#39;class&#39;: [&#39;title&#39;]} 6.2.5.4 Get The Sibling findPreviousSibling() Sibling is element at the same level of hierachy elem_prev_sib = elem.findPreviousSibling() elem_prev_sib.attrs ## {&#39;id&#39;: &#39;my-id2&#39;, &#39;class&#39;: [&#39;subtitle&#39;], &#39;custom_attr&#39;: &#39;funny&#39;} "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
